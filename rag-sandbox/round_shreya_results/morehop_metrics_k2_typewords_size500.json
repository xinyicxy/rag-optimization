{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.5195672588744862,
      "faithfulness": 0.41805555555555557,
      "context_recall": 0.2916666666666667,
      "context_precision": 0.36666666663166664,
      "answer_correctness": 0.5438314321218771,
      "EM": 0.3416666666666667,
      "F1": 0.3906878306878307,
      "avg_retrieve_context": 0.105165034532547,
      "avg_llm_response": 0.9486779888470968,
      "avg_total": 1.0538430233796439,
      "sample_size": 120
    }
  },
  "answer_type": {
    "date": {
      "answer_relevancy": 0.39214247758879955,
      "faithfulness": 0.453125,
      "context_recall": 0.21875,
      "context_precision": 0.32812499996718747,
      "answer_correctness": 0.5402252041639064,
      "EM": 0.3125,
      "F1": 0.3125,
      "avg_retrieve_context": 0.105165034532547,
      "avg_llm_response": 0.862862266600132,
      "avg_total": 0.968027301132679,
      "sample_size": 32
    },
    "organization": {
      "answer_relevancy": 0.0,
      "faithfulness": 1.0,
      "context_recall": 0.0,
      "context_precision": 0.0,
      "answer_correctness": 0.19078338159286864,
      "EM": 0.0,
      "F1": 0.037037037037037035,
      "avg_retrieve_context": 0.105165034532547,
      "avg_llm_response": 0.5438736279805502,
      "avg_total": 0.6490386625130972,
      "sample_size": 3
    },
    "person": {
      "answer_relevancy": 0.6012530105076763,
      "faithfulness": 0.35752688172043007,
      "context_recall": 0.3387096774193548,
      "context_precision": 0.4435483870548386,
      "answer_correctness": 0.5807543545825056,
      "EM": 0.4032258064516129,
      "F1": 0.4963133640552996,
      "avg_retrieve_context": 0.105165034532547,
      "avg_llm_response": 0.891427343891513,
      "avg_total": 0.99659237842406,
      "sample_size": 62
    },
    "place": {
      "answer_relevancy": 0.7614361221512154,
      "faithfulness": 0.5,
      "context_recall": 1.0,
      "context_precision": 0.9999999999,
      "answer_correctness": 0.9923731044664574,
      "EM": 0.5,
      "F1": 0.5,
      "avg_retrieve_context": 0.105165034532547,
      "avg_llm_response": 2.0554510354995728,
      "avg_total": 2.1606160700321198,
      "sample_size": 2
    },
    "year": {
      "answer_relevancy": 0.5237596612532562,
      "faithfulness": 0.4523809523809524,
      "context_recall": 0.23809523809523808,
      "context_precision": 0.1904761904595238,
      "answer_correctness": 0.4480332849311141,
      "EM": 0.23809523809523808,
      "F1": 0.23809523809523808,
      "avg_retrieve_context": 0.105165034532547,
      "avg_llm_response": 1.200892754963466,
      "avg_total": 1.306057789496013,
      "sample_size": 21
    }
  }
}