{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6655074699262763,
      "faithfulness": 0.6666666666666666,
      "context_recall": 0.5583333333333333,
      "context_precision": 0.42499999996041665,
      "answer_correctness": 0.7614213241135181,
      "EM": 0.625,
      "F1": 0.6692063492063492,
      "avg_retrieve_context": 0.06817948818206787,
      "avg_llm_response": 0.8518151442209879,
      "avg_total": 0.9199946324030558,
      "sample_size": 120
    }
  },
  "answer_type": {
    "date": {
      "answer_relevancy": 0.637881291657011,
      "faithfulness": 0.84375,
      "context_recall": 0.59375,
      "context_precision": 0.46874999995468747,
      "answer_correctness": 0.7934124415562265,
      "EM": 0.65625,
      "F1": 0.65625,
      "avg_retrieve_context": 0.06817948818206787,
      "avg_llm_response": 0.7429345548152924,
      "avg_total": 0.8111140429973602,
      "sample_size": 32
    },
    "organization": {
      "answer_relevancy": 0.8322997581406502,
      "faithfulness": 1.0,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.3333333333,
      "answer_correctness": 0.6508338726689261,
      "EM": 0.3333333333333333,
      "F1": 0.4666666666666666,
      "avg_retrieve_context": 0.06817948818206787,
      "avg_llm_response": 0.5689151287078857,
      "avg_total": 0.6370946168899536,
      "sample_size": 3
    },
    "person": {
      "answer_relevancy": 0.6401628681575063,
      "faithfulness": 0.6209677419354839,
      "context_recall": 0.5645161290322581,
      "context_precision": 0.43548387092903224,
      "answer_correctness": 0.7637317225048302,
      "EM": 0.6290322580645161,
      "F1": 0.7081413210445469,
      "avg_retrieve_context": 0.06817948818206787,
      "avg_llm_response": 0.8642873879401914,
      "avg_total": 0.9324668761222593,
      "sample_size": 62
    },
    "place": {
      "answer_relevancy": 0.7573178640225657,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.49999999995,
      "answer_correctness": 0.9923731044664575,
      "EM": 0.5,
      "F1": 0.5,
      "avg_retrieve_context": 0.06817948818206787,
      "avg_llm_response": 2.064581513404846,
      "avg_total": 2.132761001586914,
      "sample_size": 2
    },
    "year": {
      "answer_relevancy": 0.7498601061855399,
      "faithfulness": 0.4523809523809524,
      "context_recall": 0.42857142857142855,
      "context_precision": 0.3333333333,
      "answer_correctness": 0.6996545781706552,
      "EM": 0.6190476190476191,
      "F1": 0.6190476190476191,
      "avg_retrieve_context": 0.06817948818206787,
      "avg_llm_response": 0.9058183374859038,
      "avg_total": 0.9739978256679717,
      "sample_size": 21
    }
  }
}