{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.7479785818600113,
      "faithfulness": 0.7815126050420168,
      "context_recall": 0.6554621848739496,
      "context_precision": 0.49033613441007007,
      "answer_correctness": 0.8654493928409853,
      "EM": 0.7916666666666666,
      "F1": 0.8311507936507937,
      "avg_retrieve_context": 0.06331945657730101,
      "avg_llm_response": 0.9949361483256022,
      "avg_total": 1.058255604902903,
      "sample_size": 120
    }
  },
  "answer_type": {
    "date": {
      "answer_relevancy": 0.7550889783525407,
      "faithfulness": 0.8125,
      "context_recall": 0.8125,
      "context_precision": 0.5140624999501563,
      "answer_correctness": 0.9421492106256527,
      "EM": 0.90625,
      "F1": 0.90625,
      "avg_retrieve_context": 0.06331945657730102,
      "avg_llm_response": 0.7704601809382439,
      "avg_total": 0.8337796375155448,
      "sample_size": 32
    },
    "organization": {
      "answer_relevancy": 0.8164907523067179,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.416666666625,
      "answer_correctness": 0.9145122024985631,
      "EM": 0.6666666666666666,
      "F1": 0.7999999999999999,
      "avg_retrieve_context": 0.06331945657730102,
      "avg_llm_response": 0.649094025293986,
      "avg_total": 0.7124134818712871,
      "sample_size": 3
    },
    "person": {
      "answer_relevancy": 0.7271665643393197,
      "faithfulness": 0.8114754098360656,
      "context_recall": 0.6229508196721312,
      "context_precision": 0.49836065569599725,
      "answer_correctness": 0.846632184757363,
      "EM": 0.7580645161290323,
      "F1": 0.8280337941628264,
      "avg_retrieve_context": 0.06331945657730105,
      "avg_llm_response": 1.108750089522331,
      "avg_total": 1.1720695460996322,
      "sample_size": 62
    },
    "place": {
      "answer_relevancy": 0.7573178640225657,
      "faithfulness": 0.75,
      "context_recall": 1.0,
      "context_precision": 0.5416666666270833,
      "answer_correctness": 0.8673731044664575,
      "EM": 0.5,
      "F1": 0.5,
      "avg_retrieve_context": 0.06331945657730102,
      "avg_llm_response": 2.035887598991394,
      "avg_total": 2.0992070555686952,
      "sample_size": 2
    },
    "year": {
      "answer_relevancy": 0.7879117877103309,
      "faithfulness": 0.6190476190476191,
      "context_recall": 0.42857142857142855,
      "context_precision": 0.43650793646706343,
      "answer_correctness": 0.7960408057823157,
      "EM": 0.7619047619047619,
      "F1": 0.7619047619047619,
      "avg_retrieve_context": 0.06331945657730101,
      "avg_llm_response": 0.9512404373713902,
      "avg_total": 1.0145598939486913,
      "sample_size": 21
    }
  }
}