{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6932952137551822,
      "faithfulness": 0.8684565434565434,
      "context_recall": 0.8704545454545455,
      "context_precision": 0.7105555555161039,
      "answer_correctness": 0.6891311953800833,
      "EM": 0.06363636363636363,
      "F1": 0.4890591784784581,
      "avg_retrieve_context": 0.08528189875862817,
      "avg_llm_response": 1.1670110008933328,
      "avg_total": 1.2522928996519613,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.7164875662123983,
      "faithfulness": 0.8900226757369614,
      "context_recall": 0.7976190476190477,
      "context_precision": 0.7825396824958862,
      "answer_correctness": 0.6544013345355422,
      "EM": 0.0,
      "F1": 0.3336968779200401,
      "avg_retrieve_context": 0.08528189875862816,
      "avg_llm_response": 1.507661501566569,
      "avg_total": 1.5929434003251974,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7109297782615891,
      "faithfulness": 0.8274161735700196,
      "context_recall": 0.7692307692307693,
      "context_precision": 0.8282051281602456,
      "answer_correctness": 0.5703461713457721,
      "EM": 0.0,
      "F1": 0.49322034284656274,
      "avg_retrieve_context": 0.08528189875862814,
      "avg_llm_response": 1.6008824568528395,
      "avg_total": 1.6861643556114672,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7796716299425718,
      "faithfulness": 0.8194444444444443,
      "context_recall": 0.9166666666666666,
      "context_precision": 0.7861111110617592,
      "answer_correctness": 0.6779811291545467,
      "EM": 0.0,
      "F1": 0.41802885253734456,
      "avg_retrieve_context": 0.08528189875862814,
      "avg_llm_response": 0.715621829032898,
      "avg_total": 0.8009037277915262,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.7415112416971662,
      "faithfulness": 0.8571428571428571,
      "context_recall": 1.0,
      "context_precision": 0.863492063443806,
      "answer_correctness": 0.6494404226519797,
      "EM": 0.0,
      "F1": 0.49271864490300205,
      "avg_retrieve_context": 0.08528189875862814,
      "avg_llm_response": 0.9386960778917585,
      "avg_total": 1.023977976650387,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.44701140602254896,
      "faithfulness": 0.75,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.4749999999777083,
      "answer_correctness": 0.5588602425155575,
      "EM": 0.0,
      "F1": 0.20217740558715558,
      "avg_retrieve_context": 0.08528189875862814,
      "avg_llm_response": 0.6612626711527506,
      "avg_total": 0.7465445699113787,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.7362245861097451,
      "faithfulness": 0.9,
      "context_recall": 0.8,
      "context_precision": 0.606666666613,
      "answer_correctness": 0.6554467171245018,
      "EM": 0.0,
      "F1": 0.5022105109061631,
      "avg_retrieve_context": 0.08528189875862816,
      "avg_llm_response": 1.4202581882476806,
      "avg_total": 1.505540087006309,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.8330189595400728,
      "faithfulness": 0.9375,
      "context_recall": 1.0,
      "context_precision": 0.956249999953698,
      "answer_correctness": 0.7571700953770627,
      "EM": 0.0,
      "F1": 0.46112525900900186,
      "avg_retrieve_context": 0.08528189875862816,
      "avg_llm_response": 0.9526542723178864,
      "avg_total": 1.0379361710765145,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.9804005706386506,
      "faithfulness": 0.875,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.740740740695216,
      "answer_correctness": 0.6686528082105087,
      "EM": 0.0,
      "F1": 0.6234134466811296,
      "avg_retrieve_context": 0.08528189875862814,
      "avg_llm_response": 0.8238866726557413,
      "avg_total": 0.9091685714143697,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.967975048618911,
      "faithfulness": 1.0,
      "context_recall": 0.75,
      "context_precision": 0.6259259259005711,
      "answer_correctness": 0.7918812528679556,
      "EM": 0.0,
      "F1": 0.5281599724963569,
      "avg_retrieve_context": 0.08528189875862814,
      "avg_llm_response": 2.0223352114359536,
      "avg_total": 2.107617110194582,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.6834222821864183,
      "faithfulness": 1.0,
      "context_recall": 0.875,
      "context_precision": 0.9124999999553125,
      "answer_correctness": 0.5833746091900087,
      "EM": 0.0,
      "F1": 0.4408169350029816,
      "avg_retrieve_context": 0.08528189875862816,
      "avg_llm_response": 0.733785092830658,
      "avg_total": 0.8190669915892861,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.9572447684457165,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.8796296295808642,
      "answer_correctness": 0.9223650851800023,
      "EM": 0.0,
      "F1": 0.6416805416805417,
      "avg_retrieve_context": 0.08528189875862817,
      "avg_llm_response": 2.0221242109934487,
      "avg_total": 2.1074061097520773,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9569551847525206,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.7083333333104167,
      "answer_correctness": 0.73878169105524,
      "EM": 0.0,
      "F1": 0.3925339366515837,
      "avg_retrieve_context": 0.08528189875862816,
      "avg_llm_response": 0.9116835594177246,
      "avg_total": 0.9969654581763527,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.0,
      "faithfulness": 0.75,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.9390446527471793,
      "EM": 0.7,
      "F1": 0.9666666666666668,
      "avg_retrieve_context": 0.08528189875862816,
      "avg_llm_response": 0.7577327013015747,
      "avg_total": 0.8430146000602029,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7337590491822036,
      "faithfulness": 0.8546703296703296,
      "context_recall": 0.8625,
      "context_precision": 0.8120370369908533,
      "answer_correctness": 0.6397477953287286,
      "EM": 0.0,
      "F1": 0.42223176920693867,
      "avg_retrieve_context": 0.08528189875862817,
      "avg_llm_response": 1.2366928418477376,
      "avg_total": 1.3219747406063656,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.8059232640534457,
      "faithfulness": 0.91875,
      "context_recall": 0.875,
      "context_precision": 0.7359722221830058,
      "answer_correctness": 0.7007279311153416,
      "EM": 0.0,
      "F1": 0.469898420338685,
      "avg_retrieve_context": 0.08528189875862816,
      "avg_llm_response": 1.164807814359665,
      "avg_total": 1.250089713118293,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.0,
      "faithfulness": 0.75,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.9390446527471793,
      "EM": 0.7,
      "F1": 0.9666666666666668,
      "avg_retrieve_context": 0.08528189875862816,
      "avg_llm_response": 0.7577327013015747,
      "avg_total": 0.8430146000602029,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.0,
      "faithfulness": 0.75,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.9390446527471793,
      "EM": 0.7,
      "F1": 0.9666666666666668,
      "avg_retrieve_context": 0.08528189875862816,
      "avg_llm_response": 0.7577327013015747,
      "avg_total": 0.8430146000602029,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7979779889214083,
      "faithfulness": 0.8920118343195268,
      "context_recall": 0.8882783882783883,
      "context_precision": 0.7692918192477407,
      "answer_correctness": 0.678804149683666,
      "EM": 0.0,
      "F1": 0.4640006473014421,
      "avg_retrieve_context": 0.08528189875862816,
      "avg_llm_response": 1.1649164681906228,
      "avg_total": 1.2501983669492511,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.4051640579135437,
      "faithfulness": 0.761904761904762,
      "context_recall": 0.6574074074074073,
      "context_precision": 0.9061728394696709,
      "answer_correctness": 0.5158674825693063,
      "EM": 0.0,
      "F1": 0.21175378461472139,
      "avg_retrieve_context": 0.08528189875862816,
      "avg_llm_response": 1.6429427199893527,
      "avg_total": 1.7282246187479813,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7835602071268278,
      "faithfulness": 0.9021876271876272,
      "context_recall": 0.8712962962962963,
      "context_precision": 0.7828395061293794,
      "answer_correctness": 0.6846133686355352,
      "EM": 0.0,
      "F1": 0.4601998255385191,
      "avg_retrieve_context": 0.08528189875862814,
      "avg_llm_response": 1.2517286194695367,
      "avg_total": 1.337010518228165,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.2871027435827765,
      "faithfulness": 0.7166666666666666,
      "context_recall": 0.8666666666666666,
      "context_precision": 0.38527777775636574,
      "answer_correctness": 0.7094614157305491,
      "EM": 0.35,
      "F1": 0.6189262667081834,
      "avg_retrieve_context": 0.08528189875862816,
      "avg_llm_response": 0.785781717300415,
      "avg_total": 0.871063616059043,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 10,
  "negative_rejection_percentage": 100.0
}