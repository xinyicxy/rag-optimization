{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.672900958476294,
      "faithfulness": 0.8304112554112555,
      "context_recall": 0.8075757575757576,
      "context_precision": 0.759090909035,
      "answer_correctness": 0.6554612984790466,
      "EM": 0.07272727272727272,
      "F1": 0.45349945717116685,
      "avg_retrieve_context": 0.05880879055369983,
      "avg_llm_response": 1.2306413542140613,
      "avg_total": 1.2894501447677618,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.7077140346908246,
      "faithfulness": 0.8492063492063492,
      "context_recall": 0.6587301587301587,
      "context_precision": 0.8333333332785713,
      "answer_correctness": 0.5841498302591932,
      "EM": 0.0,
      "F1": 0.2961992139413733,
      "avg_retrieve_context": 0.05880879055369984,
      "avg_llm_response": 1.4439092477162678,
      "avg_total": 1.5027180382699672,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.577334568423133,
      "faithfulness": 0.7252747252747253,
      "context_recall": 0.8461538461538461,
      "context_precision": 0.9230769230153845,
      "answer_correctness": 0.5502341122572562,
      "EM": 0.07692307692307693,
      "F1": 0.42048946983503566,
      "avg_retrieve_context": 0.058808790553699836,
      "avg_llm_response": 1.4585835383488581,
      "avg_total": 1.517392328902558,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.6284281849448404,
      "faithfulness": 0.8055555555555555,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.7916666666,
      "answer_correctness": 0.625937700754212,
      "EM": 0.0,
      "F1": 0.35575240679864595,
      "avg_retrieve_context": 0.058808790553699836,
      "avg_llm_response": 1.0001277724901836,
      "avg_total": 1.0589365630438834,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.6658198248403054,
      "faithfulness": 0.8333333333333333,
      "context_recall": 0.8214285714285714,
      "context_precision": 0.8214285713571429,
      "answer_correctness": 0.6443424615955867,
      "EM": 0.07142857142857142,
      "F1": 0.44878883338531345,
      "avg_retrieve_context": 0.05880879055369983,
      "avg_llm_response": 1.2124271392822266,
      "avg_total": 1.2712359298359261,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.6370942625442992,
      "faithfulness": 0.7916666666666666,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.666666666625,
      "answer_correctness": 0.6785510412177631,
      "EM": 0.0,
      "F1": 0.38973813438929716,
      "avg_retrieve_context": 0.05880879055369984,
      "avg_llm_response": 0.7632484436035156,
      "avg_total": 0.8220572341572154,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.7500121570368818,
      "faithfulness": 0.9,
      "context_recall": 0.8,
      "context_precision": 0.89999999993,
      "answer_correctness": 0.5894925584117109,
      "EM": 0.0,
      "F1": 0.4208046855105678,
      "avg_retrieve_context": 0.05880879055369984,
      "avg_llm_response": 1.1542314052581788,
      "avg_total": 1.2130401958118786,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.8323872589450307,
      "faithfulness": 0.9375,
      "context_recall": 1.0,
      "context_precision": 0.999999999925,
      "answer_correctness": 0.6835190074845818,
      "EM": 0.0,
      "F1": 0.47341648652231266,
      "avg_retrieve_context": 0.05880879055369984,
      "avg_llm_response": 1.2811204493045807,
      "avg_total": 1.3399292398582805,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.960567995115276,
      "faithfulness": 0.861111111111111,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.7499999999416667,
      "answer_correctness": 0.7207584111871798,
      "EM": 0.0,
      "F1": 0.6340135576038619,
      "avg_retrieve_context": 0.05880879055369984,
      "avg_llm_response": 0.7289243936538696,
      "avg_total": 0.7877331842075694,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9589384593940089,
      "faithfulness": 1.0,
      "context_recall": 0.75,
      "context_precision": 0.6666666666166666,
      "answer_correctness": 0.7304513615828919,
      "EM": 0.0,
      "F1": 0.5399748028324048,
      "avg_retrieve_context": 0.05880879055369984,
      "avg_llm_response": 2.146554152170817,
      "avg_total": 2.2053629427245167,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.6554144351280471,
      "faithfulness": 0.8333333333333333,
      "context_recall": 1.0,
      "context_precision": 0.9999999999375,
      "answer_correctness": 0.8106393706987282,
      "EM": 0.0,
      "F1": 0.5356691919191919,
      "avg_retrieve_context": 0.05880879055369984,
      "avg_llm_response": 0.9595640301704407,
      "avg_total": 1.0183728207241405,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.9143853016777465,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.8333333332666667,
      "answer_correctness": 0.9529625496081975,
      "EM": 0.0,
      "F1": 0.5857030672127889,
      "avg_retrieve_context": 0.05880879055369984,
      "avg_llm_response": 1.7305816809336345,
      "avg_total": 1.7893904714873343,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9855536122071181,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.74999999995,
      "answer_correctness": 0.7876101683700348,
      "EM": 0.0,
      "F1": 0.34752155172413796,
      "avg_retrieve_context": 0.05880879055369984,
      "avg_llm_response": 0.9677590131759644,
      "avg_total": 1.0265678037296642,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.17044615182561182,
      "faithfulness": 0.65,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.727766086229719,
      "EM": 0.6,
      "F1": 0.7777777777777779,
      "avg_retrieve_context": 0.05880879055369984,
      "avg_llm_response": 0.829335379600525,
      "avg_total": 0.8881441701542248,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.65383266475184,
      "faithfulness": 0.8099206349206349,
      "context_recall": 0.7722222222222221,
      "context_precision": 0.8416666666041667,
      "answer_correctness": 0.5992039461029357,
      "EM": 0.03333333333333333,
      "F1": 0.3706436524933741,
      "avg_retrieve_context": 0.05880879055369984,
      "avg_llm_response": 1.3043198903401694,
      "avg_total": 1.363128680893869,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.8271171007256456,
      "faithfulness": 0.90625,
      "context_recall": 0.8625,
      "context_precision": 0.82499999994,
      "answer_correctness": 0.7217711301055448,
      "EM": 0.0,
      "F1": 0.4967135840362033,
      "avg_retrieve_context": 0.05880879055369984,
      "avg_llm_response": 1.2204500436782837,
      "avg_total": 1.2792588342319835,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.17044615182561182,
      "faithfulness": 0.65,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.727766086229719,
      "EM": 0.6,
      "F1": 0.7777777777777779,
      "avg_retrieve_context": 0.05880879055369984,
      "avg_llm_response": 0.829335379600525,
      "avg_total": 0.8881441701542248,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.17044615182561182,
      "faithfulness": 0.65,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.727766086229719,
      "EM": 0.6,
      "F1": 0.7777777777777779,
      "avg_retrieve_context": 0.05880879055369984,
      "avg_llm_response": 0.829335379600525,
      "avg_total": 0.8881441701542248,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7448024128507691,
      "faithfulness": 0.8591051805337518,
      "context_recall": 0.8333333333333335,
      "context_precision": 0.8241758241137364,
      "answer_correctness": 0.6636012012480417,
      "EM": 0.02197802197802198,
      "F1": 0.44102152353935636,
      "avg_retrieve_context": 0.058808790553699836,
      "avg_llm_response": 1.244638503252805,
      "avg_total": 1.303447293806505,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.5041804827462469,
      "faithfulness": 0.7407407407407407,
      "context_recall": 0.5555555555555556,
      "context_precision": 0.9444444443888889,
      "answer_correctness": 0.49281918409179326,
      "EM": 0.0,
      "F1": 0.21935598544101695,
      "avg_retrieve_context": 0.05880879055369984,
      "avg_llm_response": 1.5350101523929172,
      "avg_total": 1.593818942946617,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7415137560187153,
      "faithfulness": 0.8630952380952379,
      "context_recall": 0.8166666666666667,
      "context_precision": 0.8333333332711111,
      "answer_correctness": 0.6619629518491795,
      "EM": 0.022222222222222223,
      "F1": 0.4333283660076029,
      "avg_retrieve_context": 0.058808790553699836,
      "avg_llm_response": 1.3282701280381946,
      "avg_total": 1.3870789185918941,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.3641433695353982,
      "faithfulness": 0.6833333333333333,
      "context_recall": 0.7666666666666666,
      "context_precision": 0.42499999997250004,
      "answer_correctness": 0.6262038583134479,
      "EM": 0.3,
      "F1": 0.5442693674072049,
      "avg_retrieve_context": 0.05880879055369984,
      "avg_llm_response": 0.7913118720054626,
      "avg_total": 0.8501206625591626,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 8,
  "negative_rejection_percentage": 80.0
}