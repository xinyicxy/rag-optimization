{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.678647943888458,
      "faithfulness": 0.828801652892562,
      "context_recall": 0.8396969696969697,
      "context_precision": 0.6766644033558556,
      "answer_correctness": 0.6097642027533051,
      "EM": 0.08181818181818182,
      "F1": 0.44469176468059485,
      "avg_retrieve_context": 0.05600811134685171,
      "avg_llm_response": 1.2744528943842108,
      "avg_total": 1.330461005731062,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.7647321998589399,
      "faithfulness": 0.8333333333333334,
      "context_recall": 0.6999999999999998,
      "context_precision": 0.7724516790530086,
      "answer_correctness": 0.5413459545007008,
      "EM": 0.0,
      "F1": 0.30786300214917195,
      "avg_retrieve_context": 0.05600811134685171,
      "avg_llm_response": 1.3970709414709181,
      "avg_total": 1.45307905281777,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.5781069049336326,
      "faithfulness": 0.7296037296037295,
      "context_recall": 0.8461538461538461,
      "context_precision": 0.8464133088654346,
      "answer_correctness": 0.601435660026352,
      "EM": 0.07692307692307693,
      "F1": 0.4792008867701832,
      "avg_retrieve_context": 0.05600811134685169,
      "avg_llm_response": 1.4532941488119273,
      "avg_total": 1.5093022601587789,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7205830659947726,
      "faithfulness": 0.9166666666666666,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.6574735449379049,
      "answer_correctness": 0.5974787838424266,
      "EM": 0.0,
      "F1": 0.38673166917941587,
      "avg_retrieve_context": 0.05600811134685169,
      "avg_llm_response": 0.7719056407610575,
      "avg_total": 0.8279137521079094,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.7316396654823069,
      "faithfulness": 0.880952380952381,
      "context_recall": 0.7142857142857143,
      "context_precision": 0.6475396825075231,
      "answer_correctness": 0.4968810839692764,
      "EM": 0.0,
      "F1": 0.44438974895211425,
      "avg_retrieve_context": 0.05600811134685169,
      "avg_llm_response": 0.9994970730372837,
      "avg_total": 1.0555051843841359,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.6370942625442992,
      "faithfulness": 0.875,
      "context_recall": 1.0,
      "context_precision": 0.6015873015595371,
      "answer_correctness": 0.6362358893284009,
      "EM": 0.0,
      "F1": 0.3873138919650548,
      "avg_retrieve_context": 0.05600811134685169,
      "avg_llm_response": 0.6510657469431559,
      "avg_total": 0.7070738582900077,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.7324959607473153,
      "faithfulness": 0.9,
      "context_recall": 0.8,
      "context_precision": 0.539999999963,
      "answer_correctness": 0.4166495277183273,
      "EM": 0.0,
      "F1": 0.26449299719887953,
      "avg_retrieve_context": 0.0560081113468517,
      "avg_llm_response": 2.5704389095306395,
      "avg_total": 2.6264470208774915,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.84194597251055,
      "faithfulness": 0.875,
      "context_recall": 1.0,
      "context_precision": 0.8612578537993804,
      "answer_correctness": 0.7911729577354456,
      "EM": 0.0,
      "F1": 0.48312239220401787,
      "avg_retrieve_context": 0.05600811134685169,
      "avg_llm_response": 1.2257153689861298,
      "avg_total": 1.2817234803329813,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.796646705625581,
      "faithfulness": 0.6666666666666666,
      "context_recall": 1.0,
      "context_precision": 0.9274518139998945,
      "answer_correctness": 0.5470119219647691,
      "EM": 0.0,
      "F1": 0.5008443481094252,
      "avg_retrieve_context": 0.05600811134685169,
      "avg_llm_response": 1.2995485067367554,
      "avg_total": 1.3555566180836074,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9536284369986504,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.8096891534186742,
      "answer_correctness": 0.6997051051566329,
      "EM": 0.0,
      "F1": 0.4654069704379302,
      "avg_retrieve_context": 0.05600811134685169,
      "avg_llm_response": 1.8563752969106038,
      "avg_total": 1.9123834082574558,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.48011551184901835,
      "faithfulness": 0.6083333333333334,
      "context_recall": 0.75,
      "context_precision": 0.683333333310625,
      "answer_correctness": 0.4414744819186992,
      "EM": 0.0,
      "F1": 0.2593368667570566,
      "avg_retrieve_context": 0.05600811134685169,
      "avg_llm_response": 1.4375412464141846,
      "avg_total": 1.4935493577610361,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.9141839578445125,
      "faithfulness": 0.8888888888888888,
      "context_recall": 0.8888888888888888,
      "context_precision": 0.7916666666377314,
      "answer_correctness": 0.7671730673426985,
      "EM": 0.0,
      "F1": 0.5315915300546448,
      "avg_retrieve_context": 0.05600811134685169,
      "avg_llm_response": 2.0560328165690103,
      "avg_total": 2.1120409279158623,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9571576564836395,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.7611111110928703,
      "answer_correctness": 0.6637310087437023,
      "EM": 0.0,
      "F1": 0.264638346727899,
      "avg_retrieve_context": 0.05600811134685169,
      "avg_llm_response": 1.5200490951538086,
      "avg_total": 1.5760572065006604,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.08869625091367915,
      "faithfulness": 0.7,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8655825149962993,
      "EM": 0.8,
      "F1": 0.888888888888889,
      "avg_retrieve_context": 0.0560081113468517,
      "avg_llm_response": 0.824446153640747,
      "avg_total": 0.8804542649875987,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7077453011644088,
      "faithfulness": 0.8386363636363635,
      "context_recall": 0.7616666666666667,
      "context_precision": 0.7363349394954003,
      "answer_correctness": 0.5552168201089381,
      "EM": 0.016666666666666666,
      "F1": 0.39261618481045973,
      "avg_retrieve_context": 0.056008111346851686,
      "avg_llm_response": 1.1914523402849833,
      "avg_total": 1.2474604516318355,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.7824898312182261,
      "faithfulness": 0.8462500000000001,
      "context_recall": 0.9416666666666667,
      "context_precision": 0.7563246999855029,
      "answer_correctness": 0.6276306986591079,
      "EM": 0.0,
      "F1": 0.411755853433724,
      "avg_retrieve_context": 0.0560081113468517,
      "avg_llm_response": 1.5114554107189178,
      "avg_total": 1.5674635220657698,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.08869625091367915,
      "faithfulness": 0.7,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8655825149962993,
      "EM": 0.8,
      "F1": 0.888888888888889,
      "avg_retrieve_context": 0.0560081113468517,
      "avg_llm_response": 0.824446153640747,
      "avg_total": 0.8804542649875987,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.08869625091367915,
      "faithfulness": 0.7,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8655825149962993,
      "EM": 0.8,
      "F1": 0.888888888888889,
      "avg_retrieve_context": 0.0560081113468517,
      "avg_llm_response": 0.824446153640747,
      "avg_total": 0.8804542649875987,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7501650831134798,
      "faithfulness": 0.8480019980019979,
      "context_recall": 0.8479853479853481,
      "context_precision": 0.7422956120426579,
      "answer_correctness": 0.5957247129606907,
      "EM": 0.01098901098901099,
      "F1": 0.4158759471685475,
      "avg_retrieve_context": 0.056008111346851706,
      "avg_llm_response": 1.3058888938400772,
      "avg_total": 1.361897005186929,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.6110320839185448,
      "faithfulness": 0.7777777777777778,
      "context_recall": 0.6888888888888888,
      "context_precision": 0.7649092970291386,
      "answer_correctness": 0.4674764748308598,
      "EM": 0.0,
      "F1": 0.24249933707096993,
      "avg_retrieve_context": 0.0560081113468517,
      "avg_llm_response": 1.456607500712077,
      "avg_total": 1.512615612058929,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7344278985560776,
      "faithfulness": 0.8546464646464647,
      "context_recall": 0.8337037037037037,
      "context_precision": 0.7414566693609815,
      "answer_correctness": 0.5877785701233031,
      "EM": 0.011111111111111112,
      "F1": 0.40838286819555925,
      "avg_retrieve_context": 0.0560081113468517,
      "avg_llm_response": 1.3573982106314766,
      "avg_total": 1.4134063219783284,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.4276381478841693,
      "faithfulness": 0.7125,
      "context_recall": 0.8666666666666666,
      "context_precision": 0.3850992063327892,
      "answer_correctness": 0.7086995495883154,
      "EM": 0.4,
      "F1": 0.6080817988632552,
      "avg_retrieve_context": 0.056008111346851706,
      "avg_llm_response": 0.9011989712715149,
      "avg_total": 0.9572070826183665,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 0,
  "negative_rejection_percentage": 0.0
}