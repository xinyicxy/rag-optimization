{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6821695048023723,
      "faithfulness": 0.8014679260133805,
      "context_recall": 0.7575757575757576,
      "context_precision": 0.7545454544872727,
      "answer_correctness": 0.6363640819823975,
      "EM": 0.06363636363636363,
      "F1": 0.4483182919377851,
      "avg_retrieve_context": 0.061954814737493334,
      "avg_llm_response": 1.16972918510437,
      "avg_total": 1.231683999841864,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.6776790673208491,
      "faithfulness": 0.8036075036075035,
      "context_recall": 0.6111111111111112,
      "context_precision": 0.8333333332666667,
      "answer_correctness": 0.6056389837584871,
      "EM": 0.0,
      "F1": 0.29906324387908406,
      "avg_retrieve_context": 0.061954814737493334,
      "avg_llm_response": 1.4364863690875826,
      "avg_total": 1.4984411838250762,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.715949993885009,
      "faithfulness": 0.7252747252747253,
      "context_recall": 0.7307692307692307,
      "context_precision": 0.9230769230038463,
      "answer_correctness": 0.6509381516531665,
      "EM": 0.07692307692307693,
      "F1": 0.4449957534766383,
      "avg_retrieve_context": 0.06195481473749333,
      "avg_llm_response": 1.968183627495399,
      "avg_total": 2.0301384422328925,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7253070867598637,
      "faithfulness": 0.8333333333333334,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.8749999999333333,
      "answer_correctness": 0.6438891060788529,
      "EM": 0.0,
      "F1": 0.36443250741801086,
      "avg_retrieve_context": 0.061954814737493334,
      "avg_llm_response": 0.7418667475382487,
      "avg_total": 0.8038215622757421,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.8653958989359128,
      "faithfulness": 0.9047619047619048,
      "context_recall": 0.9285714285714286,
      "context_precision": 0.8571428570821427,
      "answer_correctness": 0.6605027453544933,
      "EM": 0.07142857142857142,
      "F1": 0.597889056744249,
      "avg_retrieve_context": 0.06195481473749333,
      "avg_llm_response": 1.0544412646974837,
      "avg_total": 1.1163960794349772,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.3063583319214786,
      "faithfulness": 0.5833333333333334,
      "context_recall": 0.5,
      "context_precision": 0.6666666666166666,
      "answer_correctness": 0.4265935294752463,
      "EM": 0.0,
      "F1": 0.16874572051042638,
      "avg_retrieve_context": 0.061954814737493334,
      "avg_llm_response": 0.5079580148061117,
      "avg_total": 0.569912829543605,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.5530647378365725,
      "faithfulness": 0.7,
      "context_recall": 0.6,
      "context_precision": 0.59999999994,
      "answer_correctness": 0.42884020681849117,
      "EM": 0.0,
      "F1": 0.3193061840120664,
      "avg_retrieve_context": 0.061954814737493334,
      "avg_llm_response": 1.2956705570220948,
      "avg_total": 1.357625371759588,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.7007540680980222,
      "faithfulness": 0.875,
      "context_recall": 1.0,
      "context_precision": 0.99999999993125,
      "answer_correctness": 0.6571076014472906,
      "EM": 0.0,
      "F1": 0.39296328671328673,
      "avg_retrieve_context": 0.06195481473749334,
      "avg_llm_response": 0.9727796614170074,
      "avg_total": 1.0347344761545008,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.9665208469320753,
      "faithfulness": 0.8055555555555557,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.7499999999333333,
      "answer_correctness": 0.6347171343365823,
      "EM": 0.0,
      "F1": 0.6357879874008906,
      "avg_retrieve_context": 0.061954814737493334,
      "avg_llm_response": 0.6462365786234537,
      "avg_total": 0.7081913933609472,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.7906802882992845,
      "faithfulness": 0.8333333333333334,
      "context_recall": 0.5833333333333334,
      "context_precision": 0.6666666666166666,
      "answer_correctness": 0.528880673775937,
      "EM": 0.0,
      "F1": 0.4583686627804275,
      "avg_retrieve_context": 0.061954814737493334,
      "avg_llm_response": 1.536359469095866,
      "avg_total": 1.5983142838333595,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.927605568029427,
      "faithfulness": 0.875,
      "context_recall": 0.875,
      "context_precision": 0.999999999925,
      "answer_correctness": 0.7157885293909415,
      "EM": 0.0,
      "F1": 0.5532411774272239,
      "avg_retrieve_context": 0.06195481473749334,
      "avg_llm_response": 0.8664079308509827,
      "avg_total": 0.928362745588476,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.8965828869401903,
      "faithfulness": 0.9523809523809524,
      "context_recall": 1.0,
      "context_precision": 0.8333333332666667,
      "answer_correctness": 0.9533501695972556,
      "EM": 0.0,
      "F1": 0.5672076989906447,
      "avg_retrieve_context": 0.06195481473749334,
      "avg_llm_response": 1.8156283696492512,
      "avg_total": 1.8775831843867448,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9102869446011597,
      "faithfulness": 1.0,
      "context_recall": 0.5,
      "context_precision": 0.499999999975,
      "answer_correctness": 0.5384681296672906,
      "EM": 0.0,
      "F1": 0.3035982008995502,
      "avg_retrieve_context": 0.06195481473749334,
      "avg_llm_response": 1.2306386232376099,
      "avg_total": 1.2925934379751032,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.1707349708772178,
      "faithfulness": 0.7,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.8103375922847702,
      "EM": 0.5,
      "F1": 0.7666666666666666,
      "avg_retrieve_context": 0.061954814737493334,
      "avg_llm_response": 0.7475322246551513,
      "avg_total": 0.8094870393926448,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7392972993410681,
      "faithfulness": 0.8161832611832611,
      "context_recall": 0.7555555555555554,
      "context_precision": 0.8666666665999999,
      "answer_correctness": 0.6359053723054756,
      "EM": 0.03333333333333333,
      "F1": 0.41348183000154476,
      "avg_retrieve_context": 0.06195481473749334,
      "avg_llm_response": 1.3236196597417196,
      "avg_total": 1.385574474479213,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.7243364464756168,
      "faithfulness": 0.8047619047619048,
      "context_recall": 0.75,
      "context_precision": 0.77499999994,
      "answer_correctness": 0.5935587689221873,
      "EM": 0.0,
      "F1": 0.4209858911599255,
      "avg_retrieve_context": 0.061954814737493334,
      "avg_llm_response": 1.0444427132606506,
      "avg_total": 1.1063975279981442,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.1707349708772178,
      "faithfulness": 0.7,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.8103375922847702,
      "EM": 0.5,
      "F1": 0.7666666666666666,
      "avg_retrieve_context": 0.061954814737493334,
      "avg_llm_response": 0.7475322246551513,
      "avg_total": 0.8094870393926448,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.1707349708772178,
      "faithfulness": 0.7,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.8103375922847702,
      "EM": 0.5,
      "F1": 0.7666666666666666,
      "avg_retrieve_context": 0.061954814737493334,
      "avg_llm_response": 0.7475322246551513,
      "avg_total": 0.8094870393926448,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7553831010280594,
      "faithfulness": 0.8159602302459444,
      "context_recall": 0.7875457875457876,
      "context_precision": 0.8131868131230771,
      "answer_correctness": 0.6290107524949949,
      "EM": 0.02197802197802198,
      "F1": 0.4335189212490186,
      "avg_retrieve_context": 0.06195481473749333,
      "avg_llm_response": 1.1884020868238512,
      "avg_total": 1.2503569015613447,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.5101592917705945,
      "faithfulness": 0.7676767676767677,
      "context_recall": 0.4074074074074074,
      "context_precision": 0.9999999999333333,
      "answer_correctness": 0.5174105131301654,
      "EM": 0.0,
      "F1": 0.24423595698100073,
      "avg_retrieve_context": 0.06195481473749334,
      "avg_llm_response": 1.4500331348843045,
      "avg_total": 1.511987949621798,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7503002377965697,
      "faithfulness": 0.8268783068783069,
      "context_recall": 0.7555555555555555,
      "context_precision": 0.8222222221588891,
      "answer_correctness": 0.6325035001754421,
      "EM": 0.022222222222222223,
      "F1": 0.432728989506261,
      "avg_retrieve_context": 0.06195481473749333,
      "avg_llm_response": 1.2457433038287693,
      "avg_total": 1.3076981185662626,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.37558120632848374,
      "faithfulness": 0.6871212121212121,
      "context_recall": 0.7666666666666666,
      "context_precision": 0.449999999965,
      "answer_correctness": 0.653736700113697,
      "EM": 0.25,
      "F1": 0.518470152879644,
      "avg_retrieve_context": 0.061954814737493334,
      "avg_llm_response": 0.827665650844574,
      "avg_total": 0.8896204655820673,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 8,
  "negative_rejection_percentage": 80.0
}