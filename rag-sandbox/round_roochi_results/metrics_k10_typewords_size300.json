{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.7005890054342447,
      "faithfulness": 0.8029083038173948,
      "context_recall": 0.9393939393939393,
      "context_precision": 0.7133124870834437,
      "answer_correctness": 0.7071584710679069,
      "EM": 0.07272727272727272,
      "F1": 0.5141803307226023,
      "avg_retrieve_context": 0.05698559067466043,
      "avg_llm_response": 1.330225851319053,
      "avg_total": 1.3872114419937132,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.714067189756524,
      "faithfulness": 0.8756613756613757,
      "context_recall": 0.896825396825397,
      "context_precision": 0.742948250702679,
      "answer_correctness": 0.6227612022463277,
      "EM": 0.0,
      "F1": 0.3229300284879329,
      "avg_retrieve_context": 0.056985590674660414,
      "avg_llm_response": 1.7003547691163563,
      "avg_total": 1.757340359791017,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.719020505599241,
      "faithfulness": 0.7127039627039627,
      "context_recall": 0.9230769230769231,
      "context_precision": 0.798045961943857,
      "answer_correctness": 0.6651668790409898,
      "EM": 0.0,
      "F1": 0.5520424607274204,
      "avg_retrieve_context": 0.056985590674660434,
      "avg_llm_response": 1.5692179753230169,
      "avg_total": 1.6262035659976772,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7196434074470716,
      "faithfulness": 0.861111111111111,
      "context_recall": 1.0,
      "context_precision": 0.7242724867250815,
      "answer_correctness": 0.7063677292638774,
      "EM": 0.0,
      "F1": 0.40637170530869077,
      "avg_retrieve_context": 0.056985590674660434,
      "avg_llm_response": 1.2498266696929932,
      "avg_total": 1.3068122603676535,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.7378970643999752,
      "faithfulness": 0.8364512471655329,
      "context_recall": 1.0,
      "context_precision": 0.777560738537843,
      "answer_correctness": 0.6789513917194739,
      "EM": 0.07142857142857142,
      "F1": 0.5601036266159733,
      "avg_retrieve_context": 0.056985590674660434,
      "avg_llm_response": 1.1675823756626673,
      "avg_total": 1.2245679663373277,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.8034804572583817,
      "faithfulness": 0.638888888888889,
      "context_recall": 1.0,
      "context_precision": 0.6964616401897968,
      "answer_correctness": 0.8118751194866318,
      "EM": 0.0,
      "F1": 0.5253770097380646,
      "avg_retrieve_context": 0.05698559067466042,
      "avg_llm_response": 1.0396761099497478,
      "avg_total": 1.0966617006244082,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.9552125632921399,
      "faithfulness": 0.58,
      "context_recall": 1.0,
      "context_precision": 0.8399999999458888,
      "answer_correctness": 0.652346403038365,
      "EM": 0.0,
      "F1": 0.5063876449816191,
      "avg_retrieve_context": 0.05698559067466043,
      "avg_llm_response": 1.789104127883911,
      "avg_total": 1.8460897185585714,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.7110636616041881,
      "faithfulness": 0.875,
      "context_recall": 1.0,
      "context_precision": 0.9277565192361441,
      "answer_correctness": 0.6493055964106889,
      "EM": 0.0,
      "F1": 0.3912928848851009,
      "avg_retrieve_context": 0.05698559067466042,
      "avg_llm_response": 1.0205557644367218,
      "avg_total": 1.0775413551113822,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.9706546475964773,
      "faithfulness": 0.5833333333333334,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.7837962962493442,
      "answer_correctness": 0.6947860611069768,
      "EM": 0.0,
      "F1": 0.7091662141124506,
      "avg_retrieve_context": 0.05698559067466042,
      "avg_llm_response": 0.779167890548706,
      "avg_total": 0.8361534812233665,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.778908946897502,
      "faithfulness": 1.0,
      "context_recall": 0.9166666666666666,
      "context_precision": 0.7673941798769924,
      "answer_correctness": 0.5943727972156706,
      "EM": 0.0,
      "F1": 0.44656986156652434,
      "avg_retrieve_context": 0.05698559067466042,
      "avg_llm_response": 1.8797872463862102,
      "avg_total": 1.9367728370608706,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.8880820539310497,
      "faithfulness": 0.75,
      "context_recall": 1.0,
      "context_precision": 0.9833333332883475,
      "answer_correctness": 0.8628968282874014,
      "EM": 0.0,
      "F1": 0.5178992628992629,
      "avg_retrieve_context": 0.05698559067466042,
      "avg_llm_response": 1.2541980147361755,
      "avg_total": 1.311183605410836,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.8721347783407917,
      "faithfulness": 0.9629629629629629,
      "context_recall": 1.0,
      "context_precision": 0.8222222221725927,
      "answer_correctness": 0.9435130337260039,
      "EM": 0.0,
      "F1": 0.5534150906969523,
      "avg_retrieve_context": 0.05698559067466042,
      "avg_llm_response": 1.8108587265014648,
      "avg_total": 1.8678443171761252,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9021321392851662,
      "faithfulness": 0.75,
      "context_recall": 1.0,
      "context_precision": 0.7013888888675347,
      "answer_correctness": 0.7477947956191573,
      "EM": 0.0,
      "F1": 0.36818687430478314,
      "avg_retrieve_context": 0.05698559067466042,
      "avg_llm_response": 0.7668375968933105,
      "avg_total": 0.823823187567971,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.0,
      "faithfulness": 0.8,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.924044824862591,
      "EM": 0.7,
      "F1": 0.9666666666666666,
      "avg_retrieve_context": 0.05698559067466043,
      "avg_llm_response": 0.7588688850402832,
      "avg_total": 0.8158544757149435,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.721815955810694,
      "faithfulness": 0.8282948532948532,
      "context_recall": 0.9472222222222223,
      "context_precision": 0.7592271825042863,
      "answer_correctness": 0.6617814484990819,
      "EM": 0.016666666666666666,
      "F1": 0.4445998970671829,
      "avg_retrieve_context": 0.05698559067466042,
      "avg_llm_response": 1.4575226187705994,
      "avg_total": 1.5145082094452595,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.8438958312281318,
      "faithfulness": 0.7655555555555555,
      "context_recall": 0.9625,
      "context_precision": 0.822768565723041,
      "answer_correctness": 0.7210024164724735,
      "EM": 0.0,
      "F1": 0.5054293972197155,
      "avg_retrieve_context": 0.05698559067466043,
      "avg_llm_response": 1.2821199417114257,
      "avg_total": 1.339105532386086,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.0,
      "faithfulness": 0.8,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.924044824862591,
      "EM": 0.7,
      "F1": 0.9666666666666666,
      "avg_retrieve_context": 0.05698559067466043,
      "avg_llm_response": 0.7588688850402832,
      "avg_total": 0.8158544757149435,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.0,
      "faithfulness": 0.8,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.924044824862591,
      "EM": 0.7,
      "F1": 0.9666666666666666,
      "avg_retrieve_context": 0.05698559067466043,
      "avg_llm_response": 0.7588688850402832,
      "avg_total": 0.8158544757149435,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7975768168432287,
      "faithfulness": 0.8020503306217592,
      "context_recall": 0.9706959706959708,
      "context_precision": 0.7832216988983517,
      "answer_correctness": 0.7028090169469768,
      "EM": 0.01098901098901099,
      "F1": 0.49268962707542574,
      "avg_retrieve_context": 0.05698559067466043,
      "avg_llm_response": 1.3643197672707694,
      "avg_total": 1.4213053579454296,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.4983666961147898,
      "faithfulness": 0.8148148148148149,
      "context_recall": 0.7777777777777778,
      "context_precision": 0.7990221088254227,
      "answer_correctness": 0.5101514474076622,
      "EM": 0.0,
      "F1": 0.2287126276617599,
      "avg_retrieve_context": 0.05698559067466042,
      "avg_llm_response": 1.6203395525614421,
      "avg_total": 1.6773251432361025,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.8042248432188207,
      "faithfulness": 0.8072582972582972,
      "context_recall": 0.9555555555555556,
      "context_precision": 0.7843153501779891,
      "answer_correctness": 0.7050773956122772,
      "EM": 0.011111111111111112,
      "F1": 0.48630517394626227,
      "avg_retrieve_context": 0.05698559067466043,
      "avg_llm_response": 1.4401980426576402,
      "avg_total": 1.4971836333323005,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.23422773540365255,
      "faithfulness": 0.7833333333333333,
      "context_recall": 0.8666666666666666,
      "context_precision": 0.3937996031579899,
      "answer_correctness": 0.7165233106182407,
      "EM": 0.35,
      "F1": 0.6396185362161323,
      "avg_retrieve_context": 0.056985590674660414,
      "avg_llm_response": 0.8353509902954102,
      "avg_total": 0.8923365809700705,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 9,
  "negative_rejection_percentage": 90.0
}