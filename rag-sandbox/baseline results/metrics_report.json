{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.7565670869792457,
      "faithfulness": 0.7390753968253969,
      "context_recall": 0.5166666666666666,
      "context_precision": 0.6999999999299998,
      "answer_correctness": 0.5692513830403558,
      "EM": 0.01,
      "F1": 0.40473302307596165,
      "avg_retrieve_context": 0.09767278909683226,
      "avg_llm_response": 2.254844655990601,
      "avg_total": 2.352517445087433,
      "sample_size": 100
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.6876053898198415,
      "faithfulness": 0.8240740740740742,
      "context_recall": 0.34444444444444444,
      "context_precision": 0.7333333332599999,
      "answer_correctness": 0.4606431151839151,
      "EM": 0.0,
      "F1": 0.26879608555392515,
      "avg_retrieve_context": 0.09767278909683229,
      "avg_llm_response": 2.3987766106923423,
      "avg_total": 2.4964493997891752,
      "sample_size": 15
    },
    "infra_2": {
      "answer_relevancy": 0.907138911736083,
      "faithfulness": 0.75,
      "context_recall": 1.0,
      "context_precision": 0.9999999999,
      "answer_correctness": 0.5375990310814684,
      "EM": 0.0,
      "F1": 0.6186868686868687,
      "avg_retrieve_context": 0.09767278909683227,
      "avg_llm_response": 3.1776089668273926,
      "avg_total": 3.2752817559242247,
      "sample_size": 2
    },
    "infra_3": {
      "answer_relevancy": 0.9477090803413883,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.9999999999,
      "answer_correctness": 0.8373672413850841,
      "EM": 0.0,
      "F1": 0.5590039313242119,
      "avg_retrieve_context": 0.09767278909683227,
      "avg_llm_response": 2.1333931922912597,
      "avg_total": 2.231065981388092,
      "sample_size": 5
    },
    "infra_4": {
      "answer_relevancy": 0.5195782654312961,
      "faithfulness": 0.7083333333333334,
      "context_recall": 0.3611111111111111,
      "context_precision": 0.5555555555,
      "answer_correctness": 0.4706210328036702,
      "EM": 0.0,
      "F1": 0.37488378089100877,
      "avg_retrieve_context": 0.09767278909683227,
      "avg_llm_response": 1.9580651256773207,
      "avg_total": 2.055737914774153,
      "sample_size": 18
    },
    "natsec_1": {
      "answer_relevancy": 0.8458658453511886,
      "faithfulness": 0.59375,
      "context_recall": 0.625,
      "context_precision": 0.749999999925,
      "answer_correctness": 0.6434279388896325,
      "EM": 0.0,
      "F1": 0.3380841956502346,
      "avg_retrieve_context": 0.09767278909683227,
      "avg_llm_response": 2.0173453986644745,
      "avg_total": 2.115018187761307,
      "sample_size": 8
    },
    "natsec_2": {
      "answer_relevancy": 0.85065428755914,
      "faithfulness": 0.8375,
      "context_recall": 0.4,
      "context_precision": 0.69999999993,
      "answer_correctness": 0.483328392530741,
      "EM": 0.1,
      "F1": 0.4104770083038137,
      "avg_retrieve_context": 0.09767278909683227,
      "avg_llm_response": 2.8613866329193116,
      "avg_total": 2.9590594220161437,
      "sample_size": 10
    },
    "natsec_3": {
      "answer_relevancy": 0.6137864827508877,
      "faithfulness": 0.45,
      "context_recall": 0.125,
      "context_precision": 0.6249999999375,
      "answer_correctness": 0.5241075104594548,
      "EM": 0.0,
      "F1": 0.3559763578206201,
      "avg_retrieve_context": 0.09767278909683227,
      "avg_llm_response": 1.8358922004699707,
      "avg_total": 1.9335649895668028,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.7797257201937572,
      "faithfulness": 0.8197278911564625,
      "context_recall": 0.42857142857142855,
      "context_precision": 0.42857142852857144,
      "answer_correctness": 0.5168709219444617,
      "EM": 0.0,
      "F1": 0.42417786891471104,
      "avg_retrieve_context": 0.09767278909683229,
      "avg_llm_response": 1.5277344499315535,
      "avg_total": 1.6254072390283856,
      "sample_size": 7
    },
    "natsec_5": {
      "answer_relevancy": 0.8310983798438685,
      "faithfulness": 0.9375,
      "context_recall": 0.75,
      "context_precision": 0.9999999999,
      "answer_correctness": 0.6641094676782998,
      "EM": 0.0,
      "F1": 0.5815443894377691,
      "avg_retrieve_context": 0.09767278909683227,
      "avg_llm_response": 2.035153806209564,
      "avg_total": 2.1328265953063963,
      "sample_size": 8
    },
    "natsec_6": {
      "answer_relevancy": 0.9540766765654155,
      "faithfulness": 0.75,
      "context_recall": 0.75,
      "context_precision": 0.749999999925,
      "answer_correctness": 0.798696119566611,
      "EM": 0.0,
      "F1": 0.6623824451410658,
      "avg_retrieve_context": 0.09767278909683227,
      "avg_llm_response": 2.531233251094818,
      "avg_total": 2.62890604019165,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.7755473784855766,
      "faithfulness": 0.5833333333333334,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.6666666666,
      "answer_correctness": 0.6086472485979584,
      "EM": 0.0,
      "F1": 0.3393314369443763,
      "avg_retrieve_context": 0.09767278909683229,
      "avg_llm_response": 2.910632292429606,
      "avg_total": 3.0083050815264385,
      "sample_size": 6
    },
    "natsec_8": {
      "answer_relevancy": 0.9641306988882354,
      "faithfulness": 0.6481481481481483,
      "context_recall": 0.7777777777777778,
      "context_precision": 0.6666666666,
      "answer_correctness": 0.7034523368589445,
      "EM": 0.0,
      "F1": 0.41074294036819015,
      "avg_retrieve_context": 0.09767278909683227,
      "avg_llm_response": 2.581288311216566,
      "avg_total": 2.678961100313399,
      "sample_size": 9
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.6554828212560017,
      "faithfulness": 0.7902777777777779,
      "context_recall": 0.4666666666666667,
      "context_precision": 0.69999999993,
      "answer_correctness": 0.5160714896828287,
      "EM": 0.0,
      "F1": 0.37030606833354585,
      "avg_retrieve_context": 0.09767278909683227,
      "avg_llm_response": 2.2062251329422,
      "avg_total": 2.303897922039032,
      "sample_size": 40
    },
    "natsec": {
      "answer_relevancy": 0.8239565974614086,
      "faithfulness": 0.7049404761904762,
      "context_recall": 0.55,
      "context_precision": 0.69999999993,
      "answer_correctness": 0.6047046452787072,
      "EM": 0.016666666666666666,
      "F1": 0.42768432623757235,
      "avg_retrieve_context": 0.0976727890968323,
      "avg_llm_response": 2.287257671356201,
      "avg_total": 2.3849304604530333,
      "sample_size": 60
    }
  },
  "chunks_length": {
    "1": {
      "answer_relevancy": 0.7551831381862124,
      "faithfulness": 0.7386844636844637,
      "context_recall": 0.5218855218855218,
      "context_precision": 0.6969696968999999,
      "answer_correctness": 0.5698778771273891,
      "EM": 0.010101010101010102,
      "F1": 0.407064538021393,
      "avg_retrieve_context": 0.09767278909683226,
      "avg_llm_response": 2.239338015065049,
      "avg_total": 2.337010804161881,
      "sample_size": 99
    },
    "2": {
      "answer_relevancy": 0.893578017489531,
      "faithfulness": 0.7777777777777778,
      "context_recall": 0.0,
      "context_precision": 0.9999999999,
      "answer_correctness": 0.5072284684240534,
      "EM": 0.0,
      "F1": 0.1739130434782609,
      "avg_retrieve_context": 0.09767278909683227,
      "avg_llm_response": 3.7900021076202393,
      "avg_total": 3.8876748967170713,
      "sample_size": 1
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7565670869792457,
      "faithfulness": 0.7390753968253969,
      "context_recall": 0.5166666666666666,
      "context_precision": 0.6999999999299998,
      "answer_correctness": 0.5692513830403558,
      "EM": 0.01,
      "F1": 0.40473302307596165,
      "avg_retrieve_context": 0.09767278909683226,
      "avg_llm_response": 2.254844655990601,
      "avg_total": 2.352517445087433,
      "sample_size": 100
    }
  }
}