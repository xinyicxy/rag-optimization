{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.7080258527259443,
      "faithfulness": 0.8014868464868464,
      "context_recall": 0.9265151515151514,
      "context_precision": 0.7433333332929596,
      "answer_correctness": 0.6817001371664154,
      "EM": 0.06363636363636363,
      "F1": 0.49376028707840286,
      "avg_retrieve_context": 0.06816454367204146,
      "avg_llm_response": 1.25481858253479,
      "avg_total": 1.3229831262068326,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.6688413933652088,
      "faithfulness": 0.789534275248561,
      "context_recall": 0.8531746031746033,
      "context_precision": 0.8349206348752711,
      "answer_correctness": 0.6140321732201731,
      "EM": 0.0,
      "F1": 0.289385694710241,
      "avg_retrieve_context": 0.06816454367204147,
      "avg_llm_response": 1.2383934543246315,
      "avg_total": 1.3065579979966726,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7926228110061386,
      "faithfulness": 0.6666666666666666,
      "context_recall": 0.8846153846153846,
      "context_precision": 0.7967948717618002,
      "answer_correctness": 0.7032841593223023,
      "EM": 0.07692307692307693,
      "F1": 0.5862980935071354,
      "avg_retrieve_context": 0.06816454367204147,
      "avg_llm_response": 2.343898131297185,
      "avg_total": 2.412062674969226,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7940790951542236,
      "faithfulness": 0.8194444444444443,
      "context_recall": 0.9166666666666666,
      "context_precision": 0.8063657406794088,
      "answer_correctness": 0.6711850413628371,
      "EM": 0.0,
      "F1": 0.38456965498707785,
      "avg_retrieve_context": 0.06816454367204147,
      "avg_llm_response": 0.8089237014452616,
      "avg_total": 0.8770882451173033,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.7408074219658284,
      "faithfulness": 0.9107142857142857,
      "context_recall": 1.0,
      "context_precision": 0.8022817459799264,
      "answer_correctness": 0.7160914149335914,
      "EM": 0.07142857142857142,
      "F1": 0.6030477943000057,
      "avg_retrieve_context": 0.06816454367204147,
      "avg_llm_response": 1.399199264390128,
      "avg_total": 1.467363808062169,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.6370942625442992,
      "faithfulness": 0.6666666666666666,
      "context_recall": 1.0,
      "context_precision": 0.6812499999713483,
      "answer_correctness": 0.6948537250087882,
      "EM": 0.0,
      "F1": 0.33409742995481534,
      "avg_retrieve_context": 0.06816454367204146,
      "avg_llm_response": 0.6409291823705038,
      "avg_total": 0.7090937260425453,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.7531892804893954,
      "faithfulness": 0.8,
      "context_recall": 0.8,
      "context_precision": 0.8399999999458888,
      "answer_correctness": 0.6222731648959735,
      "EM": 0.0,
      "F1": 0.42643239113827347,
      "avg_retrieve_context": 0.06816454367204146,
      "avg_llm_response": 1.2134986877441407,
      "avg_total": 1.2816632314161822,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.7064262024021959,
      "faithfulness": 0.875,
      "context_recall": 1.0,
      "context_precision": 0.95260416662273,
      "answer_correctness": 0.5902458753567683,
      "EM": 0.0,
      "F1": 0.3957864711330796,
      "avg_retrieve_context": 0.06816454367204146,
      "avg_llm_response": 0.8460617065429688,
      "avg_total": 0.9142262502150102,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.9564643697940957,
      "faithfulness": 0.8333333333333334,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.7798611110632813,
      "answer_correctness": 0.6509603772879587,
      "EM": 0.0,
      "F1": 0.6848663681071784,
      "avg_retrieve_context": 0.06816454367204146,
      "avg_llm_response": 0.6375378370285034,
      "avg_total": 0.7057023807005449,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.7919268567148677,
      "faithfulness": 0.9444444444444443,
      "context_recall": 0.9166666666666666,
      "context_precision": 0.7659722221925868,
      "answer_correctness": 0.667235423749723,
      "EM": 0.0,
      "F1": 0.5077726195373254,
      "avg_retrieve_context": 0.06816454367204146,
      "avg_llm_response": 1.8875414530436199,
      "avg_total": 1.9557059967156614,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.9094283050339041,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.9583333333004167,
      "answer_correctness": 0.852368240327014,
      "EM": 0.0,
      "F1": 0.6422532781228434,
      "avg_retrieve_context": 0.06816454367204146,
      "avg_llm_response": 0.9447904825210571,
      "avg_total": 1.0129550261930986,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.876378963274732,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.8444444443940741,
      "answer_correctness": 0.9311801822902382,
      "EM": 0.0,
      "F1": 0.6508845160007951,
      "avg_retrieve_context": 0.06816454367204146,
      "avg_llm_response": 2.0554890632629395,
      "avg_total": 2.123653606934981,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9192875563873242,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.7083333333055555,
      "answer_correctness": 0.7293540876168395,
      "EM": 0.0,
      "F1": 0.41330645161290325,
      "avg_retrieve_context": 0.06816454367204146,
      "avg_llm_response": 1.1268833875656128,
      "avg_total": 1.1950479312376543,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.1797130768013828,
      "faithfulness": 0.5666666666666667,
      "context_recall": 1.0,
      "context_precision": 0.0,
      "answer_correctness": 0.7296793407042539,
      "EM": 0.5,
      "F1": 0.775,
      "avg_retrieve_context": 0.06816454367204147,
      "avg_llm_response": 0.8225797891616822,
      "avg_total": 0.8907443328337237,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7375003142186911,
      "faithfulness": 0.7971703296703296,
      "context_recall": 0.9069444444444446,
      "context_precision": 0.8133333332859327,
      "answer_correctness": 0.6686145002372982,
      "EM": 0.03333333333333333,
      "F1": 0.44594132974254724,
      "avg_retrieve_context": 0.06816454367204144,
      "avg_llm_response": 1.42954687277476,
      "avg_total": 1.4977114164468015,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.7958923544679646,
      "faithfulness": 0.8666666666666666,
      "context_recall": 0.9375,
      "context_precision": 0.8241666666267395,
      "answer_correctness": 0.6893337916756321,
      "EM": 0.0,
      "F1": 0.49517879485178706,
      "avg_retrieve_context": 0.06816454367204146,
      "avg_llm_response": 1.100785845518112,
      "avg_total": 1.1689503891901538,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.1797130768013828,
      "faithfulness": 0.5666666666666667,
      "context_recall": 1.0,
      "context_precision": 0.0,
      "answer_correctness": 0.7296793407042539,
      "EM": 0.5,
      "F1": 0.775,
      "avg_retrieve_context": 0.06816454367204147,
      "avg_llm_response": 0.8225797891616822,
      "avg_total": 0.8907443328337237,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.1797130768013828,
      "faithfulness": 0.5666666666666667,
      "context_recall": 1.0,
      "context_precision": 0.0,
      "answer_correctness": 0.7296793407042539,
      "EM": 0.5,
      "F1": 0.775,
      "avg_retrieve_context": 0.06816454367204147,
      "avg_llm_response": 0.8225797891616822,
      "avg_total": 0.8907443328337237,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.795153533412236,
      "faithfulness": 0.8375457875457876,
      "context_recall": 0.9432234432234433,
      "context_precision": 0.8078754578304365,
      "answer_correctness": 0.6946664977424227,
      "EM": 0.02197802197802198,
      "F1": 0.49506049571605126,
      "avg_retrieve_context": 0.06816454367204146,
      "avg_llm_response": 1.3108952936235365,
      "avg_total": 1.379059837295578,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.4140823879251736,
      "faithfulness": 0.6978021978021978,
      "context_recall": 0.6759259259259259,
      "context_precision": 0.916666666628426,
      "answer_correctness": 0.49728559852252185,
      "EM": 0.0,
      "F1": 0.16812516316262768,
      "avg_retrieve_context": 0.06816454367204146,
      "avg_llm_response": 1.168086051940918,
      "avg_total": 1.2362505956129595,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.782049176949501,
      "faithfulness": 0.8373728123728125,
      "context_recall": 0.9175925925925927,
      "context_precision": 0.8137808641526098,
      "answer_correctness": 0.6967971944383499,
      "EM": 0.022222222222222223,
      "F1": 0.48590065269787847,
      "avg_retrieve_context": 0.06816454367204146,
      "avg_llm_response": 1.3505200571484035,
      "avg_total": 1.418684600820445,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.37492089371993875,
      "faithfulness": 0.6399999999999999,
      "context_recall": 0.9666666666666666,
      "context_precision": 0.4263194444245341,
      "answer_correctness": 0.613763379442711,
      "EM": 0.25,
      "F1": 0.5291286417907627,
      "avg_retrieve_context": 0.06816454367204147,
      "avg_llm_response": 0.824161946773529,
      "avg_total": 0.8923264904455704,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 8,
  "negative_rejection_percentage": 80.0
}