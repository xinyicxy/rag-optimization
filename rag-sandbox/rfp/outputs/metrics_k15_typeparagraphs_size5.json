{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.7179396955250729,
      "faithfulness": 0.8036002886002886,
      "context_recall": 0.9303030303030303,
      "context_precision": 0.6655442074466927,
      "answer_correctness": 0.7048331017685715,
      "EM": 0.05454545454545454,
      "F1": 0.4752954916059965,
      "avg_retrieve_context": 0.084714581749656,
      "avg_llm_response": 1.973650529167869,
      "avg_total": 2.058365110917525,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.8095274355231235,
      "faithfulness": 0.8544973544973544,
      "context_recall": 0.9206349206349206,
      "context_precision": 0.7529732987108801,
      "answer_correctness": 0.6748020595826121,
      "EM": 0.0,
      "F1": 0.3444547998159567,
      "avg_retrieve_context": 0.08471458174965599,
      "avg_llm_response": 1.9657323246910459,
      "avg_total": 2.0504469064407025,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7780371781205913,
      "faithfulness": 0.75,
      "context_recall": 0.9230769230769231,
      "context_precision": 0.6971786150097043,
      "answer_correctness": 0.7019958823844875,
      "EM": 0.0,
      "F1": 0.5622635079115527,
      "avg_retrieve_context": 0.08471458174965597,
      "avg_llm_response": 2.230755255772517,
      "avg_total": 2.315469837522173,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7987714229685853,
      "faithfulness": 0.8722222222222222,
      "context_recall": 1.0,
      "context_precision": 0.7342658729741368,
      "answer_correctness": 0.769088422380073,
      "EM": 0.0,
      "F1": 0.4326137145102662,
      "avg_retrieve_context": 0.08471458174965597,
      "avg_llm_response": 1.5182016491889954,
      "avg_total": 1.602916230938651,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.5312797011253575,
      "faithfulness": 0.7142857142857143,
      "context_recall": 1.0,
      "context_precision": 0.681618910160905,
      "answer_correctness": 0.5393245721761388,
      "EM": 0.0,
      "F1": 0.413752152898777,
      "avg_retrieve_context": 0.08471458174965597,
      "avg_llm_response": 2.4681317465645924,
      "avg_total": 2.552846328314249,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.7877693803459983,
      "faithfulness": 0.6428571428571429,
      "context_recall": 1.0,
      "context_precision": 0.7020513143321808,
      "answer_correctness": 0.809690324800172,
      "EM": 0.0,
      "F1": 0.4661715191126956,
      "avg_retrieve_context": 0.08471458174965597,
      "avg_llm_response": 1.289064089457194,
      "avg_total": 1.37377867120685,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.9561050945781198,
      "faithfulness": 0.9199999999999999,
      "context_recall": 1.0,
      "context_precision": 0.8311111110367406,
      "answer_correctness": 0.7310552991101049,
      "EM": 0.0,
      "F1": 0.4568897227433813,
      "avg_retrieve_context": 0.08471458174965599,
      "avg_llm_response": 2.19677677154541,
      "avg_total": 2.281491353295066,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.9586520013830044,
      "faithfulness": 0.8888888888888888,
      "context_recall": 1.0,
      "context_precision": 0.8581426840788331,
      "answer_correctness": 0.7908794998079121,
      "EM": 0.0,
      "F1": 0.5182406070780896,
      "avg_retrieve_context": 0.08471458174965599,
      "avg_llm_response": 1.8500584065914154,
      "avg_total": 1.9347729883410714,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.6545234312107304,
      "faithfulness": 0.6944444444444443,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.7146310993076167,
      "answer_correctness": 0.592649035367141,
      "EM": 0.0,
      "F1": 0.47901550062840387,
      "avg_retrieve_context": 0.08471458174965597,
      "avg_llm_response": 1.6091784238815308,
      "avg_total": 1.693893005631187,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.7953210477922611,
      "faithfulness": 0.9166666666666666,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.649168475544957,
      "answer_correctness": 0.689352651547044,
      "EM": 0.0,
      "F1": 0.43566067733777375,
      "avg_retrieve_context": 0.08471458174965597,
      "avg_llm_response": 2.6496347188949585,
      "avg_total": 2.734349300644615,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.6762979334094698,
      "faithfulness": 0.875,
      "context_recall": 1.0,
      "context_precision": 0.7357077896489529,
      "answer_correctness": 0.70015473688673,
      "EM": 0.0,
      "F1": 0.4042207792207792,
      "avg_retrieve_context": 0.08471458174965599,
      "avg_llm_response": 0.9466577172279358,
      "avg_total": 1.0313722989775918,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.8769748807447205,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.7702003022999168,
      "answer_correctness": 0.9547792754717795,
      "EM": 0.0,
      "F1": 0.5926770708283313,
      "avg_retrieve_context": 0.084714581749656,
      "avg_llm_response": 2.606247584025065,
      "avg_total": 2.6909621657747214,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9529417896860468,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.6555059523603981,
      "answer_correctness": 0.8028507839280565,
      "EM": 0.0,
      "F1": 0.39802631578947373,
      "avg_retrieve_context": 0.08471458174965599,
      "avg_llm_response": 1.7750228643417358,
      "avg_total": 1.8597374460913918,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.17182095595340047,
      "faithfulness": 0.65,
      "context_recall": 0.7,
      "context_precision": 0.0,
      "answer_correctness": 0.7652123487164538,
      "EM": 0.6,
      "F1": 0.784920634920635,
      "avg_retrieve_context": 0.08471458174965599,
      "avg_llm_response": 1.9822062969207763,
      "avg_total": 2.0669208786704325,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7356288725488551,
      "faithfulness": 0.8026851851851852,
      "context_recall": 0.9555555555555556,
      "context_precision": 0.7204936080999491,
      "answer_correctness": 0.6679399133543337,
      "EM": 0.0,
      "F1": 0.42544785189485584,
      "avg_retrieve_context": 0.084714581749656,
      "avg_llm_response": 2.0508743564287824,
      "avg_total": 2.135588938178438,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.8279356148823176,
      "faithfulness": 0.8433730158730158,
      "context_recall": 0.95,
      "context_precision": 0.7495061583284813,
      "answer_correctness": 0.7450780726529584,
      "EM": 0.0,
      "F1": 0.472660665344048,
      "avg_retrieve_context": 0.08471458174965599,
      "avg_llm_response": 1.855675846338272,
      "avg_total": 1.940390428087928,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.17182095595340047,
      "faithfulness": 0.65,
      "context_recall": 0.7,
      "context_precision": 0.0,
      "answer_correctness": 0.7652123487164538,
      "EM": 0.6,
      "F1": 0.784920634920635,
      "avg_retrieve_context": 0.08471458174965599,
      "avg_llm_response": 1.9822062969207763,
      "avg_total": 2.0669208786704325,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.17182095595340047,
      "faithfulness": 0.65,
      "context_recall": 0.7,
      "context_precision": 0.0,
      "answer_correctness": 0.7652123487164538,
      "EM": 0.6,
      "F1": 0.784920634920635,
      "avg_retrieve_context": 0.08471458174965599,
      "avg_llm_response": 1.9822062969207763,
      "avg_total": 2.0669208786704325,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7663425626217488,
      "faithfulness": 0.8218123146694576,
      "context_recall": 0.9633699633699633,
      "context_precision": 0.7285177444316491,
      "answer_correctness": 0.702084498401453,
      "EM": 0.0,
      "F1": 0.45758955872683105,
      "avg_retrieve_context": 0.08471458174965599,
      "avg_llm_response": 1.9689422649341626,
      "avg_total": 2.0536568466838188,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.8353315277383175,
      "faithfulness": 0.7901234567901234,
      "context_recall": 0.8518518518518517,
      "context_precision": 0.7683053417617922,
      "answer_correctness": 0.6655364836495699,
      "EM": 0.0,
      "F1": 0.3102942092568488,
      "avg_retrieve_context": 0.08471458174965599,
      "avg_llm_response": 2.0117499033610025,
      "avg_total": 2.096464485110659,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7741952949083806,
      "faithfulness": 0.8266225749559084,
      "context_recall": 0.951851851851852,
      "context_precision": 0.7339347632492081,
      "answer_correctness": 0.6963435810478379,
      "EM": 0.0,
      "F1": 0.4518355380963702,
      "avg_retrieve_context": 0.08471458174965597,
      "avg_llm_response": 1.9941624879837037,
      "avg_total": 2.0788770697333594,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.4647894983001882,
      "faithfulness": 0.7,
      "context_recall": 0.8333333333333333,
      "context_precision": 0.357786706335373,
      "answer_correctness": 0.7430359450118742,
      "EM": 0.3,
      "F1": 0.5808652823993148,
      "avg_retrieve_context": 0.08471458174965599,
      "avg_llm_response": 1.8813467144966125,
      "avg_total": 1.966061296246269,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 8,
  "negative_rejection_percentage": 80.0
}