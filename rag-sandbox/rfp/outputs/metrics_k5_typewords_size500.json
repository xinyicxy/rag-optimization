{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6705729351944485,
      "faithfulness": 0.8082568807339449,
      "context_recall": 0.9327217125382263,
      "context_precision": 0.7889525993464006,
      "answer_correctness": 0.6638843366531568,
      "EM": 0.07272727272727272,
      "F1": 0.4799094046978984,
      "avg_retrieve_context": 0.11103976423090149,
      "avg_llm_response": 1.5276720068671488,
      "avg_total": 1.63871177109805,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.7141179748650407,
      "faithfulness": 0.8690476190476191,
      "context_recall": 0.8412698412698413,
      "context_precision": 0.8408730158304563,
      "answer_correctness": 0.6524923059775506,
      "EM": 0.0,
      "F1": 0.34397521802152997,
      "avg_retrieve_context": 0.11103976423090153,
      "avg_llm_response": 1.988597449802217,
      "avg_total": 2.0996372140331188,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.5672912038547225,
      "faithfulness": 0.8076923076923077,
      "context_recall": 0.9230769230769231,
      "context_precision": 0.9225427350025204,
      "answer_correctness": 0.567791591408752,
      "EM": 0.07692307692307693,
      "F1": 0.4665093107966611,
      "avg_retrieve_context": 0.11103976423090155,
      "avg_llm_response": 1.646793897335346,
      "avg_total": 1.7578336615662478,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7128954255057005,
      "faithfulness": 0.8125,
      "context_recall": 1.0,
      "context_precision": 0.8545138888310677,
      "answer_correctness": 0.6991002977607551,
      "EM": 0.08333333333333333,
      "F1": 0.4527435079122426,
      "avg_retrieve_context": 0.11103976423090155,
      "avg_llm_response": 1.0885571042696636,
      "avg_total": 1.1995968685005653,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.8000714011186529,
      "faithfulness": 0.8047619047619048,
      "context_recall": 1.0,
      "context_precision": 0.8633928570948238,
      "answer_correctness": 0.6696748934900535,
      "EM": 0.0,
      "F1": 0.528775917695402,
      "avg_retrieve_context": 0.11103976423090155,
      "avg_llm_response": 1.4365153312683105,
      "avg_total": 1.5475550954992126,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.9381175617142247,
      "faithfulness": 0.75,
      "context_recall": 1.0,
      "context_precision": 0.9083333332719444,
      "answer_correctness": 0.8494435506831032,
      "EM": 0.0,
      "F1": 0.5103188750247573,
      "avg_retrieve_context": 0.11103976423090155,
      "avg_llm_response": 1.453072190284729,
      "avg_total": 1.5641119545156308,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.710228504714793,
      "faithfulness": 0.7916666666666666,
      "context_recall": 1.0,
      "context_precision": 0.8958333332760418,
      "answer_correctness": 0.5570123057743184,
      "EM": 0.0,
      "F1": 0.3933105130163954,
      "avg_retrieve_context": 0.11103976423090153,
      "avg_llm_response": 1.663572645187378,
      "avg_total": 1.7746124094182796,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.5799275799354787,
      "faithfulness": 0.8125,
      "context_recall": 1.0,
      "context_precision": 0.8937499999632812,
      "answer_correctness": 0.5704442766331442,
      "EM": 0.0,
      "F1": 0.35428613785797336,
      "avg_retrieve_context": 0.11103976423090155,
      "avg_llm_response": 1.1700890362262726,
      "avg_total": 1.2811288004571741,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.9757790542457186,
      "faithfulness": 0.8611111111111112,
      "context_recall": 1.0,
      "context_precision": 0.7784722221723901,
      "answer_correctness": 0.717438881425803,
      "EM": 0.0,
      "F1": 0.6549006486752441,
      "avg_retrieve_context": 0.11103976423090155,
      "avg_llm_response": 1.1521386702855427,
      "avg_total": 1.2631784345164443,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.7877599474521121,
      "faithfulness": 0.9166666666666666,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.8840277777500521,
      "answer_correctness": 0.6891960398199687,
      "EM": 0.0,
      "F1": 0.5457181277614714,
      "avg_retrieve_context": 0.11103976423090155,
      "avg_llm_response": 2.15769092241923,
      "avg_total": 2.268730686650132,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.24134243106129014,
      "faithfulness": 0.625,
      "context_recall": 1.0,
      "context_precision": 0.8902777777347685,
      "answer_correctness": 0.3051749450017622,
      "EM": 0.0,
      "F1": 0.1713157894736842,
      "avg_retrieve_context": 0.11103976423090155,
      "avg_llm_response": 1.5109619498252869,
      "avg_total": 1.6220017140561884,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.8877093435803781,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.8611111110513888,
      "answer_correctness": 0.9584989211832218,
      "EM": 0.0,
      "F1": 0.7151515151515152,
      "avg_retrieve_context": 0.11103976423090155,
      "avg_llm_response": 2.1355953216552734,
      "avg_total": 2.246635085886175,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9435275290169224,
      "faithfulness": 0.75,
      "context_recall": 1.0,
      "context_precision": 0.8499999999575,
      "answer_correctness": 0.7947329183329008,
      "EM": 0.0,
      "F1": 0.45392628205128205,
      "avg_retrieve_context": 0.11103976423090155,
      "avg_llm_response": 1.8838365077972412,
      "avg_total": 1.9948762720281428,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.17596152403526116,
      "faithfulness": 0.65,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7501374851403761,
      "EM": 0.6,
      "F1": 0.7861111111111111,
      "avg_retrieve_context": 0.11103976423090153,
      "avg_llm_response": 0.9226860761642456,
      "avg_total": 1.0337258403951473,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7021167974001131,
      "faithfulness": 0.8294444444444444,
      "context_recall": 0.9277777777777777,
      "context_precision": 0.866550925879545,
      "answer_correctness": 0.6474713532638692,
      "EM": 0.03333333333333333,
      "F1": 0.43539809269152113,
      "avg_retrieve_context": 0.11103976423090155,
      "avg_llm_response": 1.6057127833366394,
      "avg_total": 1.7167525475675407,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.7488673551752686,
      "faithfulness": 0.8162393162393161,
      "context_recall": 0.9743589743589743,
      "context_precision": 0.8718660968201275,
      "answer_correctness": 0.6670188884091844,
      "EM": 0.0,
      "F1": 0.47012594610416125,
      "avg_retrieve_context": 0.11103976423090153,
      "avg_llm_response": 1.5618573248386383,
      "avg_total": 1.67289708906954,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.17596152403526116,
      "faithfulness": 0.65,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7501374851403761,
      "EM": 0.6,
      "F1": 0.7861111111111111,
      "avg_retrieve_context": 0.11103976423090153,
      "avg_llm_response": 0.9226860761642456,
      "avg_total": 1.0337258403951473,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.17596152403526116,
      "faithfulness": 0.65,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7501374851403761,
      "EM": 0.6,
      "F1": 0.7861111111111111,
      "avg_retrieve_context": 0.11103976423090153,
      "avg_llm_response": 0.9226860761642456,
      "avg_total": 1.0337258403951473,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7527074850470407,
      "faithfulness": 0.8335185185185187,
      "context_recall": 0.9759259259259261,
      "context_precision": 0.8652006172362361,
      "answer_correctness": 0.6745311843765993,
      "EM": 0.02197802197802198,
      "F1": 0.47331950348888313,
      "avg_retrieve_context": 0.1110397642309015,
      "avg_llm_response": 1.5541898837456336,
      "avg_total": 1.6652296479765352,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.3987956712898438,
      "faithfulness": 0.7314814814814815,
      "context_recall": 0.6481481481481481,
      "context_precision": 0.9030864197218261,
      "answer_correctness": 0.46157902776626625,
      "EM": 0.0,
      "F1": 0.20631650979659366,
      "avg_retrieve_context": 0.11103976423090155,
      "avg_llm_response": 1.931753396987915,
      "avg_total": 2.0427931612188166,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7380069260052952,
      "faithfulness": 0.8279026217228465,
      "context_recall": 0.9550561797752809,
      "context_precision": 0.8714263420259998,
      "answer_correctness": 0.6631205962738295,
      "EM": 0.022222222222222223,
      "F1": 0.46108734244889277,
      "avg_retrieve_context": 0.11103976423090152,
      "avg_llm_response": 1.6120087226231894,
      "avg_total": 1.723048486854091,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.37049167608618006,
      "faithfulness": 0.7208333333333333,
      "context_recall": 0.8333333333333333,
      "context_precision": 0.42194444442218515,
      "answer_correctness": 0.6672829813411633,
      "EM": 0.3,
      "F1": 0.5646086848184233,
      "avg_retrieve_context": 0.11103976423090153,
      "avg_llm_response": 1.1481567859649657,
      "avg_total": 1.2591965501958675,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 8,
  "negative_rejection_percentage": 80.0
}