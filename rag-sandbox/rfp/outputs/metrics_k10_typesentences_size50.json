{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6817714422934187,
      "faithfulness": 0.8058913813459269,
      "context_recall": 0.9742424242424241,
      "context_precision": 0.7642192302557349,
      "answer_correctness": 0.6849673271187144,
      "EM": 0.05454545454545454,
      "F1": 0.4871303989982484,
      "avg_retrieve_context": 0.07014813639900899,
      "avg_llm_response": 1.9463566368276424,
      "avg_total": 2.0165047732266514,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.7096521660070579,
      "faithfulness": 0.8455988455988456,
      "context_recall": 0.984126984126984,
      "context_precision": 0.839467592559053,
      "answer_correctness": 0.6558939276206717,
      "EM": 0.0,
      "F1": 0.3430043983731679,
      "avg_retrieve_context": 0.07014813639900902,
      "avg_llm_response": 2.3489884308406284,
      "avg_total": 2.419136567239638,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7093903717337772,
      "faithfulness": 0.7307692307692307,
      "context_recall": 0.9615384615384616,
      "context_precision": 0.9769230768841025,
      "answer_correctness": 0.6636705218630953,
      "EM": 0.07692307692307693,
      "F1": 0.5190310768934931,
      "avg_retrieve_context": 0.07014813639900899,
      "avg_llm_response": 2.1268161810361423,
      "avg_total": 2.1969643174351514,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7131676285313869,
      "faithfulness": 0.875,
      "context_recall": 0.9166666666666666,
      "context_precision": 0.9305555555193288,
      "answer_correctness": 0.6359252119805084,
      "EM": 0.0,
      "F1": 0.38427731824153916,
      "avg_retrieve_context": 0.07014813639900899,
      "avg_llm_response": 1.0811031659444172,
      "avg_total": 1.1512513023434263,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.536687117481036,
      "faithfulness": 0.7833333333333333,
      "context_recall": 1.0,
      "context_precision": 0.798783811113949,
      "answer_correctness": 0.6014943127850498,
      "EM": 0.07142857142857142,
      "F1": 0.47707799508807763,
      "avg_retrieve_context": 0.07014813639900899,
      "avg_llm_response": 2.04170869077955,
      "avg_total": 2.111856827178559,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.8037074813147088,
      "faithfulness": 0.8055555555555555,
      "context_recall": 1.0,
      "context_precision": 0.6374470899252515,
      "answer_correctness": 0.8047250022228436,
      "EM": 0.0,
      "F1": 0.5618026454841084,
      "avg_retrieve_context": 0.070148136399009,
      "avg_llm_response": 1.5107170343399048,
      "avg_total": 1.5808651707389139,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.7560491422742446,
      "faithfulness": 0.72,
      "context_recall": 1.0,
      "context_precision": 0.7666666666183334,
      "answer_correctness": 0.6293206708310846,
      "EM": 0.0,
      "F1": 0.44227032227032226,
      "avg_retrieve_context": 0.070148136399009,
      "avg_llm_response": 2.513944911956787,
      "avg_total": 2.584093048355796,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.8205429237386261,
      "faithfulness": 0.8946428571428571,
      "context_recall": 1.0,
      "context_precision": 0.9345920138589847,
      "answer_correctness": 0.7067237901152623,
      "EM": 0.0,
      "F1": 0.5320906378567669,
      "avg_retrieve_context": 0.070148136399009,
      "avg_llm_response": 2.414582669734955,
      "avg_total": 2.484730806133964,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.8129823022401946,
      "faithfulness": 0.75,
      "context_recall": 1.0,
      "context_precision": 0.7240299823259067,
      "answer_correctness": 0.6886626208517406,
      "EM": 0.0,
      "F1": 0.49010227455099864,
      "avg_retrieve_context": 0.070148136399009,
      "avg_llm_response": 1.6766385237375896,
      "avg_total": 1.7467866601365987,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9623410573525715,
      "faithfulness": 0.9166666666666666,
      "context_recall": 1.0,
      "context_precision": 0.8245443856408089,
      "answer_correctness": 0.8085782577882333,
      "EM": 0.0,
      "F1": 0.5357136221170488,
      "avg_retrieve_context": 0.070148136399009,
      "avg_llm_response": 2.7926997741063437,
      "avg_total": 2.862847910505353,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.6648126702612214,
      "faithfulness": 0.7083333333333334,
      "context_recall": 1.0,
      "context_precision": 0.7680390211461103,
      "answer_correctness": 0.6396294085154388,
      "EM": 0.0,
      "F1": 0.5151113076809671,
      "avg_retrieve_context": 0.070148136399009,
      "avg_llm_response": 1.6006713509559631,
      "avg_total": 1.6708194873549722,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.8770982351281412,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.8420634920341071,
      "answer_correctness": 0.9556225824372876,
      "EM": 0.0,
      "F1": 0.6262371615312792,
      "avg_retrieve_context": 0.070148136399009,
      "avg_llm_response": 2.5530519485473633,
      "avg_total": 2.6232000849463724,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9464395292914003,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.6805555555340278,
      "answer_correctness": 0.7048468685393816,
      "EM": 0.0,
      "F1": 0.38579710144927537,
      "avg_retrieve_context": 0.070148136399009,
      "avg_llm_response": 2.0438159704208374,
      "avg_total": 2.1139641068198465,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.1796258554740391,
      "faithfulness": 0.65,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.7445625717340663,
      "EM": 0.4,
      "F1": 0.763888888888889,
      "avg_retrieve_context": 0.07014813639900899,
      "avg_llm_response": 0.964851188659668,
      "avg_total": 1.034999325058677,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.6699400250966412,
      "faithfulness": 0.812070707070707,
      "context_recall": 0.9694444444444444,
      "context_precision": 0.8779743244176779,
      "answer_correctness": 0.6408918697835192,
      "EM": 0.03333333333333333,
      "F1": 0.42068193525972486,
      "avg_retrieve_context": 0.07014813639900902,
      "avg_llm_response": 1.9755754510561625,
      "avg_total": 2.045723587455172,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.82505496479343,
      "faithfulness": 0.8355952380952381,
      "context_recall": 1.0,
      "context_precision": 0.7846413965767541,
      "answer_correctness": 0.7361817019676702,
      "EM": 0.0,
      "F1": 0.5176134721333734,
      "avg_retrieve_context": 0.070148136399009,
      "avg_llm_response": 2.1479047775268554,
      "avg_total": 2.2180529139258645,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.1796258554740391,
      "faithfulness": 0.65,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.7445625717340663,
      "EM": 0.4,
      "F1": 0.763888888888889,
      "avg_retrieve_context": 0.07014813639900899,
      "avg_llm_response": 0.964851188659668,
      "avg_total": 1.034999325058677,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.1796258554740391,
      "faithfulness": 0.65,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.7445625717340663,
      "EM": 0.4,
      "F1": 0.763888888888889,
      "avg_retrieve_context": 0.07014813639900899,
      "avg_llm_response": 0.964851188659668,
      "avg_total": 1.034999325058677,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7532415061732621,
      "faithfulness": 0.8339612768184196,
      "context_recall": 0.9835164835164835,
      "context_precision": 0.8274613885715661,
      "answer_correctness": 0.6928053925414008,
      "EM": 0.02197802197802198,
      "F1": 0.4802450165458147,
      "avg_retrieve_context": 0.07014813639900899,
      "avg_llm_response": 2.0178047195895688,
      "avg_total": 2.087952855988578,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.517069226196533,
      "faithfulness": 0.6952861952861953,
      "context_recall": 0.9629629629629629,
      "context_precision": 0.9739032186798126,
      "answer_correctness": 0.5394988382722752,
      "EM": 0.0,
      "F1": 0.2492398328054769,
      "avg_retrieve_context": 0.070148136399009,
      "avg_llm_response": 2.3144987424214682,
      "avg_total": 2.3846468788204773,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7297186526489124,
      "faithfulness": 0.832116402116402,
      "context_recall": 0.9833333333333333,
      "context_precision": 0.8318235036493764,
      "answer_correctness": 0.6799300244060669,
      "EM": 0.022222222222222223,
      "F1": 0.47021355123764036,
      "avg_retrieve_context": 0.07014813639900899,
      "avg_llm_response": 2.086951266394721,
      "avg_total": 2.15709940279373,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.4660089956936961,
      "faithfulness": 0.6878787878787879,
      "context_recall": 0.9333333333333332,
      "context_precision": 0.45999999998434815,
      "answer_correctness": 0.7076351893256299,
      "EM": 0.2,
      "F1": 0.5632562139209842,
      "avg_retrieve_context": 0.07014813639900902,
      "avg_llm_response": 1.3136808037757874,
      "avg_total": 1.3838289401747965,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 8,
  "negative_rejection_percentage": 80.0
}