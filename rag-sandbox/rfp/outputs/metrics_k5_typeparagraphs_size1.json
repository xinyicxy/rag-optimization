{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6609423025773126,
      "faithfulness": 0.7979535615899251,
      "context_recall": 0.7776515151515151,
      "context_precision": 0.6653914140993363,
      "answer_correctness": 0.6497678563555408,
      "EM": 0.03636363636363636,
      "F1": 0.428947020485977,
      "avg_retrieve_context": 0.09327183636752046,
      "avg_llm_response": 1.1063697814941407,
      "avg_total": 1.1996416178616605,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.809447933572649,
      "faithfulness": 0.865079365079365,
      "context_recall": 0.6746031746031745,
      "context_precision": 0.8153439152939131,
      "answer_correctness": 0.6543527979323089,
      "EM": 0.0,
      "F1": 0.3151407834162667,
      "avg_retrieve_context": 0.09327183636752043,
      "avg_llm_response": 1.4874411764599027,
      "avg_total": 1.5807130128274232,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7153955398695625,
      "faithfulness": 0.7564102564102563,
      "context_recall": 0.8076923076923077,
      "context_precision": 0.9388888888248681,
      "answer_correctness": 0.5536478252740367,
      "EM": 0.07692307692307693,
      "F1": 0.49318944128132897,
      "avg_retrieve_context": 0.09327183636752043,
      "avg_llm_response": 1.3255961674910326,
      "avg_total": 1.4188680038585533,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.5507705629509216,
      "faithfulness": 0.8055555555555555,
      "context_recall": 0.75,
      "context_precision": 0.8222222221573842,
      "answer_correctness": 0.5729850797248864,
      "EM": 0.0,
      "F1": 0.31295853930796746,
      "avg_retrieve_context": 0.09327183636752041,
      "avg_llm_response": 0.8259485761324564,
      "avg_total": 0.919220412499977,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.5367015150063086,
      "faithfulness": 0.7305194805194805,
      "context_recall": 0.8839285714285714,
      "context_precision": 0.5938492063025761,
      "answer_correctness": 0.5763455852562027,
      "EM": 0.0,
      "F1": 0.4223778307263542,
      "avg_retrieve_context": 0.09327183636752043,
      "avg_llm_response": 1.1879054307937622,
      "avg_total": 1.2811772671612827,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.9051253673032625,
      "faithfulness": 0.7916666666666666,
      "context_recall": 1.0,
      "context_precision": 0.7333333332981944,
      "answer_correctness": 0.9024606569600252,
      "EM": 0.0,
      "F1": 0.46147719790898206,
      "avg_retrieve_context": 0.09327183636752041,
      "avg_llm_response": 0.6035789251327515,
      "avg_total": 0.696850761500272,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.9600162957215822,
      "faithfulness": 0.8333333333333333,
      "context_recall": 1.0,
      "context_precision": 0.6666666666,
      "answer_correctness": 0.77260957914416,
      "EM": 0.0,
      "F1": 0.5810988031576266,
      "avg_retrieve_context": 0.09327183636752041,
      "avg_llm_response": 1.2041711807250977,
      "avg_total": 1.2974430170926181,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.8310495644881837,
      "faithfulness": 0.9375,
      "context_recall": 1.0,
      "context_precision": 0.8309027777427633,
      "answer_correctness": 0.6894028463508135,
      "EM": 0.0,
      "F1": 0.43545625766180773,
      "avg_retrieve_context": 0.09327183636752041,
      "avg_llm_response": 0.8301241397857666,
      "avg_total": 0.9233959761532871,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.0,
      "faithfulness": 0.5833333333333334,
      "context_recall": 0.0,
      "context_precision": 0.0,
      "answer_correctness": 0.18028187630916928,
      "EM": 0.0,
      "F1": 0.02666666666666667,
      "avg_retrieve_context": 0.09327183636752041,
      "avg_llm_response": 0.3671357234319051,
      "avg_total": 0.4604075597994255,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9408835643173741,
      "faithfulness": 0.8333333333333334,
      "context_recall": 0.5833333333333334,
      "context_precision": 0.5027777777627778,
      "answer_correctness": 0.6244549467804134,
      "EM": 0.0,
      "F1": 0.44696374484753254,
      "avg_retrieve_context": 0.09327183636752041,
      "avg_llm_response": 1.6019000212351482,
      "avg_total": 1.6951718576026684,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.8970258970038603,
      "faithfulness": 0.8660714285714286,
      "context_recall": 1.0,
      "context_precision": 0.9458333332869792,
      "answer_correctness": 0.8545050804097295,
      "EM": 0.0,
      "F1": 0.5904816194770591,
      "avg_retrieve_context": 0.09327183636752041,
      "avg_llm_response": 0.8015677332878113,
      "avg_total": 0.8948395696553317,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.8765983865065641,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.8902777777281136,
      "answer_correctness": 0.9360649712503303,
      "EM": 0.0,
      "F1": 0.603584229390681,
      "avg_retrieve_context": 0.09327183636752041,
      "avg_llm_response": 1.6259829998016357,
      "avg_total": 1.7192548361691562,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.8709809018762003,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.9166666666333333,
      "answer_correctness": 0.9006863360250065,
      "EM": 0.0,
      "F1": 0.3928571428571429,
      "avg_retrieve_context": 0.09327183636752041,
      "avg_llm_response": 1.2995585203170776,
      "avg_total": 1.3928303566845979,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.17976445591503265,
      "faithfulness": 0.65,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7941931109418208,
      "EM": 0.3,
      "F1": 0.7527777777777778,
      "avg_retrieve_context": 0.09327183636752043,
      "avg_llm_response": 0.7908728122711182,
      "avg_total": 0.8841446486386385,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.673693609813822,
      "faithfulness": 0.7982323232323232,
      "context_recall": 0.7673611111111112,
      "context_precision": 0.7918055555003355,
      "answer_correctness": 0.5980581605904407,
      "EM": 0.016666666666666666,
      "F1": 0.3783035215043908,
      "avg_retrieve_context": 0.09327183636752044,
      "avg_llm_response": 1.2501845637957254,
      "avg_total": 1.343456400163246,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.7621098033881184,
      "faithfulness": 0.8345238095238094,
      "context_recall": 0.7875,
      "context_precision": 0.6421180555226715,
      "answer_correctness": 0.691226086356622,
      "EM": 0.0,
      "F1": 0.42395457963540617,
      "avg_retrieve_context": 0.09327183636752041,
      "avg_llm_response": 0.9695218503475189,
      "avg_total": 1.0627936867150392,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.17976445591503265,
      "faithfulness": 0.65,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7941931109418208,
      "EM": 0.3,
      "F1": 0.7527777777777778,
      "avg_retrieve_context": 0.09327183636752043,
      "avg_llm_response": 0.7908728122711182,
      "avg_total": 0.8841446486386385,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.17976445591503265,
      "faithfulness": 0.65,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7941931109418208,
      "EM": 0.3,
      "F1": 0.7527777777777778,
      "avg_retrieve_context": 0.09327183636752043,
      "avg_llm_response": 0.7908728122711182,
      "avg_total": 0.8841446486386385,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7180103659843076,
      "faithfulness": 0.8222253936539651,
      "context_recall": 0.8044871794871796,
      "context_precision": 0.7165293039825119,
      "answer_correctness": 0.6425513897871461,
      "EM": 0.01098901098901099,
      "F1": 0.41344949557554683,
      "avg_retrieve_context": 0.09327183636752044,
      "avg_llm_response": 1.0570566863804074,
      "avg_total": 1.1503285227479279,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.618562824420229,
      "faithfulness": 0.716931216931217,
      "context_recall": 0.48148148148148145,
      "context_precision": 0.8876543209464918,
      "answer_correctness": 0.5622618465623359,
      "EM": 0.0,
      "F1": 0.2258322642561036,
      "avg_retrieve_context": 0.09327183636752041,
      "avg_llm_response": 1.955532153447469,
      "avg_total": 2.04880398981499,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7131261233587499,
      "faithfulness": 0.8183982683982685,
      "context_recall": 0.7763888888888889,
      "context_precision": 0.7150462962530026,
      "answer_correctness": 0.6443118779372653,
      "EM": 0.011111111111111112,
      "F1": 0.40882808273738874,
      "avg_retrieve_context": 0.09327183636752044,
      "avg_llm_response": 1.1370099279615613,
      "avg_total": 1.230281764329082,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.4261151090608439,
      "faithfulness": 0.7059523809523809,
      "context_recall": 0.7833333333333333,
      "context_precision": 0.441944444407838,
      "answer_correctness": 0.6743197592377823,
      "EM": 0.15,
      "F1": 0.5194822403546241,
      "avg_retrieve_context": 0.09327183636752043,
      "avg_llm_response": 0.968489122390747,
      "avg_total": 1.0617609587582675,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 8,
  "negative_rejection_percentage": 80.0
}