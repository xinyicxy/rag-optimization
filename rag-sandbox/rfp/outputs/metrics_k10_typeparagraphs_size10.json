{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.704366997226645,
      "faithfulness": 0.8288383838383838,
      "context_recall": 0.9424242424242425,
      "context_precision": 0.6893459108918656,
      "answer_correctness": 0.685039161081053,
      "EM": 0.05454545454545454,
      "F1": 0.4501596447839544,
      "avg_retrieve_context": 0.07472414536909622,
      "avg_llm_response": 2.3981957067142834,
      "avg_total": 2.472919852083379,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.8041521854622977,
      "faithfulness": 0.9261904761904761,
      "context_recall": 0.9365079365079365,
      "context_precision": 0.8075963718429154,
      "answer_correctness": 0.6538615316503732,
      "EM": 0.0,
      "F1": 0.33114298093049266,
      "avg_retrieve_context": 0.07472414536909626,
      "avg_llm_response": 2.473731733503796,
      "avg_total": 2.548455878872892,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.6485601844058733,
      "faithfulness": 0.7307692307692307,
      "context_recall": 0.9230769230769231,
      "context_precision": 0.8442307691949517,
      "answer_correctness": 0.6566931948785771,
      "EM": 0.0,
      "F1": 0.46381175635409916,
      "avg_retrieve_context": 0.07472414536909623,
      "avg_llm_response": 2.610355047079233,
      "avg_total": 2.6850791924483293,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7150061820663725,
      "faithfulness": 0.7888888888888889,
      "context_recall": 1.0,
      "context_precision": 0.8333333332844907,
      "answer_correctness": 0.6237119130237274,
      "EM": 0.08333333333333333,
      "F1": 0.36627829093532444,
      "avg_retrieve_context": 0.07472414536909623,
      "avg_llm_response": 1.5273306369781494,
      "avg_total": 1.6020547823472455,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.6658185553344225,
      "faithfulness": 0.8456349206349206,
      "context_recall": 1.0,
      "context_precision": 0.6967687074552001,
      "answer_correctness": 0.7091671684343568,
      "EM": 0.07142857142857142,
      "F1": 0.48630739732209854,
      "avg_retrieve_context": 0.07472414536909623,
      "avg_llm_response": 3.7872994116374423,
      "avg_total": 3.8620235570065384,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.9465731943824677,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.7096891534197441,
      "answer_correctness": 0.9231813883461055,
      "EM": 0.0,
      "F1": 0.5240420300430095,
      "avg_retrieve_context": 0.07472414536909623,
      "avg_llm_response": 2.3910030523935952,
      "avg_total": 2.4657271977626913,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.9540081098310973,
      "faithfulness": 0.85,
      "context_recall": 1.0,
      "context_precision": 0.7842857142265001,
      "answer_correctness": 0.8015141670977481,
      "EM": 0.0,
      "F1": 0.5031411056662133,
      "avg_retrieve_context": 0.07472414536909623,
      "avg_llm_response": 2.1177077770233153,
      "avg_total": 2.1924319223924114,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.7204449325499859,
      "faithfulness": 0.875,
      "context_recall": 1.0,
      "context_precision": 0.8833939593952522,
      "answer_correctness": 0.6867949956899605,
      "EM": 0.0,
      "F1": 0.4050498980954389,
      "avg_retrieve_context": 0.07472414536909623,
      "avg_llm_response": 2.727231979370117,
      "avg_total": 2.8019561247392133,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.8161702907821563,
      "faithfulness": 0.5833333333333334,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.5633597883273356,
      "answer_correctness": 0.604933065223916,
      "EM": 0.0,
      "F1": 0.49813173135383,
      "avg_retrieve_context": 0.07472414536909623,
      "avg_llm_response": 1.0311006704966228,
      "avg_total": 1.105824815865719,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9495520509366431,
      "faithfulness": 0.9444444444444445,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.6938751889520004,
      "answer_correctness": 0.6322835375241581,
      "EM": 0.0,
      "F1": 0.4836487396814044,
      "avg_retrieve_context": 0.07472414536909623,
      "avg_llm_response": 2.8237402041753135,
      "avg_total": 2.8984643495444096,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.47016653818433174,
      "faithfulness": 0.75,
      "context_recall": 1.0,
      "context_precision": 0.4817035147241052,
      "answer_correctness": 0.546947904136313,
      "EM": 0.0,
      "F1": 0.23337386018237077,
      "avg_retrieve_context": 0.07472414536909623,
      "avg_llm_response": 1.4988102912902832,
      "avg_total": 1.5735344366593793,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.6322226671402436,
      "faithfulness": 0.8333333333333334,
      "context_recall": 1.0,
      "context_precision": 0.7107142856915417,
      "answer_correctness": 0.5961609875159747,
      "EM": 0.0,
      "F1": 0.3783068783068783,
      "avg_retrieve_context": 0.07472414536909623,
      "avg_llm_response": 3.7133963108062744,
      "avg_total": 3.7881204561753705,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9397538276532378,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.6448412698114419,
      "answer_correctness": 0.6681988730234798,
      "EM": 0.0,
      "F1": 0.4176755447941889,
      "avg_retrieve_context": 0.07472414536909623,
      "avg_llm_response": 2.407132387161255,
      "avg_total": 2.481856532530351,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.17961424078404545,
      "faithfulness": 0.7,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.789632963375716,
      "EM": 0.4,
      "F1": 0.7635555555555555,
      "avg_retrieve_context": 0.07472414536909623,
      "avg_llm_response": 1.4737233161926269,
      "avg_total": 1.548447461561723,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.720333537524383,
      "faithfulness": 0.8375925925925927,
      "context_recall": 0.9611111111111111,
      "context_precision": 0.7948214285337049,
      "answer_correctness": 0.6613497835407511,
      "EM": 0.03333333333333333,
      "F1": 0.40311997476461514,
      "avg_retrieve_context": 0.07472414536909623,
      "avg_llm_response": 2.620552357037862,
      "avg_total": 2.6952765024069576,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.8116053758906878,
      "faithfulness": 0.8479166666666668,
      "context_recall": 0.925,
      "context_precision": 0.7034691121520733,
      "answer_correctness": 0.6944247768178409,
      "EM": 0.0,
      "F1": 0.44237017212006347,
      "avg_retrieve_context": 0.07472414536909623,
      "avg_llm_response": 2.295778828859329,
      "avg_total": 2.370502974228425,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.17961424078404545,
      "faithfulness": 0.7,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.789632963375716,
      "EM": 0.4,
      "F1": 0.7635555555555555,
      "avg_retrieve_context": 0.07472414536909623,
      "avg_llm_response": 1.4737233161926269,
      "avg_total": 1.548447461561723,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.17961424078404545,
      "faithfulness": 0.7,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.789632963375716,
      "EM": 0.4,
      "F1": 0.7635555555555555,
      "avg_retrieve_context": 0.07472414536909623,
      "avg_llm_response": 1.4737233161926269,
      "avg_total": 1.548447461561723,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7707033511718283,
      "faithfulness": 0.842002442002442,
      "context_recall": 0.9560439560439561,
      "context_precision": 0.7490697998413071,
      "answer_correctness": 0.6863978634929709,
      "EM": 0.02197802197802198,
      "F1": 0.4344257788659973,
      "avg_retrieve_context": 0.07472414536909622,
      "avg_llm_response": 2.4735177951854666,
      "avg_total": 2.548241940554562,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.6166913700504573,
      "faithfulness": 0.8388888888888889,
      "context_recall": 0.8518518518518517,
      "context_precision": 0.8514109347273641,
      "answer_correctness": 0.55508583414426,
      "EM": 0.0,
      "F1": 0.2610288326526319,
      "avg_retrieve_context": 0.07472414536909623,
      "avg_llm_response": 2.663797246085273,
      "avg_total": 2.738521391454369,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7562698926276258,
      "faithfulness": 0.8448765432098766,
      "context_recall": 0.9444444444444444,
      "context_precision": 0.756582612433915,
      "answer_correctness": 0.6799039249296275,
      "EM": 0.022222222222222223,
      "F1": 0.42938202758723726,
      "avg_retrieve_context": 0.07472414536909623,
      "avg_llm_response": 2.5410082605150013,
      "avg_total": 2.615732405884097,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.4708039679222315,
      "faithfulness": 0.7566666666666666,
      "context_recall": 0.9333333333333332,
      "context_precision": 0.386780753952643,
      "answer_correctness": 0.708147723762469,
      "EM": 0.2,
      "F1": 0.5436589221691821,
      "avg_retrieve_context": 0.07472414536909625,
      "avg_llm_response": 1.7555392146110536,
      "avg_total": 1.8302633599801497,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 8,
  "negative_rejection_percentage": 80.0
}