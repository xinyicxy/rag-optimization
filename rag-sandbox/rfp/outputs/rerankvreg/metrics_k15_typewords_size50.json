{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.7239185138567662,
      "faithfulness": 0.8165184310638857,
      "context_recall": 0.9015151515151514,
      "context_precision": 0.649450159365122,
      "answer_correctness": 0.5944471412749787,
      "EM": 0.045454545454545456,
      "F1": 0.4323999033627387,
      "avg_retrieve_context": 0.0590470552444458,
      "avg_llm_response": 1.531892921707847,
      "avg_total": 1.5909399769522916,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.7695637720000913,
      "faithfulness": 0.868140589569161,
      "context_recall": 0.8650793650793651,
      "context_precision": 0.6741982524906687,
      "answer_correctness": 0.5468443869045778,
      "EM": 0.0,
      "F1": 0.31315117979699736,
      "avg_retrieve_context": 0.05904705524444579,
      "avg_llm_response": 1.6125138600667317,
      "avg_total": 1.6715609153111781,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.6460661103672987,
      "faithfulness": 0.6999666999667,
      "context_recall": 0.8846153846153846,
      "context_precision": 0.8050935175532957,
      "answer_correctness": 0.5727182659852205,
      "EM": 0.0,
      "F1": 0.43237225389481027,
      "avg_retrieve_context": 0.059047055244445784,
      "avg_llm_response": 1.6101760864257812,
      "avg_total": 1.6692231416702268,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7277702906559264,
      "faithfulness": 0.7916666666666666,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.6535523889351927,
      "answer_correctness": 0.48705144228476666,
      "EM": 0.0,
      "F1": 0.3693852792230074,
      "avg_retrieve_context": 0.059047055244445784,
      "avg_llm_response": 1.0464768608411152,
      "avg_total": 1.105523916085561,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.7397159778460317,
      "faithfulness": 0.8904761904761905,
      "context_recall": 0.7857142857142857,
      "context_precision": 0.6866239315917239,
      "answer_correctness": 0.5159845829368633,
      "EM": 0.0,
      "F1": 0.4041270653005317,
      "avg_retrieve_context": 0.05904705524444578,
      "avg_llm_response": 1.2314172301973616,
      "avg_total": 1.2904642854418071,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.6370942625442992,
      "faithfulness": 0.7916666666666666,
      "context_recall": 0.9166666666666666,
      "context_precision": 0.6550764050506365,
      "answer_correctness": 0.6361941590099248,
      "EM": 0.0,
      "F1": 0.36863876863876865,
      "avg_retrieve_context": 0.059047055244445805,
      "avg_llm_response": 1.1936896642049153,
      "avg_total": 1.2527367194493613,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.7632800860926826,
      "faithfulness": 0.9,
      "context_recall": 1.0,
      "context_precision": 0.5761904761522698,
      "answer_correctness": 0.33553635262201287,
      "EM": 0.0,
      "F1": 0.27377911848500086,
      "avg_retrieve_context": 0.0590470552444458,
      "avg_llm_response": 2.620256042480469,
      "avg_total": 2.6793030977249144,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.8381741855655085,
      "faithfulness": 0.9375,
      "context_recall": 1.0,
      "context_precision": 0.8162832884382625,
      "answer_correctness": 0.7616006523327713,
      "EM": 0.0,
      "F1": 0.4817214907046017,
      "avg_retrieve_context": 0.0590470552444458,
      "avg_llm_response": 1.8773542642593384,
      "avg_total": 1.9364013195037844,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.9581812154542012,
      "faithfulness": 0.6944444444444443,
      "context_recall": 1.0,
      "context_precision": 0.8988444425369325,
      "answer_correctness": 0.6293543673212768,
      "EM": 0.0,
      "F1": 0.6271305799934832,
      "avg_retrieve_context": 0.059047055244445805,
      "avg_llm_response": 0.832303524017334,
      "avg_total": 0.8913505792617799,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9490395787586684,
      "faithfulness": 0.9166666666666666,
      "context_recall": 1.0,
      "context_precision": 0.7526468060387753,
      "answer_correctness": 0.7655670132373382,
      "EM": 0.0,
      "F1": 0.48144019061311055,
      "avg_retrieve_context": 0.059047055244445805,
      "avg_llm_response": 3.1458222468694053,
      "avg_total": 3.204869302113851,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.9621777119617749,
      "faithfulness": 0.9285714285714286,
      "context_recall": 1.0,
      "context_precision": 0.5879056306785256,
      "answer_correctness": 0.7278306528733516,
      "EM": 0.0,
      "F1": 0.5865721452303532,
      "avg_retrieve_context": 0.0590470552444458,
      "avg_llm_response": 1.0779804587364197,
      "avg_total": 1.1370275139808654,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.6094925607721996,
      "faithfulness": 0.7962962962962963,
      "context_recall": 1.0,
      "context_precision": 0.7490740740488735,
      "answer_correctness": 0.6861498299102086,
      "EM": 0.0,
      "F1": 0.4671857619577308,
      "avg_retrieve_context": 0.05904705524444579,
      "avg_llm_response": 3.0119205315907798,
      "avg_total": 3.0709675868352257,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9590857256717974,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.7551527176369197,
      "answer_correctness": 0.7266072304892842,
      "EM": 0.0,
      "F1": 0.33251231527093594,
      "avg_retrieve_context": 0.0590470552444458,
      "avg_llm_response": 1.2296686172485352,
      "avg_total": 1.288715672492981,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.2599026462714128,
      "faithfulness": 0.6,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.7011547707524288,
      "EM": 0.5,
      "F1": 0.6777777777777778,
      "avg_retrieve_context": 0.05904705524444579,
      "avg_llm_response": 0.8957550048828125,
      "avg_total": 0.9548020601272583,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7274827637415393,
      "faithfulness": 0.8216197691197691,
      "context_recall": 0.8444444444444446,
      "context_precision": 0.7013290456667222,
      "answer_correctness": 0.5332911841889548,
      "EM": 0.0,
      "F1": 0.37145693902088356,
      "avg_retrieve_context": 0.05904705524444582,
      "avg_llm_response": 1.409877395629883,
      "avg_total": 1.4689244508743287,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.8345761059259447,
      "faithfulness": 0.8629960317460317,
      "context_recall": 0.9875,
      "context_precision": 0.7339943697540019,
      "answer_correctness": 0.6595041695346519,
      "EM": 0.0,
      "F1": 0.4624698812717617,
      "avg_retrieve_context": 0.0590470552444458,
      "avg_llm_response": 1.8739506900310516,
      "avg_total": 1.9329977452754974,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.2599026462714128,
      "faithfulness": 0.6,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.7011547707524288,
      "EM": 0.5,
      "F1": 0.6777777777777778,
      "avg_retrieve_context": 0.05904705524444579,
      "avg_llm_response": 0.8957550048828125,
      "avg_total": 0.9548020601272583,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.2599026462714128,
      "faithfulness": 0.6,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.7011547707524288,
      "EM": 0.5,
      "F1": 0.6777777777777778,
      "avg_retrieve_context": 0.05904705524444579,
      "avg_llm_response": 0.8957550048828125,
      "avg_total": 0.9548020601272583,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7737767564685826,
      "faithfulness": 0.8379422165136451,
      "context_recall": 0.9102564102564104,
      "context_precision": 0.7140897353393735,
      "answer_correctness": 0.5838349358508375,
      "EM": 0.0,
      "F1": 0.4205442734205464,
      "avg_retrieve_context": 0.059047055244445805,
      "avg_llm_response": 1.5604834189781775,
      "avg_total": 1.6195304742226226,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.7353694692099026,
      "faithfulness": 0.8404761904761906,
      "context_recall": 0.8148148148148148,
      "context_precision": 0.7174835126978264,
      "answer_correctness": 0.583184296699683,
      "EM": 0.0,
      "F1": 0.2796314123170845,
      "avg_retrieve_context": 0.05904705524444579,
      "avg_llm_response": 1.949631134668986,
      "avg_total": 2.008678189913432,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7715677327572363,
      "faithfulness": 0.8468558601891936,
      "context_recall": 0.9092592592592593,
      "context_precision": 0.7149293670509868,
      "answer_correctness": 0.591957396897676,
      "EM": 0.0,
      "F1": 0.4129403652993969,
      "avg_retrieve_context": 0.0590470552444458,
      "avg_llm_response": 1.6577005412843493,
      "avg_total": 1.7167475965287944,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.5094970288046495,
      "faithfulness": 0.6799999999999999,
      "context_recall": 0.8666666666666666,
      "context_precision": 0.35479372477873056,
      "answer_correctness": 0.6056509909728398,
      "EM": 0.25,
      "F1": 0.5199678246477765,
      "avg_retrieve_context": 0.05904705524444579,
      "avg_llm_response": 0.9657586336135864,
      "avg_total": 1.0248056888580321,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 7,
  "negative_rejection_percentage": 70.0
}