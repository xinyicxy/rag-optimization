{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.732990787876409,
      "faithfulness": 0.8719588744588745,
      "context_recall": 0.9393939393939394,
      "context_precision": 0.6728752347409062,
      "answer_correctness": 0.7070044487033867,
      "EM": 0.06363636363636363,
      "F1": 0.4927773179221299,
      "avg_retrieve_context": 0.07564689029346815,
      "avg_llm_response": 1.3922678318890658,
      "avg_total": 1.4679147221825337,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.7136476068426182,
      "faithfulness": 0.8638888888888888,
      "context_recall": 0.9206349206349207,
      "context_precision": 0.8077362055506695,
      "answer_correctness": 0.5895107687128173,
      "EM": 0.0,
      "F1": 0.32601218583981917,
      "avg_retrieve_context": 0.07564689029346813,
      "avg_llm_response": 1.3904616719200498,
      "avg_total": 1.4661085622135184,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7031691526845167,
      "faithfulness": 0.7923076923076924,
      "context_recall": 0.9230769230769231,
      "context_precision": 0.6942612942353301,
      "answer_correctness": 0.628574989399369,
      "EM": 0.07692307692307693,
      "F1": 0.5000624705618504,
      "avg_retrieve_context": 0.07564689029346815,
      "avg_llm_response": 2.6403452983269324,
      "avg_total": 2.7159921886204015,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.796505858016921,
      "faithfulness": 0.9583333333333334,
      "context_recall": 1.0,
      "context_precision": 0.7428571428160914,
      "answer_correctness": 0.6355513118534687,
      "EM": 0.0,
      "F1": 0.43133234065052184,
      "avg_retrieve_context": 0.07564689029346815,
      "avg_llm_response": 0.7882249553998312,
      "avg_total": 0.8638718456932993,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.813767847106391,
      "faithfulness": 0.9571428571428572,
      "context_recall": 1.0,
      "context_precision": 0.6612811791076952,
      "answer_correctness": 0.7573689572320482,
      "EM": 0.07142857142857142,
      "F1": 0.5324560281370057,
      "avg_retrieve_context": 0.07564689029346815,
      "avg_llm_response": 1.635319403239659,
      "avg_total": 1.7109662935331278,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.9244429011728615,
      "faithfulness": 0.7916666666666666,
      "context_recall": 1.0,
      "context_precision": 0.7150958994467355,
      "answer_correctness": 0.9061802857687765,
      "EM": 0.0,
      "F1": 0.552717052438396,
      "avg_retrieve_context": 0.07564689029346815,
      "avg_llm_response": 0.9111388524373373,
      "avg_total": 0.9867857427308054,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.9568677565754526,
      "faithfulness": 0.86,
      "context_recall": 1.0,
      "context_precision": 0.7644444443834073,
      "answer_correctness": 0.8653771605736852,
      "EM": 0.0,
      "F1": 0.5489126559714794,
      "avg_retrieve_context": 0.07564689029346813,
      "avg_llm_response": 1.422221565246582,
      "avg_total": 1.49786845554005,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.7173582512942055,
      "faithfulness": 0.8571428571428572,
      "context_recall": 1.0,
      "context_precision": 0.8464232567591292,
      "answer_correctness": 0.7095823899911802,
      "EM": 0.0,
      "F1": 0.39780032467532467,
      "avg_retrieve_context": 0.07564689029346813,
      "avg_llm_response": 0.8090883493423462,
      "avg_total": 0.8847352396358144,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.815463485078086,
      "faithfulness": 0.861111111111111,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.7207754629169741,
      "answer_correctness": 0.7881493659266027,
      "EM": 0.0,
      "F1": 0.5190110443004181,
      "avg_retrieve_context": 0.07564689029346815,
      "avg_llm_response": 0.6866252422332764,
      "avg_total": 0.7622721325267445,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9587705357325799,
      "faithfulness": 1.0,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.6634516460760825,
      "answer_correctness": 0.8384494446534178,
      "EM": 0.0,
      "F1": 0.6453081232492998,
      "avg_retrieve_context": 0.07564689029346815,
      "avg_llm_response": 1.7321579456329346,
      "avg_total": 1.8078048359264027,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.6598278748465711,
      "faithfulness": 0.875,
      "context_recall": 1.0,
      "context_precision": 0.7588252314437921,
      "answer_correctness": 0.627712730396609,
      "EM": 0.0,
      "F1": 0.3890316205533597,
      "avg_retrieve_context": 0.07564689029346813,
      "avg_llm_response": 1.8424965143203735,
      "avg_total": 1.9181434046138417,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.8860842513781729,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.7759259258811729,
      "answer_correctness": 0.9577129077976195,
      "EM": 0.0,
      "F1": 0.6464352972827548,
      "avg_retrieve_context": 0.07564689029346813,
      "avg_llm_response": 1.961696942647298,
      "avg_total": 2.0373438329407665,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.8603712342361398,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.6517857142639881,
      "answer_correctness": 0.578181986794137,
      "EM": 0.0,
      "F1": 0.3799295774647887,
      "avg_retrieve_context": 0.07564689029346813,
      "avg_llm_response": 1.6656309366226196,
      "avg_total": 1.7412778269160878,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.18167947349936214,
      "faithfulness": 0.7,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7248934089263057,
      "EM": 0.5,
      "F1": 0.7743589743589745,
      "avg_retrieve_context": 0.07564689029346813,
      "avg_llm_response": 0.7122420787811279,
      "avg_total": 0.787888969074596,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7513103147381038,
      "faithfulness": 0.8890277777777779,
      "context_recall": 0.9555555555555555,
      "context_precision": 0.736001322715403,
      "answer_correctness": 0.646349702477521,
      "EM": 0.03333333333333333,
      "F1": 0.43295734169440997,
      "avg_retrieve_context": 0.07564689029346815,
      "avg_llm_response": 1.5979559183120728,
      "avg_total": 1.6736028086055408,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.8433393261781289,
      "faithfulness": 0.8893452380952382,
      "context_recall": 0.95,
      "context_precision": 0.746404911464387,
      "answer_correctness": 0.7935143279864555,
      "EM": 0.0,
      "F1": 0.512111868154499,
      "avg_retrieve_context": 0.07564689029346813,
      "avg_llm_response": 1.2537421405315399,
      "avg_total": 1.329389030825008,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.18167947349936214,
      "faithfulness": 0.7,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7248934089263057,
      "EM": 0.5,
      "F1": 0.7743589743589745,
      "avg_retrieve_context": 0.07564689029346813,
      "avg_llm_response": 0.7122420787811279,
      "avg_total": 0.787888969074596,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.18167947349936214,
      "faithfulness": 0.7,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7248934089263057,
      "EM": 0.5,
      "F1": 0.7743589743589745,
      "avg_retrieve_context": 0.07564689029346813,
      "avg_llm_response": 0.7122420787811279,
      "avg_total": 0.787888969074596,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.815491432801083,
      "faithfulness": 0.9005363683935114,
      "context_recall": 0.9633699633699633,
      "context_precision": 0.7323374109130226,
      "answer_correctness": 0.7282159593574548,
      "EM": 0.02197802197802198,
      "F1": 0.4859795247270597,
      "avg_retrieve_context": 0.07564689029346815,
      "avg_llm_response": 1.4649492358113383,
      "avg_total": 1.540596126104806,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.511385727390312,
      "faithfulness": 0.7740740740740741,
      "context_recall": 0.8518518518518517,
      "context_precision": 0.8192857142682907,
      "answer_correctness": 0.47265588517567697,
      "EM": 0.0,
      "F1": 0.24864205307579043,
      "avg_retrieve_context": 0.07564689029346813,
      "avg_llm_response": 1.4129622512393527,
      "avg_total": 1.4886091415328209,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.8021336041278161,
      "faithfulness": 0.8990608465608466,
      "context_recall": 0.9518518518518517,
      "context_precision": 0.7449515655683001,
      "answer_correctness": 0.7227021890091079,
      "EM": 0.022222222222222223,
      "F1": 0.47767429791073546,
      "avg_retrieve_context": 0.07564689029346815,
      "avg_llm_response": 1.5335434065924751,
      "avg_total": 1.609190296885943,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.4218481147450771,
      "faithfulness": 0.75,
      "context_recall": 0.8833333333333332,
      "context_precision": 0.3485317460176333,
      "answer_correctness": 0.6363646173276409,
      "EM": 0.25,
      "F1": 0.5607409079734051,
      "avg_retrieve_context": 0.07564689029346813,
      "avg_llm_response": 0.7565277457237244,
      "avg_total": 0.8321746360171925,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 8,
  "negative_rejection_percentage": 80.0
}