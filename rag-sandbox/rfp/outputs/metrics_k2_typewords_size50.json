{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6055450798579516,
      "faithfulness": 0.7654545454545454,
      "context_recall": 0.7143181818181819,
      "context_precision": 0.7636363635749999,
      "answer_correctness": 0.6035055257293299,
      "EM": 0.05454545454545454,
      "F1": 0.4045584099534314,
      "avg_retrieve_context": 0.058654000542380604,
      "avg_llm_response": 1.1029861168427901,
      "avg_total": 1.1616401173851705,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.6350324100646362,
      "faithfulness": 0.865079365079365,
      "context_recall": 0.5968253968253967,
      "context_precision": 0.8571428570761903,
      "answer_correctness": 0.5631615509432134,
      "EM": 0.0,
      "F1": 0.2715228092719875,
      "avg_retrieve_context": 0.05865400054238059,
      "avg_llm_response": 1.366675887789045,
      "avg_total": 1.4253298883314254,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7160190580814219,
      "faithfulness": 0.7371794871794871,
      "context_recall": 0.9230769230769231,
      "context_precision": 0.8846153845423077,
      "answer_correctness": 0.6640898476737249,
      "EM": 0.07692307692307693,
      "F1": 0.5513706710478206,
      "avg_retrieve_context": 0.05865400054238058,
      "avg_llm_response": 1.4247416166158824,
      "avg_total": 1.483395617158263,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.543460691293571,
      "faithfulness": 0.7638888888888888,
      "context_recall": 0.625,
      "context_precision": 0.7499999999333333,
      "answer_correctness": 0.5702661214591613,
      "EM": 0.0,
      "F1": 0.32610414218984735,
      "avg_retrieve_context": 0.05865400054238059,
      "avg_llm_response": 0.6847688754399618,
      "avg_total": 0.7434228759823425,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.5383543845876231,
      "faithfulness": 0.744047619047619,
      "context_recall": 0.49107142857142855,
      "context_precision": 0.9285714284857143,
      "answer_correctness": 0.44459439111039334,
      "EM": 0.0,
      "F1": 0.3064477686018498,
      "avg_retrieve_context": 0.05865400054238058,
      "avg_llm_response": 1.2153872762407576,
      "avg_total": 1.274041276783138,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.44009008553686063,
      "faithfulness": 0.6666666666666666,
      "context_recall": 0.5,
      "context_precision": 0.6666666666166666,
      "answer_correctness": 0.5562335464312961,
      "EM": 0.0,
      "F1": 0.19652349828820417,
      "avg_retrieve_context": 0.05865400054238059,
      "avg_llm_response": 0.6413805882136027,
      "avg_total": 0.7000345887559832,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.5704051336531664,
      "faithfulness": 0.6,
      "context_recall": 0.4,
      "context_precision": 0.59999999995,
      "answer_correctness": 0.4199246001016734,
      "EM": 0.0,
      "F1": 0.28943322009654926,
      "avg_retrieve_context": 0.05865400054238059,
      "avg_llm_response": 1.2628399848937988,
      "avg_total": 1.3214939854361796,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.8248576733065471,
      "faithfulness": 0.8583333333333334,
      "context_recall": 1.0,
      "context_precision": 0.93749999993125,
      "answer_correctness": 0.7111404031970541,
      "EM": 0.0,
      "F1": 0.4518491988830008,
      "avg_retrieve_context": 0.05865400054238059,
      "avg_llm_response": 0.8899328410625458,
      "avg_total": 0.9485868416049263,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.7873758295402539,
      "faithfulness": 0.5833333333333334,
      "context_recall": 1.0,
      "context_precision": 0.999999999925,
      "answer_correctness": 0.6579510473824991,
      "EM": 0.0,
      "F1": 0.4752861952861953,
      "avg_retrieve_context": 0.05865400054238059,
      "avg_llm_response": 0.5119549433390299,
      "avg_total": 0.5706089438814105,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9384528585449882,
      "faithfulness": 0.8333333333333334,
      "context_recall": 0.7777777777777777,
      "context_precision": 0.7499999999416667,
      "answer_correctness": 0.599180675109458,
      "EM": 0.0,
      "F1": 0.4346092722227024,
      "avg_retrieve_context": 0.05865400054238059,
      "avg_llm_response": 1.8929926951726277,
      "avg_total": 1.9516466957150087,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.6926631348823149,
      "faithfulness": 0.875,
      "context_recall": 0.5,
      "context_precision": 0.74999999995,
      "answer_correctness": 0.6311181483944188,
      "EM": 0.0,
      "F1": 0.3180980310012568,
      "avg_retrieve_context": 0.05865400054238059,
      "avg_llm_response": 0.7086055278778076,
      "avg_total": 0.7672595284201882,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.6107509276114751,
      "faithfulness": 0.6666666666666666,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.8333333332833334,
      "answer_correctness": 0.6853781328861569,
      "EM": 0.0,
      "F1": 0.407832422586521,
      "avg_retrieve_context": 0.05865400054238059,
      "avg_llm_response": 1.6735450426737468,
      "avg_total": 1.7321990432161278,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9678141562150266,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.999999999925,
      "answer_correctness": 0.6703222626703544,
      "EM": 0.0,
      "F1": 0.3380952380952381,
      "avg_retrieve_context": 0.05865400054238059,
      "avg_llm_response": 0.595050573348999,
      "avg_total": 0.6537045738913796,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.09226074069646865,
      "faithfulness": 0.7,
      "context_recall": 1.0,
      "context_precision": 0.0,
      "answer_correctness": 0.8268342950403774,
      "EM": 0.5,
      "F1": 0.8555555555555555,
      "avg_retrieve_context": 0.05865400054238059,
      "avg_llm_response": 0.8117199420928956,
      "avg_total": 0.8703739426352761,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.6117069674360903,
      "faithfulness": 0.7888888888888889,
      "context_recall": 0.6484722222222222,
      "context_precision": 0.8583333332608333,
      "answer_correctness": 0.5587845920436894,
      "EM": 0.016666666666666666,
      "F1": 0.3512219364172912,
      "avg_retrieve_context": 0.05865400054238058,
      "avg_llm_response": 1.207574717203776,
      "avg_total": 1.2662287177461564,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.7246233332811142,
      "faithfulness": 0.7466666666666667,
      "context_recall": 0.7416666666666666,
      "context_precision": 0.81249999994,
      "answer_correctness": 0.6147547339300293,
      "EM": 0.0,
      "F1": 0.37181383385711075,
      "avg_retrieve_context": 0.05865400054238059,
      "avg_llm_response": 1.0189197599887847,
      "avg_total": 1.0775737605311655,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.09226074069646865,
      "faithfulness": 0.7,
      "context_recall": 1.0,
      "context_precision": 0.0,
      "answer_correctness": 0.8268342950403774,
      "EM": 0.5,
      "F1": 0.8555555555555555,
      "avg_retrieve_context": 0.05865400054238059,
      "avg_llm_response": 0.8117199420928956,
      "avg_total": 0.8703739426352761,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.09226074069646865,
      "faithfulness": 0.7,
      "context_recall": 1.0,
      "context_precision": 0.0,
      "answer_correctness": 0.8268342950403774,
      "EM": 0.5,
      "F1": 0.8555555555555555,
      "avg_retrieve_context": 0.05865400054238059,
      "avg_llm_response": 0.8117199420928956,
      "avg_total": 0.8703739426352761,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.6905788389354419,
      "faithfulness": 0.7714285714285715,
      "context_recall": 0.7147435897435898,
      "context_precision": 0.8296703296032968,
      "answer_correctness": 0.5961576897083101,
      "EM": 0.01098901098901099,
      "F1": 0.3805661565965997,
      "avg_retrieve_context": 0.0586540005423806,
      "avg_llm_response": 1.1085856773041107,
      "avg_total": 1.1672396778464913,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.31607522603164123,
      "faithfulness": 0.7777777777777778,
      "context_recall": 0.3925925925925926,
      "context_precision": 0.9444444443722221,
      "answer_correctness": 0.4296572351518118,
      "EM": 0.0,
      "F1": 0.14603880989237006,
      "avg_retrieve_context": 0.0586540005423806,
      "avg_llm_response": 1.3699974219004314,
      "avg_total": 1.4286514224428122,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.6760005523302528,
      "faithfulness": 0.7707407407407406,
      "context_recall": 0.6749074074074073,
      "context_precision": 0.8388888888211113,
      "answer_correctness": 0.5895406085950604,
      "EM": 0.011111111111111112,
      "F1": 0.37299360921548147,
      "avg_retrieve_context": 0.05865400054238059,
      "avg_llm_response": 1.165713651974996,
      "avg_total": 1.2243676525173766,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.28849545373259644,
      "faithfulness": 0.7416666666666666,
      "context_recall": 0.8916666666666666,
      "context_precision": 0.42499999996749993,
      "answer_correctness": 0.6663476528335428,
      "EM": 0.25,
      "F1": 0.5466000132742062,
      "avg_retrieve_context": 0.05865400054238059,
      "avg_llm_response": 0.8207122087478638,
      "avg_total": 0.8793662092902442,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 9,
  "negative_rejection_percentage": 90.0
}