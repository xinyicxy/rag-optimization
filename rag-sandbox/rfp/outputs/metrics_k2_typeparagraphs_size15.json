{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6157406508014206,
      "faithfulness": 0.7806385281385281,
      "context_recall": 0.787878787878788,
      "context_precision": 0.7454545453972726,
      "answer_correctness": 0.6032617741695273,
      "EM": 0.045454545454545456,
      "F1": 0.41848176776749607,
      "avg_retrieve_context": 0.05626775351437653,
      "avg_llm_response": 1.1602301077409225,
      "avg_total": 1.2164978612552995,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.6256987245980141,
      "faithfulness": 0.7383219954648526,
      "context_recall": 0.8174603174603176,
      "context_precision": 0.9761904761119047,
      "answer_correctness": 0.5540982591080776,
      "EM": 0.0,
      "F1": 0.2802714362043305,
      "avg_retrieve_context": 0.05626775351437655,
      "avg_llm_response": 1.2881378786904472,
      "avg_total": 1.3444056322048237,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7954039042048439,
      "faithfulness": 0.8307692307692308,
      "context_recall": 0.8461538461538461,
      "context_precision": 0.9230769229961537,
      "answer_correctness": 0.6925403897837599,
      "EM": 0.0,
      "F1": 0.48807918384828636,
      "avg_retrieve_context": 0.056267753514376545,
      "avg_llm_response": 1.4723517161149244,
      "avg_total": 1.5286194696293012,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.6322836750681092,
      "faithfulness": 0.8333333333333334,
      "context_recall": 0.9166666666666666,
      "context_precision": 0.8333333332750001,
      "answer_correctness": 0.5781218258019537,
      "EM": 0.0,
      "F1": 0.3425844554612824,
      "avg_retrieve_context": 0.056267753514376545,
      "avg_llm_response": 1.0101159811019897,
      "avg_total": 1.066383734616366,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.5360104559127766,
      "faithfulness": 0.6130952380952381,
      "context_recall": 0.7857142857142857,
      "context_precision": 0.7142857142214286,
      "answer_correctness": 0.49012048053800716,
      "EM": 0.0,
      "F1": 0.4282920176996832,
      "avg_retrieve_context": 0.05626775351437654,
      "avg_llm_response": 1.3603489228657313,
      "avg_total": 1.4166166763801076,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.6268374093584171,
      "faithfulness": 0.7678571428571429,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.74999999995,
      "answer_correctness": 0.5468800129834376,
      "EM": 0.0,
      "F1": 0.3600217864923747,
      "avg_retrieve_context": 0.05626775351437655,
      "avg_llm_response": 0.9383400678634644,
      "avg_total": 0.9946078213778408,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.37800740553390566,
      "faithfulness": 0.6,
      "context_recall": 0.4,
      "context_precision": 0.39999999997,
      "answer_correctness": 0.3495906152890153,
      "EM": 0.0,
      "F1": 0.21217605923488275,
      "avg_retrieve_context": 0.05626775351437655,
      "avg_llm_response": 1.1986149311065675,
      "avg_total": 1.254882684620944,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.8390283476468826,
      "faithfulness": 0.9375,
      "context_recall": 0.875,
      "context_precision": 0.9999999999375,
      "answer_correctness": 0.7994707730486998,
      "EM": 0.0,
      "F1": 0.5270464091791427,
      "avg_retrieve_context": 0.05626775351437655,
      "avg_llm_response": 0.9134246706962585,
      "avg_total": 0.9696924242106351,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.648237978466665,
      "faithfulness": 0.75,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.5833333332833334,
      "answer_correctness": 0.6225556712359798,
      "EM": 0.0,
      "F1": 0.45998133328915175,
      "avg_retrieve_context": 0.05626775351437655,
      "avg_llm_response": 0.5310353438059489,
      "avg_total": 0.5873030973203255,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.7921678787246463,
      "faithfulness": 0.9166666666666666,
      "context_recall": 0.75,
      "context_precision": 0.7499999999583333,
      "answer_correctness": 0.5845418714785248,
      "EM": 0.0,
      "F1": 0.3999385749385749,
      "avg_retrieve_context": 0.05626775351437655,
      "avg_llm_response": 1.533363143603007,
      "avg_total": 1.5896308971173836,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.6985897176579241,
      "faithfulness": 0.96875,
      "context_recall": 0.75,
      "context_precision": 0.74999999995,
      "answer_correctness": 0.5925619257724495,
      "EM": 0.0,
      "F1": 0.37961424880029526,
      "avg_retrieve_context": 0.05626775351437655,
      "avg_llm_response": 0.6665302515029907,
      "avg_total": 0.7227980050173672,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.628776339056477,
      "faithfulness": 0.8333333333333334,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.9999999999166667,
      "answer_correctness": 0.6878668762479756,
      "EM": 0.0,
      "F1": 0.4478632478632479,
      "avg_retrieve_context": 0.05626775351437655,
      "avg_llm_response": 1.8001286188761394,
      "avg_total": 1.8563963723905157,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.8791510229472981,
      "faithfulness": 1.0,
      "context_recall": 0.5,
      "context_precision": 0.499999999975,
      "answer_correctness": 0.43186151970330977,
      "EM": 0.0,
      "F1": 0.28477402369460286,
      "avg_retrieve_context": 0.05626775351437655,
      "avg_llm_response": 1.3475524187088013,
      "avg_total": 1.4038201722231778,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.17152837915001182,
      "faithfulness": 0.75,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7955402046771303,
      "EM": 0.5,
      "F1": 0.7666666666666666,
      "avg_retrieve_context": 0.05626775351437655,
      "avg_llm_response": 0.818905234336853,
      "avg_total": 0.8751729878512297,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.6428579075802908,
      "faithfulness": 0.7481349206349205,
      "context_recall": 0.836111111111111,
      "context_precision": 0.8749999999283332,
      "answer_correctness": 0.5739706190935677,
      "EM": 0.0,
      "F1": 0.3722971877274936,
      "avg_retrieve_context": 0.056267753514376566,
      "avg_llm_response": 1.289295740922292,
      "avg_total": 1.3455634944366683,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.686117833545967,
      "faithfulness": 0.8370535714285715,
      "context_recall": 0.7125,
      "context_precision": 0.73749999995,
      "answer_correctness": 0.5991288991565668,
      "EM": 0.0,
      "F1": 0.4007124131027073,
      "avg_retrieve_context": 0.05626775351437655,
      "avg_llm_response": 1.0519628763198852,
      "avg_total": 1.108230629834262,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.17152837915001182,
      "faithfulness": 0.75,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7955402046771303,
      "EM": 0.5,
      "F1": 0.7666666666666666,
      "avg_retrieve_context": 0.05626775351437655,
      "avg_llm_response": 0.818905234336853,
      "avg_total": 0.8751729878512297,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.17152837915001182,
      "faithfulness": 0.75,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7955402046771303,
      "EM": 0.5,
      "F1": 0.7666666666666666,
      "avg_retrieve_context": 0.05626775351437655,
      "avg_llm_response": 0.818905234336853,
      "avg_total": 0.8751729878512297,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.6745289442793911,
      "faithfulness": 0.7966902145473574,
      "context_recall": 0.7985347985347986,
      "context_precision": 0.8021978021346156,
      "answer_correctness": 0.6051465971337644,
      "EM": 0.0,
      "F1": 0.40255949094296206,
      "avg_retrieve_context": 0.05626775351437654,
      "avg_llm_response": 1.165833177147331,
      "avg_total": 1.2221009306617072,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.5148948741368374,
      "faithfulness": 0.6523809523809523,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.999999999938889,
      "answer_correctness": 0.3705614191893518,
      "EM": 0.0,
      "F1": 0.19260156799426242,
      "avg_retrieve_context": 0.05626775351437655,
      "avg_llm_response": 1.4828267097473145,
      "avg_total": 1.5390944632616912,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.6719456100488606,
      "faithfulness": 0.7918915343915345,
      "context_recall": 0.7777777777777778,
      "context_precision": 0.7999999999388889,
      "answer_correctness": 0.5924097436542011,
      "EM": 0.0,
      "F1": 0.3957515723464355,
      "avg_retrieve_context": 0.056267753514376545,
      "avg_llm_response": 1.244706752565172,
      "avg_total": 1.3009745060795483,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.36281833418793985,
      "faithfulness": 0.73,
      "context_recall": 0.8333333333333333,
      "context_precision": 0.49999999996,
      "answer_correctness": 0.6520959114884965,
      "EM": 0.25,
      "F1": 0.5207676471622693,
      "avg_retrieve_context": 0.05626775351437655,
      "avg_llm_response": 0.7800852060317993,
      "avg_total": 0.836352959546176,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 8,
  "negative_rejection_percentage": 80.0
}