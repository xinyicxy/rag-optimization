{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.7011990618590633,
      "faithfulness": 0.8187529137529137,
      "context_recall": 0.9610606060606061,
      "context_precision": 0.7709042722787702,
      "answer_correctness": 0.7043271551022867,
      "EM": 0.07272727272727272,
      "F1": 0.4959791123645636,
      "avg_retrieve_context": 0.08577125505967574,
      "avg_llm_response": 1.878075367754156,
      "avg_total": 1.9638466228138323,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.6665756515509911,
      "faithfulness": 0.8412698412698412,
      "context_recall": 0.9722222222222221,
      "context_precision": 0.8534391533980534,
      "answer_correctness": 0.6586756608186247,
      "EM": 0.0,
      "F1": 0.31671194849675194,
      "avg_retrieve_context": 0.08577125505967571,
      "avg_llm_response": 2.316992543992542,
      "avg_total": 2.402763799052218,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.8621901687525478,
      "faithfulness": 0.7948717948717948,
      "context_recall": 0.8846153846153846,
      "context_precision": 0.9871794871185897,
      "answer_correctness": 0.7067582973413008,
      "EM": 0.07692307692307693,
      "F1": 0.5750170735414428,
      "avg_retrieve_context": 0.08577125505967573,
      "avg_llm_response": 1.8961704694307768,
      "avg_total": 1.9819417244904527,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.8755453054207555,
      "faithfulness": 0.875,
      "context_recall": 1.0,
      "context_precision": 0.9999999999416666,
      "answer_correctness": 0.7335484486097515,
      "EM": 0.0,
      "F1": 0.4487332921208877,
      "avg_retrieve_context": 0.08577125505967574,
      "avg_llm_response": 0.9633762836456299,
      "avg_total": 1.0491475387053055,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.725882468561622,
      "faithfulness": 0.9354395604395604,
      "context_recall": 0.9857142857142858,
      "context_precision": 0.7332148930715819,
      "answer_correctness": 0.6467175397028291,
      "EM": 0.14285714285714285,
      "F1": 0.552595731254604,
      "avg_retrieve_context": 0.08577125505967573,
      "avg_llm_response": 2.8692071437835693,
      "avg_total": 2.954978398843245,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.9691048443890002,
      "faithfulness": 0.8472222222222222,
      "context_recall": 1.0,
      "context_precision": 0.7797949735158607,
      "answer_correctness": 0.9064164911019442,
      "EM": 0.0,
      "F1": 0.5294563328328811,
      "avg_retrieve_context": 0.08577125505967574,
      "avg_llm_response": 1.6098577578862507,
      "avg_total": 1.6956290129459266,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.7657190617998044,
      "faithfulness": 0.6766666666666666,
      "context_recall": 1.0,
      "context_precision": 0.6285714285238095,
      "answer_correctness": 0.7123239407226907,
      "EM": 0.0,
      "F1": 0.42904336838672863,
      "avg_retrieve_context": 0.08577125505967574,
      "avg_llm_response": 2.666216993331909,
      "avg_total": 2.751988248391585,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.7098203910736951,
      "faithfulness": 0.8125,
      "context_recall": 1.0,
      "context_precision": 0.8088541666339453,
      "answer_correctness": 0.6625606468975347,
      "EM": 0.0,
      "F1": 0.48251456585227204,
      "avg_retrieve_context": 0.08577125505967574,
      "avg_llm_response": 1.623095065355301,
      "avg_total": 1.7088663204149768,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.813915738156501,
      "faithfulness": 0.6666666666666666,
      "context_recall": 1.0,
      "context_precision": 0.8336026076673413,
      "answer_correctness": 0.6228005015697679,
      "EM": 0.0,
      "F1": 0.5776861355490387,
      "avg_retrieve_context": 0.08577125505967574,
      "avg_llm_response": 1.1789519786834717,
      "avg_total": 1.2647232337431473,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.95730490244795,
      "faithfulness": 0.861111111111111,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.87543461827893,
      "answer_correctness": 0.7234564845370959,
      "EM": 0.0,
      "F1": 0.563423081321606,
      "avg_retrieve_context": 0.08577125505967574,
      "avg_llm_response": 2.432191332181295,
      "avg_total": 2.5179625872409708,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.204421033981021,
      "faithfulness": 0.5,
      "context_recall": 1.0,
      "context_precision": 0.8291666666417709,
      "answer_correctness": 0.31209041493250045,
      "EM": 0.0,
      "F1": 0.13953612845673505,
      "avg_retrieve_context": 0.08577125505967574,
      "avg_llm_response": 1.2254009246826172,
      "avg_total": 1.311172179742293,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.5740267458124751,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.7755555555317944,
      "answer_correctness": 0.7256495158410866,
      "EM": 0.0,
      "F1": 0.4481074481074481,
      "avg_retrieve_context": 0.08577125505967574,
      "avg_llm_response": 2.439060846964518,
      "avg_total": 2.524832102024194,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9400249120573747,
      "faithfulness": 0.6666666666666666,
      "context_recall": 1.0,
      "context_precision": 0.794444444417963,
      "answer_correctness": 0.8872927016043024,
      "EM": 0.0,
      "F1": 0.4118203309692672,
      "avg_retrieve_context": 0.08577125505967574,
      "avg_llm_response": 1.8307528495788574,
      "avg_total": 1.9165241046385333,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.08875121582057036,
      "faithfulness": 0.8,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.9021272026958472,
      "EM": 0.5,
      "F1": 0.8555555555555555,
      "avg_retrieve_context": 0.08577125505967574,
      "avg_llm_response": 0.8029671669006347,
      "avg_total": 0.8887384219603106,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7645909850210949,
      "faithfulness": 0.8599358974358975,
      "context_recall": 0.9619444444444445,
      "context_precision": 0.8836760676033821,
      "answer_correctness": 0.6812778946964109,
      "EM": 0.05,
      "F1": 0.45412187695809425,
      "avg_retrieve_context": 0.08577125505967574,
      "avg_llm_response": 2.0839412490526836,
      "avg_total": 2.1697125041123595,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.7592231386256387,
      "faithfulness": 0.7616666666666667,
      "context_recall": 0.975,
      "context_precision": 0.7944726473615449,
      "answer_correctness": 0.6894510338127112,
      "EM": 0.0,
      "F1": 0.46887085467651984,
      "avg_retrieve_context": 0.08577125505967574,
      "avg_llm_response": 1.8380535960197448,
      "avg_total": 1.9238248510794207,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.08875121582057036,
      "faithfulness": 0.8,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.9021272026958472,
      "EM": 0.5,
      "F1": 0.8555555555555555,
      "avg_retrieve_context": 0.08577125505967574,
      "avg_llm_response": 0.8029671669006347,
      "avg_total": 0.8887384219603106,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.08875121582057036,
      "faithfulness": 0.8,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.9021272026958472,
      "EM": 0.5,
      "F1": 0.8555555555555555,
      "avg_retrieve_context": 0.08577125505967574,
      "avg_llm_response": 0.8029671669006347,
      "avg_total": 0.8887384219603106,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7986443379369816,
      "faithfulness": 0.8303606649760495,
      "context_recall": 0.9703296703296703,
      "context_precision": 0.8384557137461325,
      "answer_correctness": 0.6989965045133971,
      "EM": 0.03296703296703297,
      "F1": 0.4849451819210216,
      "avg_retrieve_context": 0.08577125505967576,
      "avg_llm_response": 1.9856837031605479,
      "avg_total": 2.071454958220224,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.3964166548917681,
      "faithfulness": 0.7222222222222222,
      "context_recall": 0.9351851851851851,
      "context_precision": 0.9444444444185185,
      "answer_correctness": 0.5384481248415517,
      "EM": 0.0,
      "F1": 0.20801502774816372,
      "avg_retrieve_context": 0.08577125505967574,
      "avg_llm_response": 1.9846001995934381,
      "avg_total": 2.070371454653114,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7845946672937208,
      "faithfulness": 0.8303276353276355,
      "context_recall": 0.9672222222222222,
      "context_precision": 0.8440681846417748,
      "answer_correctness": 0.7037646371097135,
      "EM": 0.03333333333333333,
      "F1": 0.47838350946037655,
      "avg_retrieve_context": 0.08577125505967574,
      "avg_llm_response": 2.058329388830397,
      "avg_total": 2.1441006438900727,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.32591883740310346,
      "faithfulness": 0.7666666666666666,
      "context_recall": 0.9333333333333332,
      "context_precision": 0.44166666664524995,
      "answer_correctness": 0.706858486068868,
      "EM": 0.25,
      "F1": 0.5751593254334055,
      "avg_retrieve_context": 0.08577125505967573,
      "avg_llm_response": 1.0669322729110717,
      "avg_total": 1.1527035279707476,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 9,
  "negative_rejection_percentage": 90.0
}