{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.7171288019369039,
      "faithfulness": 0.8597868797868798,
      "context_recall": 0.9439393939393941,
      "context_precision": 0.6912010484049868,
      "answer_correctness": 0.7073856546614153,
      "EM": 0.05454545454545454,
      "F1": 0.5252104068659811,
      "avg_retrieve_context": 0.06141637455333362,
      "avg_llm_response": 1.5181342233311046,
      "avg_total": 1.5795505978844384,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.718871498875668,
      "faithfulness": 0.8514739229024942,
      "context_recall": 0.9444444444444444,
      "context_precision": 0.8040347124163292,
      "answer_correctness": 0.6158736051520906,
      "EM": 0.0,
      "F1": 0.3544385002727114,
      "avg_retrieve_context": 0.06141637455333363,
      "avg_llm_response": 1.8509262516385032,
      "avg_total": 1.9123426261918364,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7074595175001467,
      "faithfulness": 0.8461538461538461,
      "context_recall": 0.8461538461538461,
      "context_precision": 0.7085552161211459,
      "answer_correctness": 0.6282858172683401,
      "EM": 0.0,
      "F1": 0.512028487507475,
      "avg_retrieve_context": 0.061416374553333625,
      "avg_llm_response": 1.9561526041764479,
      "avg_total": 2.017568978729781,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7283263700775003,
      "faithfulness": 0.8583333333333334,
      "context_recall": 1.0,
      "context_precision": 0.7924933862027296,
      "answer_correctness": 0.7638454489665109,
      "EM": 0.08333333333333333,
      "F1": 0.4999877920516866,
      "avg_retrieve_context": 0.061416374553333625,
      "avg_llm_response": 1.3113661011060078,
      "avg_total": 1.3727824756593414,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.8009879795475617,
      "faithfulness": 0.8717948717948717,
      "context_recall": 1.0,
      "context_precision": 0.8084727205508049,
      "answer_correctness": 0.7260293418561822,
      "EM": 0.0,
      "F1": 0.579849544349526,
      "avg_retrieve_context": 0.06141637455333362,
      "avg_llm_response": 1.427784834589277,
      "avg_total": 1.4892012091426103,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.7793231372854122,
      "faithfulness": 0.8511904761904763,
      "context_recall": 1.0,
      "context_precision": 0.6461748436431047,
      "answer_correctness": 0.7312481826539083,
      "EM": 0.0,
      "F1": 0.40577342047930287,
      "avg_retrieve_context": 0.06141637455333363,
      "avg_llm_response": 1.3711396058400471,
      "avg_total": 1.4325559803933807,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.7676245934800205,
      "faithfulness": 0.9,
      "context_recall": 1.0,
      "context_precision": 0.5254166666306145,
      "answer_correctness": 0.659194066664585,
      "EM": 0.0,
      "F1": 0.4627533888819798,
      "avg_retrieve_context": 0.06141637455333363,
      "avg_llm_response": 1.5376984119415282,
      "avg_total": 1.5991147864948618,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.83286814235686,
      "faithfulness": 0.9375,
      "context_recall": 1.0,
      "context_precision": 0.8948141904017161,
      "answer_correctness": 0.7024077769535437,
      "EM": 0.0,
      "F1": 0.4854749292189995,
      "avg_retrieve_context": 0.06141637455333363,
      "avg_llm_response": 1.126842439174652,
      "avg_total": 1.1882588137279857,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.9707875141438724,
      "faithfulness": 0.8333333333333334,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.8187499999541338,
      "answer_correctness": 0.6869044048270934,
      "EM": 0.0,
      "F1": 0.6577339880233617,
      "avg_retrieve_context": 0.06141637455333363,
      "avg_llm_response": 0.7921300331751505,
      "avg_total": 0.8535464077284841,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.8020645808806929,
      "faithfulness": 0.9583333333333334,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.6350831738352501,
      "answer_correctness": 0.7027211280368606,
      "EM": 0.0,
      "F1": 0.6123659084460044,
      "avg_retrieve_context": 0.06141637455333363,
      "avg_llm_response": 2.3644906679789224,
      "avg_total": 2.425907042532256,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.9083342626403736,
      "faithfulness": 0.9166666666666666,
      "context_recall": 1.0,
      "context_precision": 0.7360923577960176,
      "answer_correctness": 0.8906168528771461,
      "EM": 0.0,
      "F1": 0.5547117799953875,
      "avg_retrieve_context": 0.06141637455333363,
      "avg_llm_response": 1.2268316745758057,
      "avg_total": 1.2882480491291393,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.8725648274391697,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.8425925925448302,
      "answer_correctness": 0.936660449252735,
      "EM": 0.0,
      "F1": 0.6226318484383001,
      "avg_retrieve_context": 0.06141637455333363,
      "avg_llm_response": 1.9107128779093425,
      "avg_total": 1.9721292524626761,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.876262564859657,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.6249188311532081,
      "answer_correctness": 0.6115594430959048,
      "EM": 0.0,
      "F1": 0.3303571428571429,
      "avg_retrieve_context": 0.06141637455333363,
      "avg_llm_response": 1.3495492935180664,
      "avg_total": 1.4109656680714,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.0819468691859453,
      "faithfulness": 0.6666666666666667,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.814476201897163,
      "EM": 0.5,
      "F1": 0.8555555555555555,
      "avg_retrieve_context": 0.06141637455333363,
      "avg_llm_response": 0.9761591196060181,
      "avg_total": 1.0375754941593516,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7374503893081135,
      "faithfulness": 0.8564346764346763,
      "context_recall": 0.9472222222222223,
      "context_precision": 0.7820747582076971,
      "answer_correctness": 0.6738602917711168,
      "EM": 0.016666666666666666,
      "F1": 0.47028876614729526,
      "avg_retrieve_context": 0.06141637455333363,
      "avg_llm_response": 1.6670802672704061,
      "avg_total": 1.7284966418237395,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.8454419040678293,
      "faithfulness": 0.9130952380952382,
      "context_recall": 0.95,
      "context_precision": 0.7276907458021677,
      "answer_correctness": 0.7309010621879262,
      "EM": 0.0,
      "F1": 0.5250065807716161,
      "avg_retrieve_context": 0.06141637455333363,
      "avg_llm_response": 1.430208933353424,
      "avg_total": 1.4916253079067576,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.0819468691859453,
      "faithfulness": 0.6666666666666667,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.814476201897163,
      "EM": 0.5,
      "F1": 0.8555555555555555,
      "avg_retrieve_context": 0.06141637455333363,
      "avg_llm_response": 0.9761591196060181,
      "avg_total": 1.0375754941593516,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.0819468691859453,
      "faithfulness": 0.6666666666666667,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.814476201897163,
      "EM": 0.5,
      "F1": 0.8555555555555555,
      "avg_retrieve_context": 0.06141637455333363,
      "avg_llm_response": 0.9761591196060181,
      "avg_total": 1.0375754941593516,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.8076320062484684,
      "faithfulness": 0.8851950247554643,
      "context_recall": 0.9542124542124543,
      "context_precision": 0.750695554441055,
      "answer_correctness": 0.7139213021180194,
      "EM": 0.01098901098901099,
      "F1": 0.5111913027828529,
      "avg_retrieve_context": 0.061416374553333625,
      "avg_llm_response": 1.518972559289618,
      "avg_total": 1.580388933842952,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.5077985502877022,
      "faithfulness": 0.8174603174603176,
      "context_recall": 0.8888888888888888,
      "context_precision": 0.8576466522680593,
      "answer_correctness": 0.5223135001160317,
      "EM": 0.0,
      "F1": 0.2999089607180838,
      "avg_retrieve_context": 0.06141637455333363,
      "avg_llm_response": 2.111852275000678,
      "avg_total": 2.1732686495540117,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.8148741330366265,
      "faithfulness": 0.8823321123321124,
      "context_recall": 0.9462962962962963,
      "context_precision": 0.7570527544519378,
      "answer_correctness": 0.7119512744813558,
      "EM": 0.011111111111111112,
      "F1": 0.5123385302129949,
      "avg_retrieve_context": 0.061416374553333625,
      "avg_llm_response": 1.633570655186971,
      "avg_total": 1.6949870297403045,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.2772748119881516,
      "faithfulness": 0.7583333333333333,
      "context_recall": 0.9333333333333332,
      "context_precision": 0.3948683711937065,
      "answer_correctness": 0.6868403654716835,
      "EM": 0.25,
      "F1": 0.5831338518044186,
      "avg_retrieve_context": 0.06141637455333363,
      "avg_llm_response": 0.9986702799797058,
      "avg_total": 1.060086654533039,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 9,
  "negative_rejection_percentage": 90.0
}