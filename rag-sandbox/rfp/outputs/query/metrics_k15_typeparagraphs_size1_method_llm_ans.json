{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6878225166375992,
      "faithfulness": 0.7951334776334776,
      "context_recall": 0.8681818181818182,
      "context_precision": 0.5946525533522272,
      "answer_correctness": 0.6738283812219003,
      "EM": 0.06363636363636363,
      "F1": 0.4675593889107486,
      "avg_retrieve_context": 0.07501752376556393,
      "avg_llm_response": 1.3686955473639748,
      "avg_total": 1.4437130711295378,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.7677287801574298,
      "faithfulness": 0.8299319727891158,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.7415384846255842,
      "answer_correctness": 0.6404264140410175,
      "EM": 0.0,
      "F1": 0.32441947233823787,
      "avg_retrieve_context": 0.07501752376556395,
      "avg_llm_response": 1.5579933098384313,
      "avg_total": 1.6330108336039957,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7252530833999689,
      "faithfulness": 0.782051282051282,
      "context_recall": 0.8461538461538461,
      "context_precision": 0.7631232457649465,
      "answer_correctness": 0.712274316612088,
      "EM": 0.07692307692307693,
      "F1": 0.5574390255771113,
      "avg_retrieve_context": 0.07501752376556395,
      "avg_llm_response": 1.5648336960719182,
      "avg_total": 1.639851219837482,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7169048420337286,
      "faithfulness": 0.775,
      "context_recall": 0.9166666666666666,
      "context_precision": 0.7041118025077129,
      "answer_correctness": 0.6496698781294051,
      "EM": 0.0,
      "F1": 0.3852354197081542,
      "avg_retrieve_context": 0.07501752376556395,
      "avg_llm_response": 0.823528786500295,
      "avg_total": 0.8985463102658588,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.7325822076059516,
      "faithfulness": 0.7609126984126985,
      "context_recall": 1.0,
      "context_precision": 0.5073244546143866,
      "answer_correctness": 0.6059535573405466,
      "EM": 0.07142857142857142,
      "F1": 0.47347592191598903,
      "avg_retrieve_context": 0.07501752376556395,
      "avg_llm_response": 2.4593017271586826,
      "avg_total": 2.534319250924247,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.9363777270318062,
      "faithfulness": 0.7916666666666666,
      "context_recall": 1.0,
      "context_precision": 0.6026353276182118,
      "answer_correctness": 0.8811191915801105,
      "EM": 0.0,
      "F1": 0.564956045763623,
      "avg_retrieve_context": 0.07501752376556396,
      "avg_llm_response": 1.0378665924072266,
      "avg_total": 1.1128841161727905,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.9608055154775761,
      "faithfulness": 0.9333333333333332,
      "context_recall": 1.0,
      "context_precision": 0.5466666666217778,
      "answer_correctness": 0.7570996271912689,
      "EM": 0.0,
      "F1": 0.5170685001273236,
      "avg_retrieve_context": 0.07501752376556396,
      "avg_llm_response": 1.382941436767578,
      "avg_total": 1.457958960533142,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.9573041356961125,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.8838374994964717,
      "answer_correctness": 0.7963830790383936,
      "EM": 0.0,
      "F1": 0.5300644173120935,
      "avg_retrieve_context": 0.07501752376556396,
      "avg_llm_response": 1.0026767551898956,
      "avg_total": 1.0776942789554596,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.0,
      "faithfulness": 0.5,
      "context_recall": 0.0,
      "context_precision": 0.0,
      "answer_correctness": 0.18029663467197632,
      "EM": 0.0,
      "F1": 0.02666666666666667,
      "avg_retrieve_context": 0.07501752376556396,
      "avg_llm_response": 0.4719011386235555,
      "avg_total": 0.5469186623891195,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.7878646185053535,
      "faithfulness": 0.861111111111111,
      "context_recall": 1.0,
      "context_precision": 0.5352064473477954,
      "answer_correctness": 0.5311424729300452,
      "EM": 0.0,
      "F1": 0.44165622389306597,
      "avg_retrieve_context": 0.07501752376556396,
      "avg_llm_response": 1.7581119934717815,
      "avg_total": 1.8331295172373452,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.7031498728179739,
      "faithfulness": 0.875,
      "context_recall": 1.0,
      "context_precision": 0.8852653133565704,
      "answer_correctness": 0.7671078099026447,
      "EM": 0.0,
      "F1": 0.4753681612505142,
      "avg_retrieve_context": 0.07501752376556396,
      "avg_llm_response": 0.8189762830734253,
      "avg_total": 0.8939938068389892,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.9547047399113638,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.8506613756185869,
      "answer_correctness": 0.9586470689398623,
      "EM": 0.0,
      "F1": 0.6403818403818403,
      "avg_retrieve_context": 0.07501752376556396,
      "avg_llm_response": 2.013028939565023,
      "avg_total": 2.088046463330587,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9218187487959012,
      "faithfulness": 0.9166666666666667,
      "context_recall": 1.0,
      "context_precision": 0.8214285714053571,
      "answer_correctness": 0.6925905297146848,
      "EM": 0.0,
      "F1": 0.3584117032392895,
      "avg_retrieve_context": 0.07501752376556396,
      "avg_llm_response": 1.0282753705978394,
      "avg_total": 1.1032928943634033,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.09226074069646863,
      "faithfulness": 0.6,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.8091746714054203,
      "EM": 0.5,
      "F1": 0.8555555555555555,
      "avg_retrieve_context": 0.07501752376556395,
      "avg_llm_response": 0.7268300771713256,
      "avg_total": 0.8018476009368897,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.740160057973228,
      "faithfulness": 0.7924669312169311,
      "context_recall": 0.8916666666666667,
      "context_precision": 0.6840799061129257,
      "answer_correctness": 0.6497984858523171,
      "EM": 0.03333333333333333,
      "F1": 0.4218500699154523,
      "avg_retrieve_context": 0.07501752376556398,
      "avg_llm_response": 1.6228877862294515,
      "avg_total": 1.6979053099950154,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.7582066486194383,
      "faithfulness": 0.8479166666666667,
      "context_recall": 0.85,
      "context_precision": 0.6091746625492366,
      "answer_correctness": 0.6760366517303955,
      "EM": 0.0,
      "F1": 0.43912432574249144,
      "avg_retrieve_context": 0.07501752376556396,
      "avg_llm_response": 1.1478735566139222,
      "avg_total": 1.2228910803794861,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.09226074069646863,
      "faithfulness": 0.6,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.8091746714054203,
      "EM": 0.5,
      "F1": 0.8555555555555555,
      "avg_retrieve_context": 0.07501752376556395,
      "avg_llm_response": 0.7268300771713256,
      "avg_total": 0.8018476009368897,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.09226074069646863,
      "faithfulness": 0.6,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.8091746714054203,
      "EM": 0.5,
      "F1": 0.8555555555555555,
      "avg_retrieve_context": 0.07501752376556395,
      "avg_llm_response": 0.7268300771713256,
      "avg_total": 0.8018476009368897,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7592189732940404,
      "faithfulness": 0.8237877202162917,
      "context_recall": 0.8882783882783883,
      "context_precision": 0.6496531971970866,
      "answer_correctness": 0.6731453886934599,
      "EM": 0.02197802197802198,
      "F1": 0.44658145823353723,
      "avg_retrieve_context": 0.07501752376556396,
      "avg_llm_response": 1.4022262017805498,
      "avg_total": 1.477243725546113,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.6276603170459482,
      "faithfulness": 0.7222222222222222,
      "context_recall": 0.7407407407407407,
      "context_precision": 0.6992599915344577,
      "answer_correctness": 0.5303494276944439,
      "EM": 0.0,
      "F1": 0.24856272504165566,
      "avg_retrieve_context": 0.07501752376556396,
      "avg_llm_response": 1.7428472306993272,
      "avg_total": 1.8178647544648914,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7446684230555661,
      "faithfulness": 0.8195546737213404,
      "context_recall": 0.8833333333333333,
      "context_precision": 0.6579813711179395,
      "answer_correctness": 0.6703475493717314,
      "EM": 0.022222222222222223,
      "F1": 0.4402049610400188,
      "avg_retrieve_context": 0.07501752376556395,
      "avg_llm_response": 1.4654599666595458,
      "avg_total": 1.5404774904251093,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.43201593775674707,
      "faithfulness": 0.6852380952380953,
      "context_recall": 0.8,
      "context_precision": 0.30967287340652216,
      "answer_correctness": 0.6894921245476614,
      "EM": 0.25,
      "F1": 0.5906543143290325,
      "avg_retrieve_context": 0.07501752376556395,
      "avg_llm_response": 0.9332556605339051,
      "avg_total": 1.008273184299469,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 9,
  "negative_rejection_percentage": 90.0
}