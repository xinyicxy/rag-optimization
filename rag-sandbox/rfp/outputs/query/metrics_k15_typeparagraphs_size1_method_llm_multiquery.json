{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6961554791047188,
      "faithfulness": 0.8426595626595628,
      "context_recall": 0.8757575757575757,
      "context_precision": 0.5747736283145864,
      "answer_correctness": 0.6874648258726659,
      "EM": 0.05454545454545454,
      "F1": 0.46356040280326116,
      "avg_retrieve_context": 0.07337675528092816,
      "avg_llm_response": 1.48794188932939,
      "avg_total": 1.5613186446103182,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.854464903395593,
      "faithfulness": 0.9141200069771498,
      "context_recall": 0.8730158730158729,
      "context_precision": 0.68091528649473,
      "answer_correctness": 0.7073523858365613,
      "EM": 0.0,
      "F1": 0.35869881347946636,
      "avg_retrieve_context": 0.07337675528092816,
      "avg_llm_response": 1.7080006372360956,
      "avg_total": 1.7813773925170235,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7248442746545412,
      "faithfulness": 0.782051282051282,
      "context_recall": 0.8461538461538461,
      "context_precision": 0.6874476967596059,
      "answer_correctness": 0.7131733901253997,
      "EM": 0.07692307692307693,
      "F1": 0.5609211256869565,
      "avg_retrieve_context": 0.07337675528092816,
      "avg_llm_response": 1.622700544504019,
      "avg_total": 1.6960772997849474,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.6268012128550544,
      "faithfulness": 0.875,
      "context_recall": 0.9166666666666666,
      "context_precision": 0.6911664723751523,
      "answer_correctness": 0.6460981391304931,
      "EM": 0.0,
      "F1": 0.41379964602514513,
      "avg_retrieve_context": 0.07337675528092816,
      "avg_llm_response": 0.800748368104299,
      "avg_total": 0.8741251233852271,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.6766402557310042,
      "faithfulness": 0.755952380952381,
      "context_recall": 0.9285714285714286,
      "context_precision": 0.5214053803023032,
      "answer_correctness": 0.4859698267208589,
      "EM": 0.0,
      "F1": 0.38686657593037055,
      "avg_retrieve_context": 0.07337675528092816,
      "avg_llm_response": 2.757882373673575,
      "avg_total": 2.8312591289545033,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.9429447344416633,
      "faithfulness": 0.7916666666666666,
      "context_recall": 1.0,
      "context_precision": 0.6897798381917589,
      "answer_correctness": 0.9092829504198866,
      "EM": 0.0,
      "F1": 0.5430990578049402,
      "avg_retrieve_context": 0.07337675528092817,
      "avg_llm_response": 1.014250636100769,
      "avg_total": 1.0876273913816972,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.9386671307963104,
      "faithfulness": 0.9,
      "context_recall": 1.0,
      "context_precision": 0.46499999995975,
      "answer_correctness": 0.8964793888960599,
      "EM": 0.0,
      "F1": 0.5735003938150313,
      "avg_retrieve_context": 0.07337675528092817,
      "avg_llm_response": 1.4783986568450929,
      "avg_total": 1.551775412126021,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.9632797898750308,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.8263778152711925,
      "answer_correctness": 0.7379085640997358,
      "EM": 0.0,
      "F1": 0.4810533691091984,
      "avg_retrieve_context": 0.07337675528092817,
      "avg_llm_response": 1.2470658123493195,
      "avg_total": 1.3204425676302476,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.0,
      "faithfulness": 0.5833333333333334,
      "context_recall": 0.0,
      "context_precision": 0.0,
      "answer_correctness": 0.180374399994549,
      "EM": 0.0,
      "F1": 0.02666666666666667,
      "avg_retrieve_context": 0.07337675528092817,
      "avg_llm_response": 0.5305724541346232,
      "avg_total": 0.6039492094155513,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9533702721158712,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.5878771097306804,
      "answer_correctness": 0.8054430486784786,
      "EM": 0.0,
      "F1": 0.5232425158516983,
      "avg_retrieve_context": 0.07337675528092817,
      "avg_llm_response": 1.8679010073343914,
      "avg_total": 1.9412777626153197,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.7247951972197209,
      "faithfulness": 0.8392857142857143,
      "context_recall": 1.0,
      "context_precision": 0.9308201057805504,
      "answer_correctness": 0.6962228254917933,
      "EM": 0.0,
      "F1": 0.3921240050272308,
      "avg_retrieve_context": 0.07337675528092817,
      "avg_llm_response": 0.8760983347892761,
      "avg_total": 0.9494750900702043,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.880606543209201,
      "faithfulness": 0.8796296296296297,
      "context_recall": 1.0,
      "context_precision": 0.8531949531535851,
      "answer_correctness": 0.7633995153250316,
      "EM": 0.0,
      "F1": 0.53479870466121,
      "avg_retrieve_context": 0.07337675528092817,
      "avg_llm_response": 1.989959478378296,
      "avg_total": 2.063336233659224,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9603820126466537,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.7552777777601722,
      "answer_correctness": 0.7330869409354264,
      "EM": 0.0,
      "F1": 0.3497536945812808,
      "avg_retrieve_context": 0.07337675528092817,
      "avg_llm_response": 1.303141474723816,
      "avg_total": 1.376518230004744,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.09765575690810649,
      "faithfulness": 0.75,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8641189846488524,
      "EM": 0.5,
      "F1": 0.8638888888888889,
      "avg_retrieve_context": 0.07337675528092816,
      "avg_llm_response": 0.8565734624862671,
      "avg_total": 0.9299502177671954,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7393552779385201,
      "faithfulness": 0.8407753357753357,
      "context_recall": 0.8888888888888888,
      "context_precision": 0.647161901116638,
      "answer_correctness": 0.6447068236309322,
      "EM": 0.016666666666666666,
      "F1": 0.42010629220543605,
      "avg_retrieve_context": 0.07337675528092817,
      "avg_llm_response": 1.753040901819865,
      "avg_total": 1.8264176571007937,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.78098071140317,
      "faithfulness": 0.8686507936507937,
      "context_recall": 0.85,
      "context_precision": 0.6098846261901556,
      "answer_correctness": 0.7074382895412198,
      "EM": 0.0,
      "F1": 0.4286594471785922,
      "avg_retrieve_context": 0.07337675528092817,
      "avg_llm_response": 1.2481354773044586,
      "avg_total": 1.321512232585387,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.09765575690810649,
      "faithfulness": 0.75,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8641189846488524,
      "EM": 0.5,
      "F1": 0.8638888888888889,
      "avg_retrieve_context": 0.07337675528092816,
      "avg_llm_response": 0.8565734624862671,
      "avg_total": 0.9299502177671954,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.09765575690810649,
      "faithfulness": 0.75,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8641189846488524,
      "EM": 0.5,
      "F1": 0.8638888888888889,
      "avg_retrieve_context": 0.07337675528092816,
      "avg_llm_response": 0.8565734624862671,
      "avg_total": 0.9299502177671954,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7584354387461569,
      "faithfulness": 0.8477203504676032,
      "context_recall": 0.8864468864468863,
      "context_precision": 0.633236145151562,
      "answer_correctness": 0.6627661257604988,
      "EM": 0.01098901098901099,
      "F1": 0.43587698684400045,
      "avg_retrieve_context": 0.07337675528092816,
      "avg_llm_response": 1.5257043943300352,
      "avg_total": 1.5990811496109636,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.7314355785041896,
      "faithfulness": 0.8944444444444445,
      "context_recall": 0.7407407407407407,
      "context_precision": 0.622289989534708,
      "answer_correctness": 0.7409137283665925,
      "EM": 0.0,
      "F1": 0.29866106851842233,
      "avg_retrieve_context": 0.07337675528092817,
      "avg_llm_response": 1.8076414797041152,
      "avg_total": 1.8810182349850433,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7674528502821051,
      "faithfulness": 0.8506579839913172,
      "context_recall": 0.8703703703703703,
      "context_precision": 0.634242019089023,
      "answer_correctness": 0.6656301865380817,
      "EM": 0.011111111111111112,
      "F1": 0.42912347758761926,
      "avg_retrieve_context": 0.07337675528092816,
      "avg_llm_response": 1.5981780105166965,
      "avg_total": 1.671554765797625,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.3753173088064801,
      "faithfulness": 0.8066666666666666,
      "context_recall": 0.9,
      "context_precision": 0.307165869829622,
      "answer_correctness": 0.7857207028782944,
      "EM": 0.25,
      "F1": 0.61852656627365,
      "avg_retrieve_context": 0.07337675528092816,
      "avg_llm_response": 0.9918793439865112,
      "avg_total": 1.0652560992674396,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 9,
  "negative_rejection_percentage": 90.0
}