{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6884962767304732,
      "faithfulness": 0.8124347874347874,
      "context_recall": 0.8795454545454545,
      "context_precision": 0.5879711809671462,
      "answer_correctness": 0.6824028128485261,
      "EM": 0.045454545454545456,
      "F1": 0.4680202970513529,
      "avg_retrieve_context": 0.09745036471973763,
      "avg_llm_response": 1.8256467667492953,
      "avg_total": 1.9230971314690335,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.7153138056138955,
      "faithfulness": 0.8781179138321995,
      "context_recall": 0.8928571428571429,
      "context_precision": 0.6922126286096744,
      "answer_correctness": 0.6162146952535918,
      "EM": 0.0,
      "F1": 0.3335368391626095,
      "avg_retrieve_context": 0.09745036471973763,
      "avg_llm_response": 2.0362023398989724,
      "avg_total": 2.1336527046187106,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7254464153128116,
      "faithfulness": 0.782051282051282,
      "context_recall": 0.8461538461538461,
      "context_precision": 0.760645705159114,
      "answer_correctness": 0.6998210025789764,
      "EM": 0.0,
      "F1": 0.5615176930046268,
      "avg_retrieve_context": 0.09745036471973764,
      "avg_llm_response": 1.8205625827495868,
      "avg_total": 1.9180129474693244,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7068468944676366,
      "faithfulness": 0.875,
      "context_recall": 0.9166666666666666,
      "context_precision": 0.7105850167933587,
      "answer_correctness": 0.6451600679239599,
      "EM": 0.0,
      "F1": 0.40520674417524977,
      "avg_retrieve_context": 0.09745036471973766,
      "avg_llm_response": 1.1033700903256733,
      "avg_total": 1.2008204550454111,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.7216764098889928,
      "faithfulness": 0.717032967032967,
      "context_recall": 1.0,
      "context_precision": 0.529863192332222,
      "answer_correctness": 0.6601457252154752,
      "EM": 0.07142857142857142,
      "F1": 0.45971536907289545,
      "avg_retrieve_context": 0.09745036471973764,
      "avg_llm_response": 2.6876688855034963,
      "avg_total": 2.7851192502232345,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.9154717768672292,
      "faithfulness": 0.75,
      "context_recall": 1.0,
      "context_precision": 0.6533716797403907,
      "answer_correctness": 0.9427045440089133,
      "EM": 0.0,
      "F1": 0.5380216753690672,
      "avg_retrieve_context": 0.09745036471973766,
      "avg_llm_response": 2.1953278382619223,
      "avg_total": 2.2927782029816597,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.9568906164880936,
      "faithfulness": 0.7,
      "context_recall": 1.0,
      "context_precision": 0.5648484848002424,
      "answer_correctness": 0.8370481282970635,
      "EM": 0.0,
      "F1": 0.5751265187370664,
      "avg_retrieve_context": 0.09745036471973766,
      "avg_llm_response": 2.2614838123321532,
      "avg_total": 2.3589341770518906,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.9569283834543298,
      "faithfulness": 0.9861111111111112,
      "context_recall": 1.0,
      "context_precision": 0.7847098090119641,
      "answer_correctness": 0.8544606572581546,
      "EM": 0.0,
      "F1": 0.5655224529552487,
      "avg_retrieve_context": 0.09745036471973766,
      "avg_llm_response": 1.4755291938781738,
      "avg_total": 1.5729795585979116,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.0,
      "faithfulness": 0.5833333333333334,
      "context_recall": 0.0,
      "context_precision": 0.0,
      "answer_correctness": 0.18037494020684922,
      "EM": 0.0,
      "F1": 0.02666666666666667,
      "avg_retrieve_context": 0.09745036471973766,
      "avg_llm_response": 1.483755389849345,
      "avg_total": 1.5812057545690823,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.7945439709306292,
      "faithfulness": 0.9444444444444443,
      "context_recall": 1.0,
      "context_precision": 0.5624984968623111,
      "answer_correctness": 0.6648823927991637,
      "EM": 0.0,
      "F1": 0.47821202919887135,
      "avg_retrieve_context": 0.09745036471973766,
      "avg_llm_response": 2.0509252548217773,
      "avg_total": 2.148375619541515,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.9283071624158533,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.9694756631718824,
      "answer_correctness": 0.7109070618677487,
      "EM": 0.0,
      "F1": 0.5801827690248952,
      "avg_retrieve_context": 0.09745036471973766,
      "avg_llm_response": 1.0253905057907104,
      "avg_total": 1.122840870510448,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.8779485331543979,
      "faithfulness": 0.8888888888888888,
      "context_recall": 1.0,
      "context_precision": 0.8201308215176896,
      "answer_correctness": 0.9427697310750925,
      "EM": 0.0,
      "F1": 0.5576920443184464,
      "avg_retrieve_context": 0.09745036471973766,
      "avg_llm_response": 2.5584930578867593,
      "avg_total": 2.6559434226064966,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9621268250316148,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.7857142856946429,
      "answer_correctness": 0.7113991796805192,
      "EM": 0.0,
      "F1": 0.33657786885245905,
      "avg_retrieve_context": 0.09745036471973766,
      "avg_llm_response": 1.0763856172561646,
      "avg_total": 1.173835981975902,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.17252621152840525,
      "faithfulness": 0.65,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7198733849684159,
      "EM": 0.4,
      "F1": 0.7555555555555555,
      "avg_retrieve_context": 0.09745036471973766,
      "avg_llm_response": 1.2104260206222535,
      "avg_total": 1.307876385341991,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7173004298169315,
      "faithfulness": 0.8190934065934066,
      "context_recall": 0.9125,
      "context_precision": 0.6728327377007176,
      "answer_correctness": 0.6503690433659381,
      "EM": 0.016666666666666666,
      "F1": 0.4267083288099747,
      "avg_retrieve_context": 0.09745036471973763,
      "avg_llm_response": 1.9549228032430013,
      "avg_total": 2.0523731679627386,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.7742825634013023,
      "faithfulness": 0.8430555555555556,
      "context_recall": 0.85,
      "context_precision": 0.6076716411085755,
      "answer_correctness": 0.7210858240424356,
      "EM": 0.0,
      "F1": 0.45810443478736984,
      "avg_retrieve_context": 0.09745036471973766,
      "avg_llm_response": 1.7855378985404968,
      "avg_total": 1.8829882632602342,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.17252621152840525,
      "faithfulness": 0.65,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7198733849684159,
      "EM": 0.4,
      "F1": 0.7555555555555555,
      "avg_retrieve_context": 0.09745036471973766,
      "avg_llm_response": 1.2104260206222535,
      "avg_total": 1.307876385341991,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.17252621152840525,
      "faithfulness": 0.65,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7198733849684159,
      "EM": 0.4,
      "F1": 0.7555555555555555,
      "avg_retrieve_context": 0.09745036471973766,
      "avg_llm_response": 1.2104260206222535,
      "avg_total": 1.307876385341991,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.752095716544826,
      "faithfulness": 0.8343664882126421,
      "context_recall": 0.8974358974358974,
      "context_precision": 0.6446758468976214,
      "answer_correctness": 0.6936068191929892,
      "EM": 0.01098901098901099,
      "F1": 0.45507783787588024,
      "avg_retrieve_context": 0.09745036471973766,
      "avg_llm_response": 1.835140293771094,
      "avg_total": 1.9325906584908321,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.618735346609869,
      "faithfulness": 0.7711640211640212,
      "context_recall": 0.787037037037037,
      "context_precision": 0.6679253154113933,
      "answer_correctness": 0.5274838907879666,
      "EM": 0.0,
      "F1": 0.27939931926535155,
      "avg_retrieve_context": 0.09745036471973766,
      "avg_llm_response": 2.4132352670033774,
      "avg_total": 2.5106856317231148,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7380609310668992,
      "faithfulness": 0.825383258716592,
      "context_recall": 0.8787037037037038,
      "context_precision": 0.6467028216179642,
      "answer_correctness": 0.6893366961602756,
      "EM": 0.011111111111111112,
      "F1": 0.4474569058661247,
      "avg_retrieve_context": 0.09745036471973766,
      "avg_llm_response": 1.9470736900965373,
      "avg_total": 2.044524054816275,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.46545533221655544,
      "faithfulness": 0.7541666666666667,
      "context_recall": 0.8833333333333332,
      "context_precision": 0.3236787980384655,
      "answer_correctness": 0.6512003379456532,
      "EM": 0.2,
      "F1": 0.5605555573848803,
      "avg_retrieve_context": 0.09745036471973764,
      "avg_llm_response": 1.2792256116867065,
      "avg_total": 1.3766759764064442,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 8,
  "negative_rejection_percentage": 80.0
}