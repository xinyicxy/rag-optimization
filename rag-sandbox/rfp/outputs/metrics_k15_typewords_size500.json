{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6928367176931802,
      "faithfulness": 0.7971836496836497,
      "context_recall": 0.9515151515151514,
      "context_precision": 0.734077797837519,
      "answer_correctness": 0.6726436585718384,
      "EM": 0.05454545454545454,
      "F1": 0.47378560474736575,
      "avg_retrieve_context": 0.06503953716971655,
      "avg_llm_response": 1.78823881149292,
      "avg_total": 1.853278348662637,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.6628438203365086,
      "faithfulness": 0.8416666666666667,
      "context_recall": 0.9603174603174602,
      "context_precision": 0.7900713087289661,
      "answer_correctness": 0.6164976449874919,
      "EM": 0.0,
      "F1": 0.3010471379969942,
      "avg_retrieve_context": 0.06503953716971657,
      "avg_llm_response": 2.2140129861377535,
      "avg_total": 2.27905252330747,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7293759868649095,
      "faithfulness": 0.7025641025641025,
      "context_recall": 0.9615384615384616,
      "context_precision": 0.8842878946159808,
      "answer_correctness": 0.6501628739282255,
      "EM": 0.0,
      "F1": 0.4902348433571729,
      "avg_retrieve_context": 0.06503953716971657,
      "avg_llm_response": 2.160005679497352,
      "avg_total": 2.225045216667069,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.700781813834681,
      "faithfulness": 0.8194444444444443,
      "context_recall": 1.0,
      "context_precision": 0.7995039682039375,
      "answer_correctness": 0.6465304014775811,
      "EM": 0.08333333333333333,
      "F1": 0.4186826292556516,
      "avg_retrieve_context": 0.06503953716971657,
      "avg_llm_response": 0.9332340161005656,
      "avg_total": 0.9982735532702823,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.8033600728980963,
      "faithfulness": 0.8606096284667714,
      "context_recall": 1.0,
      "context_precision": 0.7873875843174706,
      "answer_correctness": 0.6519888632321901,
      "EM": 0.0,
      "F1": 0.5110270945636799,
      "avg_retrieve_context": 0.06503953716971657,
      "avg_llm_response": 1.640236735343933,
      "avg_total": 1.7052762725136499,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.8035873755395738,
      "faithfulness": 0.65,
      "context_recall": 1.0,
      "context_precision": 0.7818598068306694,
      "answer_correctness": 0.7781805612515648,
      "EM": 0.0,
      "F1": 0.5081595982874755,
      "avg_retrieve_context": 0.06503953716971657,
      "avg_llm_response": 1.5918052593866985,
      "avg_total": 1.6568447965564153,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.9683159082884611,
      "faithfulness": 0.9099999999999999,
      "context_recall": 1.0,
      "context_precision": 0.8541666666235068,
      "answer_correctness": 0.784835236427962,
      "EM": 0.0,
      "F1": 0.5544280984266818,
      "avg_retrieve_context": 0.06503953716971657,
      "avg_llm_response": 1.9308479309082032,
      "avg_total": 1.9958874680779197,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.5966441917624778,
      "faithfulness": 0.8125,
      "context_recall": 1.0,
      "context_precision": 0.8682193329941278,
      "answer_correctness": 0.5901108518025416,
      "EM": 0.0,
      "F1": 0.33049758474585667,
      "avg_retrieve_context": 0.06503953716971657,
      "avg_llm_response": 1.2552481889724731,
      "avg_total": 1.3202877261421897,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.9430707659849098,
      "faithfulness": 0.8055555555555557,
      "context_recall": 1.0,
      "context_precision": 0.7521090534564375,
      "answer_correctness": 0.7447169993098232,
      "EM": 0.0,
      "F1": 0.6456645306107671,
      "avg_retrieve_context": 0.06503953716971657,
      "avg_llm_response": 1.9193594058354695,
      "avg_total": 1.9843989430051863,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9626651235670879,
      "faithfulness": 0.9444444444444443,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.7748121361534799,
      "answer_correctness": 0.7842673249414251,
      "EM": 0.0,
      "F1": 0.616600803799004,
      "avg_retrieve_context": 0.06503953716971657,
      "avg_llm_response": 3.1844707330067954,
      "avg_total": 3.2495102701765126,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.4687659265833795,
      "faithfulness": 0.75,
      "context_recall": 1.0,
      "context_precision": 0.749198024163737,
      "answer_correctness": 0.5253730338565061,
      "EM": 0.0,
      "F1": 0.3037837837837838,
      "avg_retrieve_context": 0.06503953716971657,
      "avg_llm_response": 1.912505328655243,
      "avg_total": 1.9775448658249597,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.6128127691691786,
      "faithfulness": 0.8333333333333334,
      "context_recall": 1.0,
      "context_precision": 0.7592592592117283,
      "answer_correctness": 0.6508380491701862,
      "EM": 0.0,
      "F1": 0.5058975121419368,
      "avg_retrieve_context": 0.06503953716971657,
      "avg_llm_response": 2.4324800173441568,
      "avg_total": 2.497519554513873,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.886094432133427,
      "faithfulness": 0.775,
      "context_recall": 1.0,
      "context_precision": 0.8499999999575,
      "answer_correctness": 0.8324015060239918,
      "EM": 0.0,
      "F1": 0.36231884057971014,
      "avg_retrieve_context": 0.06503953716971657,
      "avg_llm_response": 2.4455894231796265,
      "avg_total": 2.5106289603493432,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.17976445591503268,
      "faithfulness": 0.65,
      "context_recall": 0.7,
      "context_precision": 0.0,
      "answer_correctness": 0.7499164029554743,
      "EM": 0.5,
      "F1": 0.7746666666666666,
      "avg_retrieve_context": 0.06503953716971657,
      "avg_llm_response": 0.8261122465133667,
      "avg_total": 0.8911517836830833,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7176338473816669,
      "faithfulness": 0.8115033577533578,
      "context_recall": 0.9777777777777777,
      "context_precision": 0.8117452318701314,
      "answer_correctness": 0.6380796134797648,
      "EM": 0.016666666666666666,
      "F1": 0.41456022894232436,
      "avg_retrieve_context": 0.06503953716971658,
      "avg_llm_response": 1.8122744838396707,
      "avg_total": 1.877314021009387,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.7839090886049865,
      "faithfulness": 0.8125,
      "context_recall": 0.975,
      "context_precision": 0.8010960962479802,
      "answer_correctness": 0.7051715401140397,
      "EM": 0.0,
      "F1": 0.48740340297510265,
      "avg_retrieve_context": 0.06503953716971657,
      "avg_llm_response": 1.992716944217682,
      "avg_total": 2.0577564813873983,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.17976445591503268,
      "faithfulness": 0.65,
      "context_recall": 0.7,
      "context_precision": 0.0,
      "answer_correctness": 0.7499164029554743,
      "EM": 0.5,
      "F1": 0.7746666666666666,
      "avg_retrieve_context": 0.06503953716971657,
      "avg_llm_response": 0.8261122465133667,
      "avg_total": 0.8911517836830833,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.17976445591503268,
      "faithfulness": 0.65,
      "context_recall": 0.7,
      "context_precision": 0.0,
      "answer_correctness": 0.7499164029554743,
      "EM": 0.5,
      "F1": 0.7746666666666666,
      "avg_retrieve_context": 0.06503953716971657,
      "avg_llm_response": 0.8261122465133667,
      "avg_total": 0.8911517836830833,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7679868894647432,
      "faithfulness": 0.8188483677494667,
      "context_recall": 0.9835164835164835,
      "context_precision": 0.8048089652071625,
      "answer_correctness": 0.6775446834184994,
      "EM": 0.01098901098901099,
      "F1": 0.4626984474606674,
      "avg_retrieve_context": 0.06503953716971655,
      "avg_llm_response": 1.8713992951990484,
      "avg_total": 1.9364388323687651,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.5030652717564268,
      "faithfulness": 0.7416666666666667,
      "context_recall": 0.9074074074074073,
      "context_precision": 0.8345491031416978,
      "answer_correctness": 0.5372302469182262,
      "EM": 0.0,
      "F1": 0.25157679295809204,
      "avg_retrieve_context": 0.06503953716971657,
      "avg_llm_response": 2.0164234373304577,
      "avg_total": 2.0814629745001745,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7752002889474907,
      "faithfulness": 0.8339652014652015,
      "context_recall": 0.9777777777777777,
      "context_precision": 0.8041455440228817,
      "answer_correctness": 0.6834083124735444,
      "EM": 0.011111111111111112,
      "F1": 0.46547455466818755,
      "avg_retrieve_context": 0.06503953716971655,
      "avg_llm_response": 1.9681640572018093,
      "avg_total": 2.0332035943715265,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.322200647048782,
      "faithfulness": 0.6316666666666666,
      "context_recall": 0.8333333333333333,
      "context_precision": 0.41877294000338594,
      "answer_correctness": 0.6242027160141617,
      "EM": 0.25,
      "F1": 0.511185330103668,
      "avg_retrieve_context": 0.06503953716971657,
      "avg_llm_response": 0.9785752058029175,
      "avg_total": 1.0436147429726343,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 8,
  "negative_rejection_percentage": 80.0
}