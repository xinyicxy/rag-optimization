{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.681538498139953,
      "faithfulness": 0.7798629148629149,
      "context_recall": 0.9356060606060606,
      "context_precision": 0.7832702019819114,
      "answer_correctness": 0.6900034353198088,
      "EM": 0.06363636363636363,
      "F1": 0.4838133347518666,
      "avg_retrieve_context": 0.06383734616366302,
      "avg_llm_response": 2.0599542704495515,
      "avg_total": 2.1237916166132145,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.6642256989052817,
      "faithfulness": 0.7646258503401361,
      "context_recall": 0.9722222222222221,
      "context_precision": 0.8566137565773521,
      "answer_correctness": 0.6257923179303864,
      "EM": 0.0,
      "F1": 0.3077495560978646,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 2.2469439847128734,
      "avg_total": 2.3107813308765373,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.6470920615019605,
      "faithfulness": 0.764957264957265,
      "context_recall": 0.9615384615384616,
      "context_precision": 0.9871794871185897,
      "answer_correctness": 0.6057108365873046,
      "EM": 0.0,
      "F1": 0.4806029166869376,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 2.3957586471851053,
      "avg_total": 2.4595959933487683,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.795922974582397,
      "faithfulness": 0.875,
      "context_recall": 0.9166666666666666,
      "context_precision": 0.9999999999416666,
      "answer_correctness": 0.6071977217675395,
      "EM": 0.0,
      "F1": 0.4106205382865408,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 1.1459747155507405,
      "avg_total": 1.2098120617144035,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.5944348940850034,
      "faithfulness": 0.7642857142857143,
      "context_recall": 0.8571428571428571,
      "context_precision": 0.7765873015512863,
      "answer_correctness": 0.6255808076339522,
      "EM": 0.07142857142857142,
      "F1": 0.47778154498736347,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 2.2519621678761075,
      "avg_total": 2.3157995140397705,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.7859814713310956,
      "faithfulness": 0.861111111111111,
      "context_recall": 1.0,
      "context_precision": 0.8111111110770602,
      "answer_correctness": 0.753483775222299,
      "EM": 0.0,
      "F1": 0.5302055659241065,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 2.66676660378774,
      "avg_total": 2.730603949951403,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.9566800720785531,
      "faithfulness": 0.7666666666666667,
      "context_recall": 1.0,
      "context_precision": 0.7399999999453334,
      "answer_correctness": 0.804533172357627,
      "EM": 0.0,
      "F1": 0.5225594546201148,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 2.7406715869903566,
      "avg_total": 2.8045089331540196,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.8115011073088154,
      "faithfulness": 0.9375,
      "context_recall": 1.0,
      "context_precision": 0.8020833333002083,
      "answer_correctness": 0.6958195982335746,
      "EM": 0.0,
      "F1": 0.4670605672832181,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 2.295106202363968,
      "avg_total": 2.3589435485276313,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.8209473698451019,
      "faithfulness": 0.6805555555555557,
      "context_recall": 1.0,
      "context_precision": 0.8064814814365432,
      "answer_correctness": 0.7229578241979108,
      "EM": 0.0,
      "F1": 0.5360564301678558,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 1.137111226717631,
      "avg_total": 1.2009485728812939,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9525300674295804,
      "faithfulness": 0.6666666666666666,
      "context_recall": 1.0,
      "context_precision": 0.894212962942444,
      "answer_correctness": 0.768435166470233,
      "EM": 0.0,
      "F1": 0.49348006626568885,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 3.0657585064570108,
      "avg_total": 3.129595852620674,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.6735234563238813,
      "faithfulness": 0.625,
      "context_recall": 1.0,
      "context_precision": 0.8135416666363976,
      "answer_correctness": 0.7356991306302904,
      "EM": 0.0,
      "F1": 0.4591250259174787,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 1.675367534160614,
      "avg_total": 1.739204880324277,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.875828630116835,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.8115740740266859,
      "answer_correctness": 0.9371817698404478,
      "EM": 0.0,
      "F1": 0.6375862009664827,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 2.865266799926758,
      "avg_total": 2.929104146090421,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9293921567854708,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.794444444417963,
      "answer_correctness": 0.5536133877113029,
      "EM": 0.0,
      "F1": 0.3844202898550725,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 2.953050374984741,
      "avg_total": 3.0168877211484046,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.09226074069646865,
      "faithfulness": 0.65,
      "context_recall": 0.7,
      "context_precision": 0.0,
      "answer_correctness": 0.8919942514455605,
      "EM": 0.6,
      "F1": 0.8666666666666666,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 0.8499719858169555,
      "avg_total": 0.9138093319806184,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.6705683448119203,
      "faithfulness": 0.7866931216931217,
      "context_recall": 0.9319444444444444,
      "context_precision": 0.8949074073614012,
      "answer_correctness": 0.6176730586709813,
      "EM": 0.016666666666666666,
      "F1": 0.4054494447374487,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 2.060164217154185,
      "avg_total": 2.124001563317848,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.8453131674928731,
      "faithfulness": 0.8020833333333333,
      "context_recall": 1.0,
      "context_precision": 0.8116319444081548,
      "answer_correctness": 0.7480012962616126,
      "EM": 0.0,
      "F1": 0.5056458367947934,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 2.3621349215507506,
      "avg_total": 2.425972267714414,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.09226074069646865,
      "faithfulness": 0.65,
      "context_recall": 0.7,
      "context_precision": 0.0,
      "answer_correctness": 0.8919942514455605,
      "EM": 0.6,
      "F1": 0.8666666666666666,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 0.8499719858169555,
      "avg_total": 0.9138093319806184,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.09226074069646865,
      "faithfulness": 0.65,
      "context_recall": 0.7,
      "context_precision": 0.0,
      "answer_correctness": 0.8919942514455605,
      "EM": 0.6,
      "F1": 0.8666666666666666,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 0.8499719858169555,
      "avg_total": 0.9138093319806184,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7842413265197504,
      "faithfulness": 0.8075266003837431,
      "context_recall": 0.9615384615384616,
      "context_precision": 0.8499236873796291,
      "answer_correctness": 0.6894661022041921,
      "EM": 0.01098901098901099,
      "F1": 0.4726570367351772,
      "avg_retrieve_context": 0.06383734616366302,
      "avg_llm_response": 2.1878247130048143,
      "avg_total": 2.2516620591684773,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.2978518527925397,
      "faithfulness": 0.6444444444444444,
      "context_recall": 0.9351851851851851,
      "context_precision": 0.9796296296071141,
      "answer_correctness": 0.47100223001576563,
      "EM": 0.0,
      "F1": 0.17122331257083664,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 2.1114667786492243,
      "avg_total": 2.1753041248128877,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7509315998604607,
      "faithfulness": 0.7977160493827161,
      "context_recall": 0.9583333333333334,
      "context_precision": 0.8551080246490833,
      "answer_correctness": 0.6853345095691786,
      "EM": 0.011111111111111112,
      "F1": 0.45818740100598665,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 2.239065268304613,
      "avg_total": 2.302902614468276,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.36926954039766846,
      "faithfulness": 0.6995238095238095,
      "context_recall": 0.8333333333333333,
      "context_precision": 0.4599999999796389,
      "answer_correctness": 0.7110136011976453,
      "EM": 0.3,
      "F1": 0.5991300366083262,
      "avg_retrieve_context": 0.063837346163663,
      "avg_llm_response": 1.253954780101776,
      "avg_total": 1.317792126265439,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 9,
  "negative_rejection_percentage": 90.0
}