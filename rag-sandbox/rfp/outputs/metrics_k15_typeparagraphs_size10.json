{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6799935692580108,
      "faithfulness": 0.7730303030303031,
      "context_recall": 0.9212121212121211,
      "context_precision": 0.6835964704241839,
      "answer_correctness": 0.6462602850914766,
      "EM": 0.08181818181818182,
      "F1": 0.46769419649087307,
      "avg_retrieve_context": 0.15279621644453573,
      "avg_llm_response": 2.0039953708648683,
      "avg_total": 2.1567915873094035,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.5380689591257346,
      "faithfulness": 0.7380952380952381,
      "context_recall": 0.9206349206349207,
      "context_precision": 0.7754143570654364,
      "answer_correctness": 0.5355081885374171,
      "EM": 0.0,
      "F1": 0.24922730104084015,
      "avg_retrieve_context": 0.15279621644453567,
      "avg_llm_response": 2.650119191124326,
      "avg_total": 2.8029154075688614,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7909464803848528,
      "faithfulness": 0.7564102564102563,
      "context_recall": 0.9230769230769231,
      "context_precision": 0.861217948680681,
      "answer_correctness": 0.6635738597218039,
      "EM": 0.07692307692307693,
      "F1": 0.5507385861227517,
      "avg_retrieve_context": 0.15279621644453573,
      "avg_llm_response": 2.393462034372183,
      "avg_total": 2.5462582508167184,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7956082213133673,
      "faithfulness": 0.8472222222222222,
      "context_recall": 1.0,
      "context_precision": 0.8240740740251927,
      "answer_correctness": 0.6826625571830428,
      "EM": 0.08333333333333333,
      "F1": 0.47089875752222504,
      "avg_retrieve_context": 0.15279621644453573,
      "avg_llm_response": 1.437505026658376,
      "avg_total": 1.5903012431029115,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.7280073359746863,
      "faithfulness": 0.7559523809523808,
      "context_recall": 1.0,
      "context_precision": 0.6768076169578239,
      "answer_correctness": 0.6110343475042967,
      "EM": 0.07142857142857142,
      "F1": 0.4712204018416215,
      "avg_retrieve_context": 0.15279621644453573,
      "avg_llm_response": 2.3900656700134277,
      "avg_total": 2.5428618864579633,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.7832075646326145,
      "faithfulness": 0.9166666666666666,
      "context_recall": 1.0,
      "context_precision": 0.6752916065246645,
      "answer_correctness": 0.8060187401112137,
      "EM": 0.0,
      "F1": 0.5146717553909591,
      "avg_retrieve_context": 0.1527962164445357,
      "avg_llm_response": 2.228112578392029,
      "avg_total": 2.3809087948365644,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.9365223394455618,
      "faithfulness": 0.85,
      "context_recall": 1.0,
      "context_precision": 0.7842857142265001,
      "answer_correctness": 0.7710128363968125,
      "EM": 0.0,
      "F1": 0.5339454399516319,
      "avg_retrieve_context": 0.1527962164445357,
      "avg_llm_response": 1.929505968093872,
      "avg_total": 2.0823021845384075,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.7147593188954785,
      "faithfulness": 0.875,
      "context_recall": 1.0,
      "context_precision": 0.8896288028650309,
      "answer_correctness": 0.5151938797559728,
      "EM": 0.0,
      "F1": 0.3700968629313512,
      "avg_retrieve_context": 0.1527962164445357,
      "avg_llm_response": 1.8670057952404022,
      "avg_total": 2.019802011684938,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.9403822657940424,
      "faithfulness": 0.6944444444444443,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.5590139284263901,
      "answer_correctness": 0.7198083608999176,
      "EM": 0.0,
      "F1": 0.6210701645406873,
      "avg_retrieve_context": 0.1527962164445357,
      "avg_llm_response": 1.1663300196329753,
      "avg_total": 1.319126236077511,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9643730616777323,
      "faithfulness": 0.9444444444444445,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.7258026822489857,
      "answer_correctness": 0.6100868186287476,
      "EM": 0.0,
      "F1": 0.4972558483013008,
      "avg_retrieve_context": 0.1527962164445357,
      "avg_llm_response": 2.125628670056661,
      "avg_total": 2.2784248865011967,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.420565605919463,
      "faithfulness": 0.5416666666666666,
      "context_recall": 1.0,
      "context_precision": 0.4702369239593432,
      "answer_correctness": 0.5145551629175829,
      "EM": 0.0,
      "F1": 0.3743047954287919,
      "avg_retrieve_context": 0.1527962164445357,
      "avg_llm_response": 1.3235471844673157,
      "avg_total": 1.4763434009118515,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.5546323479575898,
      "faithfulness": 0.7999999999999999,
      "context_recall": 1.0,
      "context_precision": 0.7940476190040417,
      "answer_correctness": 0.7249408600544142,
      "EM": 0.0,
      "F1": 0.43903796461936,
      "avg_retrieve_context": 0.1527962164445357,
      "avg_llm_response": 2.2089788913726807,
      "avg_total": 2.3617751078172162,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.8927458351114128,
      "faithfulness": 0.9,
      "context_recall": 1.0,
      "context_precision": 0.6448412698114419,
      "answer_correctness": 0.6723153788906638,
      "EM": 0.0,
      "F1": 0.35522115823073414,
      "avg_retrieve_context": 0.1527962164445357,
      "avg_llm_response": 1.2946300506591797,
      "avg_total": 1.4474262671037155,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.18180241335402586,
      "faithfulness": 0.6,
      "context_recall": 0.7,
      "context_precision": 0.0,
      "answer_correctness": 0.8100294945650525,
      "EM": 0.6,
      "F1": 0.7851851851851851,
      "avg_retrieve_context": 0.15279621644453573,
      "avg_llm_response": 1.0746612310409547,
      "avg_total": 1.2274574474854902,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.6886858957674921,
      "faithfulness": 0.7680555555555556,
      "context_recall": 0.9555555555555556,
      "context_precision": 0.7807288392822478,
      "answer_correctness": 0.6103093947820979,
      "EM": 0.05,
      "F1": 0.410687427625047,
      "avg_retrieve_context": 0.15279621644453567,
      "avg_llm_response": 2.2913081526756285,
      "avg_total": 2.4441043691201636,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.7915028684697856,
      "faithfulness": 0.8237500000000001,
      "context_recall": 0.925,
      "context_precision": 0.7087970347431343,
      "answer_correctness": 0.6592443181871506,
      "EM": 0.0,
      "F1": 0.47383160261603424,
      "avg_retrieve_context": 0.1527962164445357,
      "avg_llm_response": 1.8053597331047058,
      "avg_total": 1.9581559495492413,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.18180241335402586,
      "faithfulness": 0.6,
      "context_recall": 0.7,
      "context_precision": 0.0,
      "answer_correctness": 0.8100294945650525,
      "EM": 0.6,
      "F1": 0.7851851851851851,
      "avg_retrieve_context": 0.15279621644453573,
      "avg_llm_response": 1.0746612310409547,
      "avg_total": 1.2274574474854902,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.18180241335402586,
      "faithfulness": 0.6,
      "context_recall": 0.7,
      "context_precision": 0.0,
      "answer_correctness": 0.8100294945650525,
      "EM": 0.6,
      "F1": 0.7851851851851851,
      "avg_retrieve_context": 0.15279621644453573,
      "avg_llm_response": 1.0746612310409547,
      "avg_total": 1.2274574474854902,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7713951840062209,
      "faithfulness": 0.8089743589743591,
      "context_recall": 0.9560439560439561,
      "context_precision": 0.7477150437122987,
      "answer_correctness": 0.654539548873008,
      "EM": 0.03296703296703297,
      "F1": 0.46629556971989294,
      "avg_retrieve_context": 0.15279621644453573,
      "avg_llm_response": 2.128390288614965,
      "avg_total": 2.2811865050595,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.30936741558609376,
      "faithfulness": 0.6018518518518517,
      "context_recall": 0.8148148148148148,
      "context_precision": 0.7948380854267827,
      "answer_correctness": 0.3805819407742421,
      "EM": 0.0,
      "F1": 0.1290681019593244,
      "avg_retrieve_context": 0.1527962164445357,
      "avg_llm_response": 1.7788180245293512,
      "avg_total": 1.9316142409738868,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7471157145561558,
      "faithfulness": 0.7994444444444445,
      "context_recall": 0.9407407407407408,
      "context_precision": 0.750078216852394,
      "answer_correctness": 0.6369155580131799,
      "EM": 0.03333333333333333,
      "F1": 0.45074959140643645,
      "avg_retrieve_context": 0.15279621644453573,
      "avg_llm_response": 2.111130510436164,
      "avg_total": 2.2639267268806993,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.37794391541635936,
      "faithfulness": 0.6541666666666666,
      "context_recall": 0.8333333333333333,
      "context_precision": 0.3844286114972398,
      "answer_correctness": 0.6883115569438111,
      "EM": 0.3,
      "F1": 0.5439449193708382,
      "avg_retrieve_context": 0.15279621644453567,
      "avg_llm_response": 1.5218872427940369,
      "avg_total": 1.6746834592385724,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 8,
  "negative_rejection_percentage": 80.0
}