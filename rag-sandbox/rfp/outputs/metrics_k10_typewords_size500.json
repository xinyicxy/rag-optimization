{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.7131450575860622,
      "faithfulness": 0.7881643356643355,
      "context_recall": 0.9613636363636363,
      "context_precision": 0.7436495209704659,
      "answer_correctness": 0.6821812909201008,
      "EM": 0.08181818181818182,
      "F1": 0.4979597133468545,
      "avg_retrieve_context": 0.06387316313656898,
      "avg_llm_response": 1.5957498181949963,
      "avg_total": 1.6596229813315657,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.6658727496832538,
      "faithfulness": 0.7713718820861677,
      "context_recall": 0.9642857142857143,
      "context_precision": 0.8177769004079233,
      "answer_correctness": 0.6114270237754298,
      "EM": 0.0,
      "F1": 0.32331432920557285,
      "avg_retrieve_context": 0.06387316313656895,
      "avg_llm_response": 2.1582388196672713,
      "avg_total": 2.2221119828038405,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7809407867978215,
      "faithfulness": 0.7710622710622711,
      "context_recall": 0.8846153846153846,
      "context_precision": 0.8624930228193034,
      "answer_correctness": 0.734722501325069,
      "EM": 0.07692307692307693,
      "F1": 0.5817950700254859,
      "avg_retrieve_context": 0.06387316313656896,
      "avg_llm_response": 1.8455318120809703,
      "avg_total": 1.9094049752175397,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7134598415671313,
      "faithfulness": 0.861111111111111,
      "context_recall": 1.0,
      "context_precision": 0.8208994708504292,
      "answer_correctness": 0.6507918624461713,
      "EM": 0.08333333333333333,
      "F1": 0.4490631216511627,
      "avg_retrieve_context": 0.06387316313656895,
      "avg_llm_response": 0.9871483643849691,
      "avg_total": 1.0510215275215378,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.6703114926207264,
      "faithfulness": 0.7555599162742019,
      "context_recall": 1.0,
      "context_precision": 0.798104450075969,
      "answer_correctness": 0.619959779623512,
      "EM": 0.07142857142857142,
      "F1": 0.5139972878344873,
      "avg_retrieve_context": 0.06387316313656896,
      "avg_llm_response": 1.4691890137536185,
      "avg_total": 1.5330621768901875,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.9478933475514667,
      "faithfulness": 0.7916666666666666,
      "context_recall": 1.0,
      "context_precision": 0.7602072310091791,
      "answer_correctness": 0.8264339888171506,
      "EM": 0.0,
      "F1": 0.5463458110516933,
      "avg_retrieve_context": 0.06387316313656893,
      "avg_llm_response": 1.429097294807434,
      "avg_total": 1.492970457944003,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.939912020441762,
      "faithfulness": 0.9666666666666666,
      "context_recall": 1.0,
      "context_precision": 0.8708333332894792,
      "answer_correctness": 0.7900929686835734,
      "EM": 0.0,
      "F1": 0.5628364315423139,
      "avg_retrieve_context": 0.06387316313656893,
      "avg_llm_response": 1.8387592315673829,
      "avg_total": 1.9026323947039518,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.7036913569480371,
      "faithfulness": 0.875,
      "context_recall": 1.0,
      "context_precision": 0.8750620039345794,
      "answer_correctness": 0.6282491955868249,
      "EM": 0.0,
      "F1": 0.4490061429865577,
      "avg_retrieve_context": 0.06387316313656893,
      "avg_llm_response": 1.255399912595749,
      "avg_total": 1.3192730757323177,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.9302742318427287,
      "faithfulness": 0.6944444444444443,
      "context_recall": 1.0,
      "context_precision": 0.7625909391104287,
      "answer_correctness": 0.6874038762947962,
      "EM": 0.0,
      "F1": 0.6191874861009358,
      "avg_retrieve_context": 0.06387316313656893,
      "avg_llm_response": 1.4299254814783733,
      "avg_total": 1.493798644614942,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.8156770878775754,
      "faithfulness": 0.8333333333333334,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.8005787036861216,
      "answer_correctness": 0.7161303277825399,
      "EM": 0.0,
      "F1": 0.49996349603671253,
      "avg_retrieve_context": 0.06387316313656893,
      "avg_llm_response": 2.258790135383606,
      "avg_total": 2.3226632985201747,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.6825251733918263,
      "faithfulness": 0.5535714285714286,
      "context_recall": 1.0,
      "context_precision": 0.7727469135438371,
      "answer_correctness": 0.6880002194843682,
      "EM": 0.0,
      "F1": 0.45365996291541866,
      "avg_retrieve_context": 0.06387316313656893,
      "avg_llm_response": 1.425042450428009,
      "avg_total": 1.488915613564578,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.8707179059431954,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.768518518472145,
      "answer_correctness": 0.8843479942026472,
      "EM": 0.0,
      "F1": 0.5989874661647869,
      "avg_retrieve_context": 0.06387316313656893,
      "avg_llm_response": 2.324228366216024,
      "avg_total": 2.3881015293525927,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9450349878076059,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.8499999999575,
      "answer_correctness": 0.7546607370672249,
      "EM": 0.0,
      "F1": 0.4291044776119403,
      "avg_retrieve_context": 0.06387316313656893,
      "avg_llm_response": 1.2576478719711304,
      "avg_total": 1.3215210351076994,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.2640036018815256,
      "faithfulness": 0.6599999999999999,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.6889008820458699,
      "EM": 0.6,
      "F1": 0.6968888888888889,
      "avg_retrieve_context": 0.06387316313656895,
      "avg_llm_response": 0.8671101093292236,
      "avg_total": 0.9309832724657925,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7013572827869292,
      "faithfulness": 0.7855631868131868,
      "context_recall": 0.9625,
      "context_precision": 0.8234996692747676,
      "answer_correctness": 0.6480049880098858,
      "EM": 0.05,
      "F1": 0.44896093855241864,
      "avg_retrieve_context": 0.06387316313656892,
      "avg_llm_response": 1.6954892555872598,
      "avg_total": 1.7593624187238284,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.8431120837108959,
      "faithfulness": 0.8241071428571429,
      "context_recall": 0.975,
      "context_precision": 0.8097866787566297,
      "answer_correctness": 0.7317658475039813,
      "EM": 0.0,
      "F1": 0.521725581653,
      "avg_retrieve_context": 0.06387316313656893,
      "avg_llm_response": 1.6283005893230438,
      "avg_total": 1.6921737524596125,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.2640036018815256,
      "faithfulness": 0.6599999999999999,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.6889008820458699,
      "EM": 0.6,
      "F1": 0.6968888888888889,
      "avg_retrieve_context": 0.06387316313656895,
      "avg_llm_response": 0.8671101093292236,
      "avg_total": 0.9309832724657925,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.2640036018815256,
      "faithfulness": 0.6599999999999999,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.6889008820458699,
      "EM": 0.6,
      "F1": 0.6968888888888889,
      "avg_retrieve_context": 0.06387316313656895,
      "avg_llm_response": 0.8671101093292236,
      "avg_total": 0.9309832724657925,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.792946216320141,
      "faithfulness": 0.812433079740772,
      "context_recall": 0.9706959706959708,
      "context_precision": 0.8125810816417186,
      "answer_correctness": 0.7067396046971035,
      "EM": 0.03296703296703297,
      "F1": 0.505928797144535,
      "avg_retrieve_context": 0.06387316313656896,
      "avg_llm_response": 1.6774913295284732,
      "avg_total": 1.7413644926650422,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.4053127367243056,
      "faithfulness": 0.6851851851851851,
      "context_recall": 0.9351851851851851,
      "context_precision": 0.8729520974838725,
      "answer_correctness": 0.42640323925733203,
      "EM": 0.0,
      "F1": 0.19635100434582564,
      "avg_retrieve_context": 0.06387316313656893,
      "avg_llm_response": 1.578851991229587,
      "avg_total": 1.642725154366156,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7895093177943473,
      "faithfulness": 0.8010897435897435,
      "context_recall": 0.9675925925925927,
      "context_precision": 0.8149650607822456,
      "answer_correctness": 0.7002084152993362,
      "EM": 0.03333333333333333,
      "F1": 0.4940962573747011,
      "avg_retrieve_context": 0.06387316313656896,
      "avg_llm_response": 1.7276107576158313,
      "avg_total": 1.7914839207524003,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.3695058866487783,
      "faithfulness": 0.73,
      "context_recall": 0.9333333333333332,
      "context_precision": 0.42272959181745684,
      "answer_correctness": 0.601059231213542,
      "EM": 0.3,
      "F1": 0.5153452652215453,
      "avg_retrieve_context": 0.06387316313656895,
      "avg_llm_response": 1.002375590801239,
      "avg_total": 1.066248753937808,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 7,
  "negative_rejection_percentage": 70.0
}