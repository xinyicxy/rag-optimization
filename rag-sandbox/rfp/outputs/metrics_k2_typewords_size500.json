{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6499609533585006,
      "faithfulness": 0.7845454545454547,
      "context_recall": 0.85,
      "context_precision": 0.813636363575909,
      "answer_correctness": 0.6437716076933027,
      "EM": 0.09090909090909091,
      "F1": 0.4729709649378703,
      "avg_retrieve_context": 0.0633085467598655,
      "avg_llm_response": 1.1137849786064842,
      "avg_total": 1.1770935253663495,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.6205991497290944,
      "faithfulness": 0.778344671201814,
      "context_recall": 0.6428571428571429,
      "context_precision": 0.8333333332761905,
      "answer_correctness": 0.5074252188733164,
      "EM": 0.0,
      "F1": 0.29411929596836,
      "avg_retrieve_context": 0.0633085467598655,
      "avg_llm_response": 1.3675505887894404,
      "avg_total": 1.430859135549306,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7760006901227154,
      "faithfulness": 0.7564102564102563,
      "context_recall": 0.8846153846153846,
      "context_precision": 0.999999999930769,
      "answer_correctness": 0.7066559105800626,
      "EM": 0.07692307692307693,
      "F1": 0.5740137476602319,
      "avg_retrieve_context": 0.06330854675986551,
      "avg_llm_response": 1.4629688262939453,
      "avg_total": 1.526277373053811,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7983403993537733,
      "faithfulness": 0.7916666666666666,
      "context_recall": 0.9166666666666666,
      "context_precision": 0.9166666665875001,
      "answer_correctness": 0.6838351923078961,
      "EM": 0.0,
      "F1": 0.3924703988920244,
      "avg_retrieve_context": 0.06330854675986551,
      "avg_llm_response": 0.7509060502052307,
      "avg_total": 0.8142145969650961,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.5345576947917907,
      "faithfulness": 0.8122448979591838,
      "context_recall": 0.8928571428571429,
      "context_precision": 0.8571428570785714,
      "answer_correctness": 0.5718128735229298,
      "EM": 0.07142857142857142,
      "F1": 0.4604185511879674,
      "avg_retrieve_context": 0.06330854675986551,
      "avg_llm_response": 0.9382756096976144,
      "avg_total": 1.0015841564574797,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.8105338530822457,
      "faithfulness": 0.7083333333333334,
      "context_recall": 1.0,
      "context_precision": 0.9166666665916666,
      "answer_correctness": 0.7557220703723745,
      "EM": 0.0,
      "F1": 0.4517744564803388,
      "avg_retrieve_context": 0.06330854675986551,
      "avg_llm_response": 0.7805041869481405,
      "avg_total": 0.8438127337080058,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.5703883569679535,
      "faithfulness": 0.8,
      "context_recall": 0.8,
      "context_precision": 0.99999999992,
      "answer_correctness": 0.4417308272710955,
      "EM": 0.0,
      "F1": 0.3554915672562731,
      "avg_retrieve_context": 0.0633085467598655,
      "avg_llm_response": 1.3171480655670167,
      "avg_total": 1.380456612326882,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.6026364297401443,
      "faithfulness": 0.7708333333333333,
      "context_recall": 1.0,
      "context_precision": 0.9374999999375,
      "answer_correctness": 0.5222749022418762,
      "EM": 0.0,
      "F1": 0.28994874903305135,
      "avg_retrieve_context": 0.0633085467598655,
      "avg_llm_response": 0.8416860997676849,
      "avg_total": 0.9049946465275505,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.9662759904598488,
      "faithfulness": 0.888888888888889,
      "context_recall": 1.0,
      "context_precision": 0.8333333332666667,
      "answer_correctness": 0.7944292782258593,
      "EM": 0.0,
      "F1": 0.6892171653398725,
      "avg_retrieve_context": 0.06330854675986551,
      "avg_llm_response": 0.6968772808710734,
      "avg_total": 0.7601858276309388,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9590841294490108,
      "faithfulness": 1.0,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.833333333275,
      "answer_correctness": 0.7546461719781928,
      "EM": 0.0,
      "F1": 0.5709524124965302,
      "avg_retrieve_context": 0.06330854675986551,
      "avg_llm_response": 1.7517362435658772,
      "avg_total": 1.8150447903257423,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.7146032363242634,
      "faithfulness": 0.75,
      "context_recall": 0.75,
      "context_precision": 0.7499999999375,
      "answer_correctness": 0.5931943551598421,
      "EM": 0.0,
      "F1": 0.37001885369532433,
      "avg_retrieve_context": 0.0633085467598655,
      "avg_llm_response": 0.8539720773696899,
      "avg_total": 0.9172806241295555,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.8862972996869654,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.9999999999333333,
      "answer_correctness": 0.9578848096087501,
      "EM": 0.0,
      "F1": 0.6577340787867104,
      "avg_retrieve_context": 0.0633085467598655,
      "avg_llm_response": 1.8447935581207275,
      "avg_total": 1.9081021048805933,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.40899337645999695,
      "faithfulness": 0.75,
      "context_recall": 1.0,
      "context_precision": 0.999999999925,
      "answer_correctness": 0.3965610243328629,
      "EM": 0.0,
      "F1": 0.26086956521739135,
      "avg_retrieve_context": 0.0633085467598655,
      "avg_llm_response": 1.2449055910110474,
      "avg_total": 1.3082141377709129,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.08875325762129149,
      "faithfulness": 0.6,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8505825499486679,
      "EM": 0.8,
      "F1": 0.888888888888889,
      "avg_retrieve_context": 0.0633085467598655,
      "avg_llm_response": 0.8498443841934205,
      "avg_total": 0.9131529309532859,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.6697413939206105,
      "faithfulness": 0.7841666666666666,
      "context_recall": 0.8083333333333333,
      "context_precision": 0.8916666666008333,
      "answer_correctness": 0.6008976495149371,
      "EM": 0.03333333333333333,
      "F1": 0.4132364739709068,
      "avg_retrieve_context": 0.06330854675986551,
      "avg_llm_response": 1.164731470743815,
      "avg_total": 1.2280400175036807,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.7605922164496375,
      "faithfulness": 0.83125,
      "context_recall": 0.9,
      "context_precision": 0.8999999999325,
      "answer_correctness": 0.6563798093970098,
      "EM": 0.0,
      "F1": 0.45859322040056083,
      "avg_retrieve_context": 0.0633085467598655,
      "avg_llm_response": 1.1033503890037537,
      "avg_total": 1.166658935763619,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.08875325762129149,
      "faithfulness": 0.6,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8505825499486679,
      "EM": 0.8,
      "F1": 0.888888888888889,
      "avg_retrieve_context": 0.0633085467598655,
      "avg_llm_response": 0.8498443841934205,
      "avg_total": 0.9131529309532859,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.08875325762129149,
      "faithfulness": 0.6,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8505825499486679,
      "EM": 0.8,
      "F1": 0.888888888888889,
      "avg_retrieve_context": 0.0633085467598655,
      "avg_llm_response": 0.8498443841934205,
      "avg_total": 0.9131529309532859,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.726418145264193,
      "faithfulness": 0.8145211930926216,
      "context_recall": 0.880952380952381,
      "context_precision": 0.8956043955368133,
      "answer_correctness": 0.646177038276152,
      "EM": 0.02197802197802198,
      "F1": 0.4545883535919686,
      "avg_retrieve_context": 0.0633085467598655,
      "avg_llm_response": 1.1068290851928375,
      "avg_total": 1.170137631952703,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.5004578971311725,
      "faithfulness": 0.6865079365079365,
      "context_recall": 0.48148148148148145,
      "context_precision": 0.8888888888333333,
      "answer_correctness": 0.38966009596075407,
      "EM": 0.0,
      "F1": 0.19670856415641078,
      "avg_retrieve_context": 0.0633085467598655,
      "avg_llm_response": 1.4773841169145372,
      "avg_total": 1.5406926636744027,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7113943282997239,
      "faithfulness": 0.8172222222222222,
      "context_recall": 0.8425925925925927,
      "context_precision": 0.8944444443772224,
      "answer_correctness": 0.6296956771147407,
      "EM": 0.022222222222222223,
      "F1": 0.44195788444163964,
      "avg_retrieve_context": 0.06330854675986551,
      "avg_llm_response": 1.156346779399448,
      "avg_total": 1.2196553261593133,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.37351076612299444,
      "faithfulness": 0.6375,
      "context_recall": 0.8833333333333332,
      "context_precision": 0.44999999997,
      "answer_correctness": 0.7071132952968314,
      "EM": 0.4,
      "F1": 0.6125298271709083,
      "avg_retrieve_context": 0.0633085467598655,
      "avg_llm_response": 0.922256875038147,
      "avg_total": 0.9855654217980128,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 9,
  "negative_rejection_percentage": 90.0
}