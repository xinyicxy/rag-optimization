{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.710207831436782,
      "faithfulness": 0.8534632034632035,
      "context_recall": 0.893939393939394,
      "context_precision": 0.7576010100625294,
      "answer_correctness": 0.7108766423249012,
      "EM": 0.06363636363636363,
      "F1": 0.5007097750003769,
      "avg_retrieve_context": 0.10233633518219,
      "avg_llm_response": 2.0666225390000776,
      "avg_total": 2.1689588741822687,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.629526678576356,
      "faithfulness": 0.8730158730158731,
      "context_recall": 0.8492063492063492,
      "context_precision": 0.8690476190008332,
      "answer_correctness": 0.6031728341144483,
      "EM": 0.0,
      "F1": 0.3086295956850095,
      "avg_retrieve_context": 0.10233633518218993,
      "avg_llm_response": 2.8691719486599876,
      "avg_total": 2.9715082838421774,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7042220458992239,
      "faithfulness": 0.7948717948717948,
      "context_recall": 0.8846153846153846,
      "context_precision": 0.7741452991138211,
      "answer_correctness": 0.6202420852734096,
      "EM": 0.07692307692307693,
      "F1": 0.5142435753802226,
      "avg_retrieve_context": 0.10233633518218996,
      "avg_llm_response": 2.959735026726356,
      "avg_total": 3.0620713619085453,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.797559028978282,
      "faithfulness": 0.7916666666666666,
      "context_recall": 0.9166666666666666,
      "context_precision": 0.8722222221738077,
      "answer_correctness": 0.6647271583773989,
      "EM": 0.0,
      "F1": 0.4076357862760355,
      "avg_retrieve_context": 0.10233633518218994,
      "avg_llm_response": 1.2577104568481445,
      "avg_total": 1.3600467920303345,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.7357404928306496,
      "faithfulness": 0.8724489795918366,
      "context_recall": 0.9285714285714286,
      "context_precision": 0.8369047618530655,
      "answer_correctness": 0.6668857431036109,
      "EM": 0.07142857142857142,
      "F1": 0.5282900651600827,
      "avg_retrieve_context": 0.10233633518218996,
      "avg_llm_response": 2.2575121266501292,
      "avg_total": 2.359848461832319,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.9396814504485556,
      "faithfulness": 0.8333333333333334,
      "context_recall": 1.0,
      "context_precision": 0.743749999968883,
      "answer_correctness": 0.9433701280185063,
      "EM": 0.0,
      "F1": 0.5749560131191186,
      "avg_retrieve_context": 0.10233633518218994,
      "avg_llm_response": 1.3357679049173992,
      "avg_total": 1.4381042400995891,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.9341669684613404,
      "faithfulness": 0.8333333333333333,
      "context_recall": 1.0,
      "context_precision": 0.7633333332860556,
      "answer_correctness": 0.8098603194270366,
      "EM": 0.0,
      "F1": 0.5926875178131715,
      "avg_retrieve_context": 0.10233633518218994,
      "avg_llm_response": 2.1954174995422364,
      "avg_total": 2.297753834724426,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.9632433368361916,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.9234374999622266,
      "answer_correctness": 0.8712890869195791,
      "EM": 0.0,
      "F1": 0.5251826201590353,
      "avg_retrieve_context": 0.10233633518218994,
      "avg_llm_response": 1.4727253913879395,
      "avg_total": 1.5750617265701292,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.7967813374263603,
      "faithfulness": 0.9166666666666666,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.8166666666116665,
      "answer_correctness": 0.7145822241135785,
      "EM": 0.0,
      "F1": 0.5421374932441733,
      "avg_retrieve_context": 0.10233633518218994,
      "avg_llm_response": 1.1398294766743977,
      "avg_total": 1.2421658118565877,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9611145021677377,
      "faithfulness": 0.9166666666666666,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.8037037036767978,
      "answer_correctness": 0.7276026477254778,
      "EM": 0.0,
      "F1": 0.5095059280808701,
      "avg_retrieve_context": 0.10233633518218994,
      "avg_llm_response": 3.676719586054484,
      "avg_total": 3.779055921236674,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.461935083705747,
      "faithfulness": 0.7083333333333333,
      "context_recall": 0.5,
      "context_precision": 0.7166666666461111,
      "answer_correctness": 0.4683663193460431,
      "EM": 0.0,
      "F1": 0.3116840065279478,
      "avg_retrieve_context": 0.10233633518218994,
      "avg_llm_response": 1.1335360407829285,
      "avg_total": 1.2358723759651185,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.8925612050631258,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.9444444443861112,
      "answer_correctness": 0.9572507787965021,
      "EM": 0.0,
      "F1": 0.6974175250037319,
      "avg_retrieve_context": 0.10233633518218994,
      "avg_llm_response": 2.0973029136657715,
      "avg_total": 2.1996392488479612,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9332813648274787,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.87499999996875,
      "answer_correctness": 0.8293095536685062,
      "EM": 0.0,
      "F1": 0.40247879973907374,
      "avg_retrieve_context": 0.10233633518218994,
      "avg_llm_response": 1.3376190662384033,
      "avg_total": 1.4399554014205933,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.09226074069646863,
      "faithfulness": 0.75,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8416746714054202,
      "EM": 0.5,
      "F1": 0.8555555555555555,
      "avg_retrieve_context": 0.10233633518218994,
      "avg_llm_response": 0.8727534294128418,
      "avg_total": 0.9750897645950317,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.704100368236031,
      "faithfulness": 0.8396825396825397,
      "context_recall": 0.888888888888889,
      "context_precision": 0.8416203703254298,
      "answer_correctness": 0.6340483821489512,
      "EM": 0.03333333333333333,
      "F1": 0.424234638948028,
      "avg_retrieve_context": 0.10233633518218994,
      "avg_llm_response": 2.4237810254096983,
      "avg_total": 2.5261173605918894,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.8738557989229869,
      "faithfulness": 0.9,
      "context_recall": 0.9,
      "context_precision": 0.8209722221838114,
      "answer_correctness": 0.7934195253186971,
      "EM": 0.0,
      "F1": 0.5267110339401061,
      "avg_retrieve_context": 0.10233633518218994,
      "avg_llm_response": 1.8293520867824555,
      "avg_total": 1.9316884219646453,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.09226074069646863,
      "faithfulness": 0.75,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8416746714054202,
      "EM": 0.5,
      "F1": 0.8555555555555555,
      "avg_retrieve_context": 0.10233633518218994,
      "avg_llm_response": 0.8727534294128418,
      "avg_total": 0.9750897645950317,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.09226074069646863,
      "faithfulness": 0.75,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8416746714054202,
      "EM": 0.5,
      "F1": 0.8555555555555555,
      "avg_retrieve_context": 0.10233633518218994,
      "avg_llm_response": 0.8727534294128418,
      "avg_total": 0.9750897645950317,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.8171021157758154,
      "faithfulness": 0.8796441653584511,
      "context_recall": 0.9157509157509158,
      "context_precision": 0.8269536019095504,
      "answer_correctness": 0.7236741908084452,
      "EM": 0.02197802197802198,
      "F1": 0.49505833036522895,
      "avg_retrieve_context": 0.10233633518218999,
      "avg_llm_response": 2.18896524984758,
      "avg_total": 2.2913015850297707,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.31599572394245967,
      "faithfulness": 0.7037037037037037,
      "context_recall": 0.6666666666666665,
      "context_precision": 0.8981481481232407,
      "answer_correctness": 0.4361480642351602,
      "EM": 0.0,
      "F1": 0.16357907013889939,
      "avg_retrieve_context": 0.10233633518218994,
      "avg_llm_response": 2.1561230288611517,
      "avg_total": 2.2584593640433415,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7948786277196174,
      "faithfulness": 0.8783068783068781,
      "context_recall": 0.8851851851851852,
      "context_precision": 0.82503086415603,
      "answer_correctness": 0.7165117754602406,
      "EM": 0.022222222222222223,
      "F1": 0.4842375375751548,
      "avg_retrieve_context": 0.10233633518218999,
      "avg_llm_response": 2.167117479112413,
      "avg_total": 2.2694538142946037,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.3291892481640221,
      "faithfulness": 0.7416666666666666,
      "context_recall": 0.9333333333333332,
      "context_precision": 0.45416666664177774,
      "answer_correctness": 0.6855185432158754,
      "EM": 0.25,
      "F1": 0.574834843413877,
      "avg_retrieve_context": 0.10233633518218994,
      "avg_llm_response": 1.614395308494568,
      "avg_total": 1.7167316436767575,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 9,
  "negative_rejection_percentage": 90.0
}