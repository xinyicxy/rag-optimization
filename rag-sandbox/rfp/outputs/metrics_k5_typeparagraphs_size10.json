{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6884223508193895,
      "faithfulness": 0.7906116106116107,
      "context_recall": 0.8564393939393941,
      "context_precision": 0.7279671716791704,
      "answer_correctness": 0.6414081227867735,
      "EM": 0.07272727272727272,
      "F1": 0.4521918950052045,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 1.278919378193942,
      "avg_total": 1.3486833615736533,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.7034407905084558,
      "faithfulness": 0.8174603174603173,
      "context_recall": 0.8015873015873015,
      "context_precision": 0.8804232803738007,
      "answer_correctness": 0.5740917319444501,
      "EM": 0.0,
      "F1": 0.3402941869303033,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 1.2497773738134474,
      "avg_total": 1.3195413571931587,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.79712870382272,
      "faithfulness": 0.7307692307692307,
      "context_recall": 0.9230769230769231,
      "context_precision": 0.9124999999633732,
      "answer_correctness": 0.7445700238006252,
      "EM": 0.07692307692307693,
      "F1": 0.5809960932811328,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 1.4554170461801381,
      "avg_total": 1.5251810295598494,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7171907651602862,
      "faithfulness": 0.875,
      "context_recall": 1.0,
      "context_precision": 0.8333333332844907,
      "answer_correctness": 0.6653213394070223,
      "EM": 0.0,
      "F1": 0.41792057311345543,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 0.8729361891746521,
      "avg_total": 0.9427001725543628,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.6666206511062848,
      "faithfulness": 0.7843406593406593,
      "context_recall": 0.9553571428571429,
      "context_precision": 0.7408730158354232,
      "answer_correctness": 0.6766979136924531,
      "EM": 0.07142857142857142,
      "F1": 0.4462334422249773,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 1.812840802328927,
      "avg_total": 1.8826047857086385,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.8149042413364097,
      "faithfulness": 0.875,
      "context_recall": 1.0,
      "context_precision": 0.7509259258977007,
      "answer_correctness": 0.7619402023189568,
      "EM": 0.0,
      "F1": 0.498909543615426,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 0.7183776696523031,
      "avg_total": 0.7881416530320139,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.7323519574983621,
      "faithfulness": 0.76,
      "context_recall": 0.8,
      "context_precision": 0.7499999999425,
      "answer_correctness": 0.6259597999651305,
      "EM": 0.0,
      "F1": 0.421945461945462,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 1.333670473098755,
      "avg_total": 1.4034344564784658,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.7136892662547674,
      "faithfulness": 0.8541666666666666,
      "context_recall": 1.0,
      "context_precision": 0.9303819443923944,
      "answer_correctness": 0.5004788809842395,
      "EM": 0.0,
      "F1": 0.34440346867131005,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 1.459307998418808,
      "avg_total": 1.529071981798519,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.7928955066270486,
      "faithfulness": 0.5833333333333334,
      "context_recall": 0.5,
      "context_precision": 0.5090277777494271,
      "answer_correctness": 0.6346988436530077,
      "EM": 0.0,
      "F1": 0.5015990212778915,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 0.6355883280436198,
      "avg_total": 0.7053523114233307,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.8002337022600029,
      "faithfulness": 0.9166666666666666,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.7324074073807253,
      "answer_correctness": 0.5913429494285215,
      "EM": 0.0,
      "F1": 0.4078282828282828,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 1.647970716158549,
      "avg_total": 1.7177346995382596,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.46977973440919163,
      "faithfulness": 0.6369047619047619,
      "context_recall": 0.75,
      "context_precision": 0.5638888888638426,
      "answer_correctness": 0.4354404868199572,
      "EM": 0.0,
      "F1": 0.276671745809707,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 0.7911410331726074,
      "avg_total": 0.8609050165523182,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.872995200665217,
      "faithfulness": 0.9629629629629629,
      "context_recall": 1.0,
      "context_precision": 0.8722222221670369,
      "answer_correctness": 0.9927677406547835,
      "EM": 0.0,
      "F1": 0.6322936841870924,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 2.084700266520182,
      "avg_total": 2.154464249899893,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9067456339334066,
      "faithfulness": 1.0,
      "context_recall": 0.5,
      "context_precision": 0.666666666625,
      "answer_correctness": 0.5960598853545019,
      "EM": 0.0,
      "F1": 0.2861165868769361,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 1.2260913848876953,
      "avg_total": 1.295855368267406,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.25214801159785405,
      "faithfulness": 0.65,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.6388223001669247,
      "EM": 0.6,
      "F1": 0.6888888888888889,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 1.143509531021118,
      "avg_total": 1.213273514400829,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7178984674630726,
      "faithfulness": 0.802457264957265,
      "context_recall": 0.9034722222222222,
      "context_precision": 0.8453935184747248,
      "answer_correctness": 0.6532160590803365,
      "EM": 0.03333333333333333,
      "F1": 0.43269070344503735,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 1.3503458658854166,
      "avg_total": 1.4201098492651278,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.7532767606592488,
      "faithfulness": 0.8079960317460317,
      "context_recall": 0.8,
      "context_precision": 0.7338194444056314,
      "answer_correctness": 0.6243426740013917,
      "EM": 0.0,
      "F1": 0.4222694338745342,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 1.205632108449936,
      "avg_total": 1.2753960918296467,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.25214801159785405,
      "faithfulness": 0.65,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.6388223001669247,
      "EM": 0.6,
      "F1": 0.6888888888888889,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 1.143509531021118,
      "avg_total": 1.213273514400829,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.25214801159785405,
      "faithfulness": 0.65,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.6388223001669247,
      "EM": 0.6,
      "F1": 0.6888888888888889,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 1.143509531021118,
      "avg_total": 1.213273514400829,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7656673403280787,
      "faithfulness": 0.8128272216184305,
      "context_recall": 0.8923992673992674,
      "context_precision": 0.7825244199820801,
      "answer_correctness": 0.674357212862976,
      "EM": 0.02197802197802198,
      "F1": 0.4546616156843486,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 1.3017345129788578,
      "avg_total": 1.3714984963585686,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.39213894492212664,
      "faithfulness": 0.7222222222222222,
      "context_recall": 0.5555555555555556,
      "context_precision": 0.9851851851488271,
      "answer_correctness": 0.31112934826055844,
      "EM": 0.0,
      "F1": 0.16422361493420923,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 1.1986884011162653,
      "avg_total": 1.268452384495976,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7511027961826944,
      "faithfulness": 0.8033401166734501,
      "context_recall": 0.8578703703703705,
      "context_precision": 0.7957870369953123,
      "answer_correctness": 0.6488934261705468,
      "EM": 0.022222222222222223,
      "F1": 0.439168078481968,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 1.3347933027479384,
      "avg_total": 1.4045572861276494,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.40636034668451737,
      "faithfulness": 0.7333333333333333,
      "context_recall": 0.85,
      "context_precision": 0.42277777775653236,
      "answer_correctness": 0.6077242575597944,
      "EM": 0.3,
      "F1": 0.510799069359769,
      "avg_retrieve_context": 0.0697639833797108,
      "avg_llm_response": 1.0274867177009583,
      "avg_total": 1.0972507010806694,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 7,
  "negative_rejection_percentage": 70.0
}
