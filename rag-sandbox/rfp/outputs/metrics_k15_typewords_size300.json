{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6672076521950862,
      "faithfulness": 0.8193181818181818,
      "context_recall": 0.9507575757575757,
      "context_precision": 0.6913182930080217,
      "answer_correctness": 0.6973702721022613,
      "EM": 0.09090909090909091,
      "F1": 0.48999962413004644,
      "avg_retrieve_context": 0.09131960218602961,
      "avg_llm_response": 1.6179177024147726,
      "avg_total": 1.7092373046008018,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.5294002396634744,
      "faithfulness": 0.7678571428571429,
      "context_recall": 0.9563492063492063,
      "context_precision": 0.7111417053347062,
      "answer_correctness": 0.5141136631605222,
      "EM": 0.0,
      "F1": 0.2463181414134787,
      "avg_retrieve_context": 0.09131960218602961,
      "avg_llm_response": 1.736600467136928,
      "avg_total": 1.827920069322958,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.650391461153936,
      "faithfulness": 0.7628205128205128,
      "context_recall": 0.9615384615384616,
      "context_precision": 0.8003627522994936,
      "answer_correctness": 0.6590065370780498,
      "EM": 0.07692307692307693,
      "F1": 0.501992131439913,
      "avg_retrieve_context": 0.09131960218602962,
      "avg_llm_response": 1.8060068900768573,
      "avg_total": 1.8973264922628867,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.6296729907035202,
      "faithfulness": 0.8472222222222222,
      "context_recall": 1.0,
      "context_precision": 0.7253306877832296,
      "answer_correctness": 0.7159538048520887,
      "EM": 0.08333333333333333,
      "F1": 0.39422712714454994,
      "avg_retrieve_context": 0.09131960218602962,
      "avg_llm_response": 1.1150736808776855,
      "avg_total": 1.2063932830637152,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.8036635474939391,
      "faithfulness": 0.8928571428571429,
      "context_recall": 1.0,
      "context_precision": 0.7462658174743694,
      "answer_correctness": 0.7721398207009205,
      "EM": 0.07142857142857142,
      "F1": 0.6412287083549318,
      "avg_retrieve_context": 0.09131960218602962,
      "avg_llm_response": 1.7470128876822335,
      "avg_total": 1.838332489868263,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.6428253963155003,
      "faithfulness": 0.7916666666666666,
      "context_recall": 1.0,
      "context_precision": 0.5883010948307571,
      "answer_correctness": 0.6781747266822601,
      "EM": 0.0,
      "F1": 0.36840821450990946,
      "avg_retrieve_context": 0.09131960218602962,
      "avg_llm_response": 1.4258568684260051,
      "avg_total": 1.5171764706120348,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.9196577266535282,
      "faithfulness": 0.9,
      "context_recall": 1.0,
      "context_precision": 0.8733333332675557,
      "answer_correctness": 0.7213154720714653,
      "EM": 0.0,
      "F1": 0.48009090909090907,
      "avg_retrieve_context": 0.09131960218602961,
      "avg_llm_response": 2.024558925628662,
      "avg_total": 2.1158785278146914,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.8318118675458986,
      "faithfulness": 0.9375,
      "context_recall": 1.0,
      "context_precision": 0.9436733047205201,
      "answer_correctness": 0.6723948388378671,
      "EM": 0.0,
      "F1": 0.48513688795946863,
      "avg_retrieve_context": 0.09131960218602961,
      "avg_llm_response": 1.3181889355182648,
      "avg_total": 1.4095085377042942,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.9585164484268677,
      "faithfulness": 0.6666666666666666,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.7275327681212772,
      "answer_correctness": 0.7510655046308506,
      "EM": 0.0,
      "F1": 0.6714004168763886,
      "avg_retrieve_context": 0.09131960218602962,
      "avg_llm_response": 1.2700392405192058,
      "avg_total": 1.3613588427052352,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9590005742266917,
      "faithfulness": 0.9444444444444445,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.7373684879781965,
      "answer_correctness": 0.7448734658555184,
      "EM": 0.0,
      "F1": 0.5096602207250555,
      "avg_retrieve_context": 0.09131960218602962,
      "avg_llm_response": 2.5029184818267822,
      "avg_total": 2.5942380840128116,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.9271590224176186,
      "faithfulness": 0.875,
      "context_recall": 1.0,
      "context_precision": 0.8833131550748294,
      "answer_correctness": 0.8753764266310259,
      "EM": 0.0,
      "F1": 0.5653234735189623,
      "avg_retrieve_context": 0.09131960218602961,
      "avg_llm_response": 2.112650156021118,
      "avg_total": 2.2039697582071476,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.6102893941403816,
      "faithfulness": 0.8333333333333334,
      "context_recall": 1.0,
      "context_precision": 0.7666666666212038,
      "answer_correctness": 0.6943106678197069,
      "EM": 0.0,
      "F1": 0.3965811965811965,
      "avg_retrieve_context": 0.0913196021860296,
      "avg_llm_response": 2.027342955271403,
      "avg_total": 2.1186625574574323,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9855536122071181,
      "faithfulness": 0.75,
      "context_recall": 1.0,
      "context_precision": 0.7430555555369791,
      "answer_correctness": 0.7766789510629977,
      "EM": 0.0,
      "F1": 0.3431372549019608,
      "avg_retrieve_context": 0.09131960218602961,
      "avg_llm_response": 2.4131606817245483,
      "avg_total": 2.5044802839105778,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.08875325762129149,
      "faithfulness": 0.75,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.8777641008643944,
      "EM": 0.7,
      "F1": 0.8777777777777779,
      "avg_retrieve_context": 0.09131960218602961,
      "avg_llm_response": 0.8965038776397705,
      "avg_total": 0.9878234798258001,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.6396643263548586,
      "faithfulness": 0.8118055555555554,
      "context_recall": 0.9763888888888889,
      "context_precision": 0.741506354832703,
      "answer_correctness": 0.6460812509403927,
      "EM": 0.05,
      "F1": 0.42344176868509276,
      "avg_retrieve_context": 0.09131960218602961,
      "avg_llm_response": 1.6297627329826354,
      "avg_total": 1.721082335168665,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.8531362395988762,
      "faithfulness": 0.8479166666666668,
      "context_recall": 0.95,
      "context_precision": 0.7888657735230054,
      "answer_correctness": 0.7292053466545314,
      "EM": 0.0,
      "F1": 0.4928918688855443,
      "avg_retrieve_context": 0.09131960218602961,
      "avg_llm_response": 1.780503612756729,
      "avg_total": 1.8718232149427585,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.08875325762129149,
      "faithfulness": 0.75,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.8777641008643944,
      "EM": 0.7,
      "F1": 0.8777777777777779,
      "avg_retrieve_context": 0.09131960218602961,
      "avg_llm_response": 0.8965038776397705,
      "avg_total": 0.9878234798258001,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.08875325762129149,
      "faithfulness": 0.75,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.8777641008643944,
      "EM": 0.7,
      "F1": 0.8777777777777779,
      "avg_retrieve_context": 0.09131960218602961,
      "avg_llm_response": 0.8965038776397705,
      "avg_total": 0.9878234798258001,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7568464395348028,
      "faithfulness": 0.8337912087912088,
      "context_recall": 0.9725274725274725,
      "context_precision": 0.7607766953363896,
      "answer_correctness": 0.6990151419196186,
      "EM": 0.03296703296703297,
      "F1": 0.4782274234553349,
      "avg_retrieve_context": 0.09131960218602961,
      "avg_llm_response": 1.6758915775424832,
      "avg_total": 1.7672111797285126,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.40358701861994445,
      "faithfulness": 0.75,
      "context_recall": 0.898148148148148,
      "context_precision": 0.7571481061412144,
      "answer_correctness": 0.4803012231021697,
      "EM": 0.0,
      "F1": 0.1781650380102063,
      "avg_retrieve_context": 0.09131960218602961,
      "avg_llm_response": 1.8333083258734808,
      "avg_total": 1.9246279280595102,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7438871883578712,
      "faithfulness": 0.8236111111111111,
      "context_recall": 0.9694444444444444,
      "context_precision": 0.7578788836976698,
      "answer_correctness": 0.685911120674156,
      "EM": 0.03333333333333333,
      "F1": 0.46434578313066005,
      "avg_retrieve_context": 0.09131960218602961,
      "avg_llm_response": 1.7416293462117514,
      "avg_total": 1.8329489483977806,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.3221497394625537,
      "faithfulness": 0.8,
      "context_recall": 0.8666666666666666,
      "context_precision": 0.39179563490460545,
      "answer_correctness": 0.748936453528736,
      "EM": 0.35,
      "F1": 0.6054419086272855,
      "avg_retrieve_context": 0.09131960218602961,
      "avg_llm_response": 1.061215305328369,
      "avg_total": 1.1525349075143985,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 9,
  "negative_rejection_percentage": 90.0
}