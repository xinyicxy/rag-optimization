{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6588197618333884,
      "faithfulness": 0.824561852289125,
      "context_recall": 0.816969696969697,
      "context_precision": 0.731414141372949,
      "answer_correctness": 0.6177432708986933,
      "EM": 0.06363636363636363,
      "F1": 0.4581473692228998,
      "avg_retrieve_context": 0.0707809730009599,
      "avg_llm_response": 1.3361838882619685,
      "avg_total": 1.4069648612629284,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.7658974799640997,
      "faithfulness": 0.8467876039304612,
      "context_recall": 0.684126984126984,
      "context_precision": 0.8759259258796583,
      "answer_correctness": 0.6149164426410577,
      "EM": 0.0,
      "F1": 0.3011500850016241,
      "avg_retrieve_context": 0.0707809730009599,
      "avg_llm_response": 1.5768861657097226,
      "avg_total": 1.6476671387106823,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.6412055841946842,
      "faithfulness": 0.7230769230769231,
      "context_recall": 0.8461538461538461,
      "context_precision": 0.8791666666136297,
      "answer_correctness": 0.5787574296467178,
      "EM": 0.07692307692307693,
      "F1": 0.47576278919083703,
      "avg_retrieve_context": 0.0707809730009599,
      "avg_llm_response": 1.42166962990394,
      "avg_total": 1.4924506029049003,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.6400973397182096,
      "faithfulness": 0.9097222222222222,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.7296296295811188,
      "answer_correctness": 0.5497193308561269,
      "EM": 0.0,
      "F1": 0.38889231324410795,
      "avg_retrieve_context": 0.0707809730009599,
      "avg_llm_response": 1.7789796590805054,
      "avg_total": 1.8497606320814655,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.7808416334559645,
      "faithfulness": 0.8532467532467533,
      "context_recall": 0.6785714285714286,
      "context_precision": 0.7492063491589848,
      "answer_correctness": 0.49399637857604795,
      "EM": 0.07142857142857142,
      "F1": 0.48207089771792294,
      "avg_retrieve_context": 0.0707809730009599,
      "avg_llm_response": 1.005517908505031,
      "avg_total": 1.0762988815059913,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.4620159165561004,
      "faithfulness": 0.75,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.5888888888566667,
      "answer_correctness": 0.5614217548567874,
      "EM": 0.0,
      "F1": 0.310412387177093,
      "avg_retrieve_context": 0.07078097300095991,
      "avg_llm_response": 0.6676102081934611,
      "avg_total": 0.7383911811944209,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.5748884395172982,
      "faithfulness": 0.5714285714285714,
      "context_recall": 0.8,
      "context_precision": 0.5733333332975555,
      "answer_correctness": 0.4369865141383654,
      "EM": 0.0,
      "F1": 0.2903743315508021,
      "avg_retrieve_context": 0.07078097300095991,
      "avg_llm_response": 1.2866488456726075,
      "avg_total": 1.3574298186735674,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.7315645574351242,
      "faithfulness": 0.90625,
      "context_recall": 1.0,
      "context_precision": 0.9369791666147873,
      "answer_correctness": 0.668837955438897,
      "EM": 0.0,
      "F1": 0.4106821477133977,
      "avg_retrieve_context": 0.07078097300095991,
      "avg_llm_response": 0.9457872807979584,
      "avg_total": 1.0165682537989182,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.9500885420087669,
      "faithfulness": 0.8333333333333334,
      "context_recall": 1.0,
      "context_precision": 0.9451388888242881,
      "answer_correctness": 0.6766130843948229,
      "EM": 0.0,
      "F1": 0.6269629554724104,
      "avg_retrieve_context": 0.07078097300095991,
      "avg_llm_response": 0.6158032417297363,
      "avg_total": 0.6865842147306962,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9563069571445321,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.8027777777512964,
      "answer_correctness": 0.7624035236672935,
      "EM": 0.0,
      "F1": 0.5377091868113539,
      "avg_retrieve_context": 0.07078097300095991,
      "avg_llm_response": 2.198081930478414,
      "avg_total": 2.268862903479374,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.6916966371871368,
      "faithfulness": 0.6875,
      "context_recall": 0.75,
      "context_precision": 0.7166666666388195,
      "answer_correctness": 0.6650775473427983,
      "EM": 0.0,
      "F1": 0.36569407603890364,
      "avg_retrieve_context": 0.07078097300095991,
      "avg_llm_response": 2.1416317224502563,
      "avg_total": 2.212412695451216,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.5992870567970804,
      "faithfulness": 0.8333333333333334,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.8333333332933334,
      "answer_correctness": 0.6507860167014894,
      "EM": 0.0,
      "F1": 0.47588917649314544,
      "avg_retrieve_context": 0.07078097300095991,
      "avg_llm_response": 1.782328446706136,
      "avg_total": 1.8531094197070959,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9678141562150266,
      "faithfulness": 0.9,
      "context_recall": 1.0,
      "context_precision": 0.8187499999701562,
      "answer_correctness": 0.6710372353350589,
      "EM": 0.0,
      "F1": 0.27435897435897433,
      "avg_retrieve_context": 0.07078097300095991,
      "avg_llm_response": 1.8149840831756592,
      "avg_total": 1.885765056176619,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.0,
      "faithfulness": 0.8,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8509077545786322,
      "EM": 0.5,
      "F1": 0.9444444444444444,
      "avg_retrieve_context": 0.0707809730009599,
      "avg_llm_response": 0.752691125869751,
      "avg_total": 0.8234720988707108,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7172078436463167,
      "faithfulness": 0.8340776815776815,
      "context_recall": 0.7477777777777777,
      "context_precision": 0.817800925877487,
      "answer_correctness": 0.5658278858534622,
      "EM": 0.03333333333333333,
      "F1": 0.39874613952492005,
      "avg_retrieve_context": 0.07078097300095991,
      "avg_llm_response": 1.450355354944865,
      "avg_total": 1.521136327945825,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.735942579572343,
      "faithfulness": 0.8164285714285715,
      "context_recall": 0.9,
      "context_precision": 0.7846874999593794,
      "answer_correctness": 0.6373252275465552,
      "EM": 0.0,
      "F1": 0.42567494496448344,
      "avg_retrieve_context": 0.07078097300095991,
      "avg_llm_response": 1.310799878835678,
      "avg_total": 1.3815808518366381,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.0,
      "faithfulness": 0.8,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8509077545786322,
      "EM": 0.5,
      "F1": 0.9444444444444444,
      "avg_retrieve_context": 0.0707809730009599,
      "avg_llm_response": 0.752691125869751,
      "avg_total": 0.8234720988707108,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.0,
      "faithfulness": 0.8,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8509077545786322,
      "EM": 0.5,
      "F1": 0.9444444444444444,
      "avg_retrieve_context": 0.0707809730009599,
      "avg_llm_response": 0.752691125869751,
      "avg_total": 0.8234720988707108,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7260589603196115,
      "faithfulness": 0.835376528233671,
      "context_recall": 0.8278388278388279,
      "context_precision": 0.7879120878668254,
      "answer_correctness": 0.5926174460993497,
      "EM": 0.02197802197802198,
      "F1": 0.42553752117117094,
      "avg_retrieve_context": 0.0707809730009599,
      "avg_llm_response": 1.3731642372005588,
      "avg_total": 1.4439452102015187,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.7109787125097861,
      "faithfulness": 0.7425044091710759,
      "context_recall": 0.6148148148148148,
      "context_precision": 0.9728395061270319,
      "answer_correctness": 0.612721628669902,
      "EM": 0.0,
      "F1": 0.2475390826108873,
      "avg_retrieve_context": 0.07078097300095991,
      "avg_llm_response": 1.6105967627631292,
      "avg_total": 1.6813777357640893,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.732291062342444,
      "faithfulness": 0.8439706589706588,
      "context_recall": 0.8133333333333334,
      "context_precision": 0.7970370369920665,
      "answer_correctness": 0.5956775869315236,
      "EM": 0.022222222222222223,
      "F1": 0.4196192631841908,
      "avg_retrieve_context": 0.0707809730009599,
      "avg_llm_response": 1.4389624754587809,
      "avg_total": 1.5097434484597412,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.3281989095426388,
      "faithfulness": 0.7372222222222222,
      "context_recall": 0.8333333333333333,
      "context_precision": 0.43611111108692124,
      "answer_correctness": 0.7170388487509565,
      "EM": 0.25,
      "F1": 0.6315238463970905,
      "avg_retrieve_context": 0.0707809730009599,
      "avg_llm_response": 0.8736802458763122,
      "avg_total": 0.9444612188772723,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 10,
  "negative_rejection_percentage": 100.0
}
