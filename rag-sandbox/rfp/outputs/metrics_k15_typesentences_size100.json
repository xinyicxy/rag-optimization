{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.689072291238806,
      "faithfulness": 0.8233585858585858,
      "context_recall": 0.9528787878787879,
      "context_precision": 0.767681989648909,
      "answer_correctness": 0.6862243762244993,
      "EM": 0.06363636363636363,
      "F1": 0.4777325010920283,
      "avg_retrieve_context": 0.05753670605746185,
      "avg_llm_response": 2.1618262832814996,
      "avg_total": 2.219362989338961,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.6643895224983746,
      "faithfulness": 0.8095238095238095,
      "context_recall": 0.9722222222222221,
      "context_precision": 0.8515873015502512,
      "answer_correctness": 0.6076754248780507,
      "EM": 0.0,
      "F1": 0.30978134208499725,
      "avg_retrieve_context": 0.05753670605746183,
      "avg_llm_response": 2.5124666690826416,
      "avg_total": 2.5700033751401037,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7077390312475182,
      "faithfulness": 0.8066239316239316,
      "context_recall": 0.8846153846153846,
      "context_precision": 0.9999999999397435,
      "answer_correctness": 0.631988241250724,
      "EM": 0.0,
      "F1": 0.49092023152072856,
      "avg_retrieve_context": 0.057536706057461834,
      "avg_llm_response": 2.04925615970905,
      "avg_total": 2.106792865766512,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7148677472346628,
      "faithfulness": 0.7916666666666666,
      "context_recall": 1.0,
      "context_precision": 0.9999999999416666,
      "answer_correctness": 0.6699227545976445,
      "EM": 0.0,
      "F1": 0.4129303878421056,
      "avg_retrieve_context": 0.057536706057461834,
      "avg_llm_response": 0.9795385996500651,
      "avg_total": 1.037075305707527,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.7301030584748168,
      "faithfulness": 0.9285714285714286,
      "context_recall": 0.9928571428571429,
      "context_precision": 0.6831605635608987,
      "answer_correctness": 0.7728852037596424,
      "EM": 0.07142857142857142,
      "F1": 0.5225372641158955,
      "avg_retrieve_context": 0.05753670605746184,
      "avg_llm_response": 3.5840522050857544,
      "avg_total": 3.6415889111432165,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.7930856877216153,
      "faithfulness": 0.861111111111111,
      "context_recall": 1.0,
      "context_precision": 0.7797949735158607,
      "answer_correctness": 0.7671979092639757,
      "EM": 0.0,
      "F1": 0.5321394618453442,
      "avg_retrieve_context": 0.05753670605746183,
      "avg_llm_response": 2.549331466356913,
      "avg_total": 2.606868172414375,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.7521012248812055,
      "faithfulness": 0.8333333333333333,
      "context_recall": 1.0,
      "context_precision": 0.6185714285228333,
      "answer_correctness": 0.6516335520793548,
      "EM": 0.0,
      "F1": 0.42693766937669375,
      "avg_retrieve_context": 0.05753670605746183,
      "avg_llm_response": 2.0646830081939695,
      "avg_total": 2.1222197142514316,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.8351581139833769,
      "faithfulness": 0.9375,
      "context_recall": 1.0,
      "context_precision": 0.8020833333002083,
      "answer_correctness": 0.8268574914275317,
      "EM": 0.0,
      "F1": 0.5468820840015705,
      "avg_retrieve_context": 0.05753670605746183,
      "avg_llm_response": 1.7914959192276,
      "avg_total": 1.8490326252850617,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.9408924453981963,
      "faithfulness": 0.625,
      "context_recall": 1.0,
      "context_precision": 0.8336026076673413,
      "answer_correctness": 0.6573038325843388,
      "EM": 0.0,
      "F1": 0.5549780499961658,
      "avg_retrieve_context": 0.05753670605746183,
      "avg_llm_response": 1.4170137643814087,
      "avg_total": 1.4745504704388706,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9589648236495917,
      "faithfulness": 0.9166666666666666,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.8775510203948378,
      "answer_correctness": 0.7950284454611255,
      "EM": 0.0,
      "F1": 0.5496941024471804,
      "avg_retrieve_context": 0.05753670605746183,
      "avg_llm_response": 2.837651491165161,
      "avg_total": 2.895188197222623,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.24029357516494512,
      "faithfulness": 0.625,
      "context_recall": 1.0,
      "context_precision": 0.8233333333058529,
      "answer_correctness": 0.3875011645431493,
      "EM": 0.0,
      "F1": 0.16499999999999998,
      "avg_retrieve_context": 0.05753670605746183,
      "avg_llm_response": 1.621293067932129,
      "avg_total": 1.6788297739895908,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.8761834048950528,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.88666666663735,
      "answer_correctness": 0.7976947966650907,
      "EM": 0.0,
      "F1": 0.585941575378195,
      "avg_retrieve_context": 0.05753670605746183,
      "avg_llm_response": 3.266766627629598,
      "avg_total": 3.32430333368706,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9195062020969078,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.794444444417963,
      "answer_correctness": 0.6061240081710719,
      "EM": 0.0,
      "F1": 0.39743589743589747,
      "avg_retrieve_context": 0.05753670605746183,
      "avg_llm_response": 2.8455899953842163,
      "avg_total": 2.903126701441678,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.18171431756934314,
      "faithfulness": 0.7,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7302638538006033,
      "EM": 0.6,
      "F1": 0.7849206349206349,
      "avg_retrieve_context": 0.05753670605746183,
      "avg_llm_response": 0.9011552095413208,
      "avg_total": 0.9586919155987825,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.6992107194024499,
      "faithfulness": 0.8331018518518519,
      "context_recall": 0.9636111111111111,
      "context_precision": 0.8741263536820755,
      "answer_correctness": 0.66394161610842,
      "EM": 0.016666666666666666,
      "F1": 0.419300959088037,
      "avg_retrieve_context": 0.05753670605746181,
      "avg_llm_response": 2.3555554032325743,
      "avg_total": 2.4130921092900355,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.8007041424107054,
      "faithfulness": 0.8395833333333332,
      "context_recall": 0.975,
      "context_precision": 0.7999359410113864,
      "answer_correctness": 0.708638647004592,
      "EM": 0.0,
      "F1": 0.48858278064086386,
      "avg_retrieve_context": 0.05753670605746183,
      "avg_llm_response": 2.186400371789932,
      "avg_total": 2.243937077847394,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.18171431756934314,
      "faithfulness": 0.7,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7302638538006033,
      "EM": 0.6,
      "F1": 0.7849206349206349,
      "avg_retrieve_context": 0.05753670605746183,
      "avg_llm_response": 0.9011552095413208,
      "avg_total": 0.9586919155987825,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.18171431756934314,
      "faithfulness": 0.7,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7302638538006033,
      "EM": 0.6,
      "F1": 0.7849206349206349,
      "avg_retrieve_context": 0.05753670605746183,
      "avg_llm_response": 0.9011552095413208,
      "avg_total": 0.9586919155987825,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7534963052754605,
      "faithfulness": 0.8432539682539683,
      "context_recall": 0.9714285714285715,
      "context_precision": 0.8310807933507248,
      "answer_correctness": 0.6990851109139565,
      "EM": 0.01098901098901099,
      "F1": 0.4702510431213626,
      "avg_retrieve_context": 0.05753670605746184,
      "avg_llm_response": 2.28444796866113,
      "avg_total": 2.3419846747185917,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.6014050089453656,
      "faithfulness": 0.7592592592592592,
      "context_recall": 0.9351851851851851,
      "context_precision": 0.9796296296071141,
      "answer_correctness": 0.5072553059465387,
      "EM": 0.0,
      "F1": 0.21205820520808585,
      "avg_retrieve_context": 0.05753670605746183,
      "avg_llm_response": 2.322730435265435,
      "avg_total": 2.3802671413228973,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7395779495711428,
      "faithfulness": 0.8266975308641976,
      "context_recall": 0.9683333333333334,
      "context_precision": 0.836055765130969,
      "answer_correctness": 0.6894910861413375,
      "EM": 0.011111111111111112,
      "F1": 0.4559974125810699,
      "avg_retrieve_context": 0.057536706057461834,
      "avg_llm_response": 2.2805468373828464,
      "avg_total": 2.3380835434403084,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.46179682874328976,
      "faithfulness": 0.8083333333333332,
      "context_recall": 0.8833333333333332,
      "context_precision": 0.4599999999796389,
      "answer_correctness": 0.6715241815987283,
      "EM": 0.3,
      "F1": 0.5755403993913416,
      "avg_retrieve_context": 0.05753670605746183,
      "avg_llm_response": 1.6275837898254395,
      "avg_total": 1.6851204958829016,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 8,
  "negative_rejection_percentage": 80.0
}