{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.7189947676423768,
      "faithfulness": 0.8491666666666666,
      "context_recall": 0.9409090909090909,
      "context_precision": 0.8004292928921087,
      "answer_correctness": 0.7209900505578842,
      "EM": 0.08181818181818182,
      "F1": 0.5126185868839893,
      "avg_retrieve_context": 0.06170790845697574,
      "avg_llm_response": 1.712741301276467,
      "avg_total": 1.7744492097334434,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.7177159588597459,
      "faithfulness": 0.8476190476190476,
      "context_recall": 0.8571428571428571,
      "context_precision": 0.8587301586909855,
      "answer_correctness": 0.6355539687089694,
      "EM": 0.0,
      "F1": 0.29320937190023766,
      "avg_retrieve_context": 0.06170790845697577,
      "avg_llm_response": 2.214621736889794,
      "avg_total": 2.276329645346769,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7847946020483685,
      "faithfulness": 0.7794871794871795,
      "context_recall": 0.9615384615384616,
      "context_precision": 0.9769230768879488,
      "answer_correctness": 0.6731335762624033,
      "EM": 0.07692307692307693,
      "F1": 0.5632399256170176,
      "avg_retrieve_context": 0.06170790845697575,
      "avg_llm_response": 2.0149084421304555,
      "avg_total": 2.0766163505874315,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7968038615286037,
      "faithfulness": 0.861111111111111,
      "context_recall": 0.9166666666666666,
      "context_precision": 0.9305555555179397,
      "answer_correctness": 0.723132848861549,
      "EM": 0.0,
      "F1": 0.4007475316912703,
      "avg_retrieve_context": 0.06170790845697575,
      "avg_llm_response": 1.1149723728497822,
      "avg_total": 1.176680281306758,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.7334361472148022,
      "faithfulness": 0.8869047619047619,
      "context_recall": 0.9285714285714286,
      "context_precision": 0.8837301586832903,
      "answer_correctness": 0.6560036966672439,
      "EM": 0.07142857142857142,
      "F1": 0.5039476453595807,
      "avg_retrieve_context": 0.06170790845697575,
      "avg_llm_response": 1.6744519983019148,
      "avg_total": 1.736159906758891,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.9390119622479799,
      "faithfulness": 0.9444444444444443,
      "context_recall": 1.0,
      "context_precision": 0.7092592592299923,
      "answer_correctness": 0.8741295194054414,
      "EM": 0.0,
      "F1": 0.5485960567802001,
      "avg_retrieve_context": 0.06170790845697576,
      "avg_llm_response": 1.4124579826990764,
      "avg_total": 1.474165891156052,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.7792374666722269,
      "faithfulness": 0.72,
      "context_recall": 1.0,
      "context_precision": 0.89999999992,
      "answer_correctness": 0.6862966534669528,
      "EM": 0.0,
      "F1": 0.454310390044946,
      "avg_retrieve_context": 0.061707908456975755,
      "avg_llm_response": 1.6016847133636474,
      "avg_total": 1.663392621820623,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.8355016890595542,
      "faithfulness": 0.921875,
      "context_recall": 1.0,
      "context_precision": 0.9756944444027547,
      "answer_correctness": 0.7405859685913925,
      "EM": 0.0,
      "F1": 0.5148639420210158,
      "avg_retrieve_context": 0.06170790845697576,
      "avg_llm_response": 1.574925810098648,
      "avg_total": 1.6366337185556237,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.9460007499092352,
      "faithfulness": 0.7083333333333334,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.7138888888475,
      "answer_correctness": 0.7240060640032707,
      "EM": 0.0,
      "F1": 0.6552766697609588,
      "avg_retrieve_context": 0.06170790845697576,
      "avg_llm_response": 1.3571075201034546,
      "avg_total": 1.4188154285604302,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.8037106661950837,
      "faithfulness": 0.9166666666666666,
      "context_recall": 1.0,
      "context_precision": 0.8340277777547048,
      "answer_correctness": 0.6609553369264181,
      "EM": 0.0,
      "F1": 0.4796104227476777,
      "avg_retrieve_context": 0.06170790845697576,
      "avg_llm_response": 2.131515145301819,
      "avg_total": 2.1932230537587944,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.9484767505632726,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.9510416666241406,
      "answer_correctness": 0.7689883439748879,
      "EM": 0.0,
      "F1": 0.5821315824151899,
      "avg_retrieve_context": 0.06170790845697576,
      "avg_llm_response": 1.8713634014129639,
      "avg_total": 1.9330713098699397,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.8877118211272896,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.8740740740227161,
      "answer_correctness": 0.9581734428530758,
      "EM": 0.0,
      "F1": 0.6786655966983836,
      "avg_retrieve_context": 0.06170790845697576,
      "avg_llm_response": 2.6106040477752686,
      "avg_total": 2.672311956232244,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.40786174852059337,
      "faithfulness": 0.6666666666666666,
      "context_recall": 1.0,
      "context_precision": 0.7499999999583333,
      "answer_correctness": 0.6741265086902042,
      "EM": 0.0,
      "F1": 0.26086956521739135,
      "avg_retrieve_context": 0.06170790845697576,
      "avg_llm_response": 2.64997935295105,
      "avg_total": 2.7116872614080254,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.0,
      "faithfulness": 0.8,
      "context_recall": 1.0,
      "context_precision": 0.0,
      "answer_correctness": 0.9140446527471792,
      "EM": 0.7,
      "F1": 0.9666666666666666,
      "avg_retrieve_context": 0.061707908456975755,
      "avg_llm_response": 0.824714207649231,
      "avg_total": 0.8864221161062066,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7517352893672321,
      "faithfulness": 0.8447222222222223,
      "context_recall": 0.9083333333333333,
      "context_precision": 0.9045370369972561,
      "answer_correctness": 0.6659835962329932,
      "EM": 0.03333333333333333,
      "F1": 0.4223958876375932,
      "avg_retrieve_context": 0.06170790845697575,
      "avg_llm_response": 1.825381044546763,
      "avg_total": 1.8870889530037394,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.8496326769656877,
      "faithfulness": 0.8681249999999998,
      "context_recall": 0.975,
      "context_precision": 0.8443749999574148,
      "answer_correctness": 0.7552360814978968,
      "EM": 0.0,
      "F1": 0.5344406158079142,
      "avg_retrieve_context": 0.061707908456975755,
      "avg_llm_response": 1.765788459777832,
      "avg_total": 1.8274963682348075,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.0,
      "faithfulness": 0.8,
      "context_recall": 1.0,
      "context_precision": 0.0,
      "answer_correctness": 0.9140446527471792,
      "EM": 0.7,
      "F1": 0.9666666666666666,
      "avg_retrieve_context": 0.061707908456975755,
      "avg_llm_response": 0.824714207649231,
      "avg_total": 0.8864221161062066,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.0,
      "faithfulness": 0.8,
      "context_recall": 1.0,
      "context_precision": 0.0,
      "answer_correctness": 0.9140446527471792,
      "EM": 0.7,
      "F1": 0.9666666666666666,
      "avg_retrieve_context": 0.061707908456975755,
      "avg_llm_response": 0.824714207649231,
      "avg_total": 0.8864221161062066,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.8185496695985273,
      "faithfulness": 0.8693223443223443,
      "context_recall": 0.9505494505494505,
      "context_precision": 0.8686507936080253,
      "answer_correctness": 0.7238413995487877,
      "EM": 0.02197802197802198,
      "F1": 0.4934645877980951,
      "avg_retrieve_context": 0.06170790845697575,
      "avg_llm_response": 1.7722140013516605,
      "avg_total": 1.8339219098086363,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.5112671674661627,
      "faithfulness": 0.7,
      "context_recall": 0.7777777777777778,
      "context_precision": 0.999999999977963,
      "answer_correctness": 0.47765463055064483,
      "EM": 0.0,
      "F1": 0.20178893343838877,
      "avg_retrieve_context": 0.06170790845697576,
      "avg_llm_response": 2.09810299343533,
      "avg_total": 2.159810901892305,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.8063205260975107,
      "faithfulness": 0.8619444444444445,
      "context_recall": 0.9351851851851852,
      "context_precision": 0.874228395019829,
      "answer_correctness": 0.716526709284804,
      "EM": 0.022222222222222223,
      "F1": 0.4843090365030099,
      "avg_retrieve_context": 0.06170790845697575,
      "avg_llm_response": 1.8368269443511962,
      "avg_total": 1.8985348528081722,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.3260288545942739,
      "faithfulness": 0.7916666666666666,
      "context_recall": 0.9666666666666666,
      "context_precision": 0.468333333317368,
      "answer_correctness": 0.7410750862867455,
      "EM": 0.35,
      "F1": 0.6400115635983965,
      "avg_retrieve_context": 0.06170790845697577,
      "avg_llm_response": 1.1543559074401855,
      "avg_total": 1.2160638158971615,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 10,
  "negative_rejection_percentage": 100.0
}