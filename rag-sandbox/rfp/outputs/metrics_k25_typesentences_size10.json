{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.7214986891798274,
      "faithfulness": 0.8098917748917749,
      "context_recall": 0.9522727272727273,
      "context_precision": 0.6698803244735496,
      "answer_correctness": 0.6979805639683314,
      "EM": 0.06363636363636363,
      "F1": 0.5137069125756021,
      "avg_retrieve_context": 0.0853168877688321,
      "avg_llm_response": 2.1945443803613838,
      "avg_total": 2.2798612681302166,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.7238447532422676,
      "faithfulness": 0.7741496598639457,
      "context_recall": 0.9642857142857143,
      "context_precision": 0.7117682064633185,
      "answer_correctness": 0.646657197274739,
      "EM": 0.0,
      "F1": 0.3507006063426239,
      "avg_retrieve_context": 0.08531688776883213,
      "avg_llm_response": 2.7528776214236306,
      "avg_total": 2.838194509192463,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7176711786871734,
      "faithfulness": 0.7564102564102563,
      "context_recall": 0.8846153846153846,
      "context_precision": 0.7031766096854732,
      "answer_correctness": 0.6880552156542004,
      "EM": 0.0,
      "F1": 0.49336880854549736,
      "avg_retrieve_context": 0.08531688776883214,
      "avg_llm_response": 3.084765360905574,
      "avg_total": 3.1700822486744067,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.7193629796449894,
      "faithfulness": 0.75,
      "context_recall": 1.0,
      "context_precision": 0.7486441798549963,
      "answer_correctness": 0.678585983938933,
      "EM": 0.0,
      "F1": 0.43346697912330995,
      "avg_retrieve_context": 0.08531688776883213,
      "avg_llm_response": 1.6917821963628132,
      "avg_total": 1.7770990841316454,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.7312915862074908,
      "faithfulness": 0.8404761904761904,
      "context_recall": 1.0,
      "context_precision": 0.8213596287796612,
      "answer_correctness": 0.6464365549413991,
      "EM": 0.07142857142857142,
      "F1": 0.5704512670134371,
      "avg_retrieve_context": 0.08531688776883214,
      "avg_llm_response": 1.7131851741245814,
      "avg_total": 1.7985020618934142,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.957339172666052,
      "faithfulness": 0.9166666666666666,
      "context_recall": 1.0,
      "context_precision": 0.645263670468693,
      "answer_correctness": 0.6977081038977578,
      "EM": 0.0,
      "F1": 0.45900493025493033,
      "avg_retrieve_context": 0.08531688776883212,
      "avg_llm_response": 3.3036405642827353,
      "avg_total": 3.3889574520515673,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.7591755084293293,
      "faithfulness": 0.8,
      "context_recall": 1.0,
      "context_precision": 0.65666666662025,
      "answer_correctness": 0.7020085299142893,
      "EM": 0.0,
      "F1": 0.46276546982429334,
      "avg_retrieve_context": 0.08531688776883212,
      "avg_llm_response": 2.1484509468078614,
      "avg_total": 2.2337678345766934,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.835936567815444,
      "faithfulness": 0.9375,
      "context_recall": 1.0,
      "context_precision": 0.8648974414552695,
      "answer_correctness": 0.6743977449305363,
      "EM": 0.0,
      "F1": 0.45406601609485625,
      "avg_retrieve_context": 0.08531688776883212,
      "avg_llm_response": 2.448186755180359,
      "avg_total": 2.5335036429491913,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.9762181704683203,
      "faithfulness": 1.0,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.7717963420509283,
      "answer_correctness": 0.7207183486513401,
      "EM": 0.16666666666666666,
      "F1": 0.6879421446066338,
      "avg_retrieve_context": 0.08531688776883212,
      "avg_llm_response": 1.2730191548665364,
      "avg_total": 1.3583360426353686,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9556708381901845,
      "faithfulness": 0.9444444444444443,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.5506359248066505,
      "answer_correctness": 0.7421522633464518,
      "EM": 0.0,
      "F1": 0.5808126141565629,
      "avg_retrieve_context": 0.08531688776883212,
      "avg_llm_response": 2.2824955781300864,
      "avg_total": 2.3678124658989184,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.6882390713869044,
      "faithfulness": 0.6160714285714286,
      "context_recall": 1.0,
      "context_precision": 0.8777252535235485,
      "answer_correctness": 0.6415010622171758,
      "EM": 0.0,
      "F1": 0.49980480046269515,
      "avg_retrieve_context": 0.08531688776883212,
      "avg_llm_response": 1.3444165587425232,
      "avg_total": 1.4297334465113554,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.8874139372266526,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.7592903827767694,
      "answer_correctness": 0.9576977403449471,
      "EM": 0.0,
      "F1": 0.6359591720668832,
      "avg_retrieve_context": 0.08531688776883212,
      "avg_llm_response": 2.7019545237223306,
      "avg_total": 2.787271411491163,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9212414300286861,
      "faithfulness": 0.8,
      "context_recall": 1.0,
      "context_precision": 0.6590909090744318,
      "answer_correctness": 0.6280665562722508,
      "EM": 0.0,
      "F1": 0.38288288288288286,
      "avg_retrieve_context": 0.08531688776883212,
      "avg_llm_response": 2.2247519493103027,
      "avg_total": 2.3100688370791347,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.08875325762129146,
      "faithfulness": 0.65,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8496272026958472,
      "EM": 0.5,
      "F1": 0.8555555555555555,
      "avg_retrieve_context": 0.08531688776883213,
      "avg_llm_response": 0.978580904006958,
      "avg_total": 1.06389779177579,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7233483850610936,
      "faithfulness": 0.780952380952381,
      "context_recall": 0.9625,
      "context_precision": 0.7428532203802674,
      "answer_correctness": 0.6619610420453484,
      "EM": 0.016666666666666666,
      "F1": 0.4494404788659068,
      "avg_retrieve_context": 0.08531688776883213,
      "avg_llm_response": 2.3699726422627765,
      "avg_total": 2.4552895300316093,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.8769105032475621,
      "faithfulness": 0.8932738095238095,
      "context_recall": 0.95,
      "context_precision": 0.7278910617318601,
      "answer_correctness": 0.714098187170927,
      "EM": 0.025,
      "F1": 0.5246444023951569,
      "avg_retrieve_context": 0.08531688776883212,
      "avg_llm_response": 2.2353928565979,
      "avg_total": 2.320709744366732,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.08875325762129146,
      "faithfulness": 0.65,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8496272026958472,
      "EM": 0.5,
      "F1": 0.8555555555555555,
      "avg_retrieve_context": 0.08531688776883213,
      "avg_llm_response": 0.978580904006958,
      "avg_total": 1.06389779177579,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.08875325762129146,
      "faithfulness": 0.65,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8496272026958472,
      "EM": 0.5,
      "F1": 0.8555555555555555,
      "avg_retrieve_context": 0.08531688776883213,
      "avg_llm_response": 0.978580904006958,
      "avg_total": 1.06389779177579,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.8202832695250708,
      "faithfulness": 0.8434589220303507,
      "context_recall": 0.9597069597069599,
      "context_precision": 0.7361094438951028,
      "answer_correctness": 0.6995609684901486,
      "EM": 0.02197802197802198,
      "F1": 0.5065948411697583,
      "avg_retrieve_context": 0.08531688776883214,
      "avg_llm_response": 2.276070859406021,
      "avg_total": 2.3613877471748537,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.42572730075407245,
      "faithfulness": 0.6481481481481483,
      "context_recall": 0.9351851851851851,
      "context_precision": 0.7445418108484564,
      "answer_correctness": 0.5135046529949416,
      "EM": 0.0,
      "F1": 0.20578603125696396,
      "avg_retrieve_context": 0.08531688776883212,
      "avg_llm_response": 2.7212916215260825,
      "avg_total": 2.806608509294915,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.8084103941718537,
      "faithfulness": 0.8324603174603176,
      "context_recall": 0.9564814814814816,
      "context_precision": 0.7358872486155476,
      "answer_correctness": 0.6884937608271657,
      "EM": 0.022222222222222223,
      "F1": 0.4931862473108114,
      "avg_retrieve_context": 0.08531688776883214,
      "avg_llm_response": 2.266023802757263,
      "avg_total": 2.351340690526096,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.3303960167157095,
      "faithfulness": 0.7083333333333334,
      "context_recall": 0.9333333333333332,
      "context_precision": 0.3728491658345586,
      "answer_correctness": 0.7406711781035774,
      "EM": 0.25,
      "F1": 0.6060499062671603,
      "avg_retrieve_context": 0.08531688776883213,
      "avg_llm_response": 1.8728869795799254,
      "avg_total": 1.958203867348758,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 9,
  "negative_rejection_percentage": 90.0
}