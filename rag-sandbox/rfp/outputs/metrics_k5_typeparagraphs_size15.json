{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6869638685340247,
      "faithfulness": 0.823436465495289,
      "context_recall": 0.8984848484848484,
      "context_precision": 0.738838383798718,
      "answer_correctness": 0.6532491759372128,
      "EM": 0.08181818181818182,
      "F1": 0.47338838018126955,
      "avg_retrieve_context": 0.09192884618585755,
      "avg_llm_response": 1.826933823932301,
      "avg_total": 1.9188626701181586,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.7543825882486542,
      "faithfulness": 0.8424603174603172,
      "context_recall": 0.8492063492063492,
      "context_precision": 0.9198412697818719,
      "answer_correctness": 0.6521157795270516,
      "EM": 0.0,
      "F1": 0.34237339424745655,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 1.8163690794081915,
      "avg_total": 1.9082979255940493,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.6365976087358569,
      "faithfulness": 0.832579185520362,
      "context_recall": 0.9230769230769231,
      "context_precision": 0.8354700854341167,
      "answer_correctness": 0.57448475245151,
      "EM": 0.07692307692307693,
      "F1": 0.4411867156881591,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 1.905357837677002,
      "avg_total": 1.99728668386286,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.8617295554004153,
      "faithfulness": 0.875,
      "context_recall": 0.9166666666666666,
      "context_precision": 0.8333333332936341,
      "answer_correctness": 0.7412594748266484,
      "EM": 0.0,
      "F1": 0.46418293768718705,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 1.0140274961789448,
      "avg_total": 1.105956342364803,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.6624485031837345,
      "faithfulness": 0.8303571428571429,
      "context_recall": 0.9285714285714286,
      "context_precision": 0.7230158729731218,
      "answer_correctness": 0.5408084288772387,
      "EM": 0.0,
      "F1": 0.48151445536683485,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 2.540877972330366,
      "avg_total": 2.6328068185162232,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.7918717182523897,
      "faithfulness": 0.875,
      "context_recall": 1.0,
      "context_precision": 0.7854166666269271,
      "answer_correctness": 0.7873917752199824,
      "EM": 0.0,
      "F1": 0.4984507007375279,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 2.1223687728246055,
      "avg_total": 2.214297619010463,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.5411322702300714,
      "faithfulness": 0.8,
      "context_recall": 0.8,
      "context_precision": 0.479999999962,
      "answer_correctness": 0.4544300409863019,
      "EM": 0.0,
      "F1": 0.3075750915750916,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 1.7561210632324218,
      "avg_total": 1.8480499094182796,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.7084191638868576,
      "faithfulness": 0.8184523809523809,
      "context_recall": 1.0,
      "context_precision": 0.9833333332824306,
      "answer_correctness": 0.605338714561713,
      "EM": 0.0,
      "F1": 0.4602189652446128,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 2.203066200017929,
      "avg_total": 2.2949950462037867,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.7911093333038948,
      "faithfulness": 0.611111111111111,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.6687499999527257,
      "answer_correctness": 0.7214732988368578,
      "EM": 0.0,
      "F1": 0.5453093447653852,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 1.1257123947143555,
      "avg_total": 1.217641240900213,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.8026230525040673,
      "faithfulness": 0.875,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.8106481481232098,
      "answer_correctness": 0.5286131845435846,
      "EM": 0.0,
      "F1": 0.39596454743513565,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 2.5437661012013755,
      "avg_total": 2.635694947387233,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.9506544998230775,
      "faithfulness": 0.8058823529411765,
      "context_recall": 0.75,
      "context_precision": 0.7083333333116666,
      "answer_correctness": 0.5467880084351956,
      "EM": 0.0,
      "F1": 0.3696936138796604,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 1.239359438419342,
      "avg_total": 1.3312882846051997,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.8938981438522465,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.9351851851345678,
      "answer_correctness": 0.9100604541998191,
      "EM": 0.0,
      "F1": 0.6076479724710574,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 2.737424612045288,
      "avg_total": 2.8293534582311453,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9212679297309357,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.738888888855926,
      "answer_correctness": 0.8224651247885877,
      "EM": 0.0,
      "F1": 0.3937368050668543,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 1.7692381143569946,
      "avg_total": 1.8611669605428522,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.08197009856593261,
      "faithfulness": 0.7,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8326251380009403,
      "EM": 0.8,
      "F1": 0.888888888888889,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 1.2444290161132812,
      "avg_total": 1.336357862299139,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7288806162694191,
      "faithfulness": 0.8440032679738562,
      "context_recall": 0.8972222222222223,
      "context_precision": 0.8383333332868357,
      "answer_correctness": 0.6271527475689809,
      "EM": 0.016666666666666666,
      "F1": 0.42061110350874314,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 1.8442337354024252,
      "avg_total": 1.9361625815882826,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.7753371894229562,
      "faithfulness": 0.8234453781512606,
      "context_recall": 0.9,
      "context_precision": 0.7743055555162212,
      "answer_correctness": 0.6475498279736294,
      "EM": 0.0,
      "F1": 0.44867916801315444,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 1.9466101586818696,
      "avg_total": 2.038539004867727,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.08197009856593261,
      "faithfulness": 0.7,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8326251380009403,
      "EM": 0.8,
      "F1": 0.888888888888889,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 1.2444290161132812,
      "avg_total": 1.336357862299139,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.08197009856593261,
      "faithfulness": 0.7,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8326251380009403,
      "EM": 0.8,
      "F1": 0.888888888888889,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 1.2444290161132812,
      "avg_total": 1.336357862299139,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.771799142148981,
      "faithfulness": 0.8458206359466862,
      "context_recall": 0.9212454212454213,
      "context_precision": 0.7971306470859214,
      "answer_correctness": 0.6534158704145947,
      "EM": 0.01098901098901099,
      "F1": 0.4522451615425738,
      "avg_retrieve_context": 0.09192884618585756,
      "avg_llm_response": 1.885087476981865,
      "avg_total": 1.977016323167723,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.5014002908362352,
      "faithfulness": 0.7342592592592592,
      "context_recall": 0.6666666666666665,
      "context_precision": 0.970370370337793,
      "answer_correctness": 0.45225708503954287,
      "EM": 0.0,
      "F1": 0.22550258118628255,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 1.8861633406745062,
      "avg_total": 1.978092186860364,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7571457606172252,
      "faithfulness": 0.847163087457205,
      "context_recall": 0.8981481481481483,
      "context_precision": 0.7974074073645356,
      "answer_correctness": 0.6398454529681293,
      "EM": 0.011111111111111112,
      "F1": 0.4406146881512532,
      "avg_retrieve_context": 0.09192884618585757,
      "avg_llm_response": 1.9698340574900308,
      "avg_total": 2.0617629036758887,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.3711453541596229,
      "faithfulness": 0.7166666666666666,
      "context_recall": 0.9,
      "context_precision": 0.4752777777525393,
      "answer_correctness": 0.7135659292980884,
      "EM": 0.4,
      "F1": 0.6208699943163433,
      "avg_retrieve_context": 0.0919288461858576,
      "avg_llm_response": 1.1838827729225159,
      "avg_total": 1.2758116191083737,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 9,
  "negative_rejection_percentage": 90.0
}