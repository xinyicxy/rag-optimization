{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.5634361630984579,
      "faithfulness": 0.7486083524318817,
      "context_recall": 0.6431818181818182,
      "context_precision": 0.6727272726704545,
      "answer_correctness": 0.5631512354393744,
      "EM": 0.07272727272727272,
      "F1": 0.3839024406145843,
      "avg_retrieve_context": 0.06441253748807038,
      "avg_llm_response": 0.9745722445574674,
      "avg_total": 1.0389847820455378,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.629799121071216,
      "faithfulness": 0.7722222222222224,
      "context_recall": 0.492063492063492,
      "context_precision": 0.78571428565,
      "answer_correctness": 0.5081517218901094,
      "EM": 0.0,
      "F1": 0.28674926804495565,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 0.9182835987636021,
      "avg_total": 0.9826961362516726,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.5020199433910738,
      "faithfulness": 0.6666666666666666,
      "context_recall": 0.6538461538461539,
      "context_precision": 0.9999999999115385,
      "answer_correctness": 0.5202391988074221,
      "EM": 0.07692307692307693,
      "F1": 0.410799122688653,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 1.2421331038841834,
      "avg_total": 1.306545641372254,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.6295747834491324,
      "faithfulness": 0.8541666666666666,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.8749999999208334,
      "answer_correctness": 0.5842850404726486,
      "EM": 0.0,
      "F1": 0.348549744190603,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 0.6376209060351054,
      "avg_total": 0.702033443523176,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.45952396351576913,
      "faithfulness": 0.5807322929171669,
      "context_recall": 0.6607142857142857,
      "context_precision": 0.5357142856642857,
      "answer_correctness": 0.49867360214519285,
      "EM": 0.0,
      "F1": 0.34090584324812834,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 1.0245631081717355,
      "avg_total": 1.088975645659806,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.6251364004954544,
      "faithfulness": 0.6527777777777778,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.7499999999416667,
      "answer_correctness": 0.574268743676622,
      "EM": 0.0,
      "F1": 0.3430559320502395,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 0.4684826930363973,
      "avg_total": 0.5328952305244677,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.7733883249485005,
      "faithfulness": 0.7333333333333333,
      "context_recall": 0.6,
      "context_precision": 0.59999999994,
      "answer_correctness": 0.6035748203273928,
      "EM": 0.0,
      "F1": 0.4538407329105004,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 1.136043405532837,
      "avg_total": 1.2004559430209074,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.7158347044214952,
      "faithfulness": 0.875,
      "context_recall": 0.875,
      "context_precision": 0.8749999999375,
      "answer_correctness": 0.5800451777316813,
      "EM": 0.0,
      "F1": 0.3356870261521424,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 1.054938942193985,
      "avg_total": 1.1193514796820554,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.0,
      "faithfulness": 0.6666666666666666,
      "context_recall": 0.0,
      "context_precision": 0.0,
      "answer_correctness": 0.1804349174739721,
      "EM": 0.0,
      "F1": 0.02666666666666667,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 0.4213157892227173,
      "avg_total": 0.4857283267107877,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9479803027267967,
      "faithfulness": 1.0,
      "context_recall": 0.611111111111111,
      "context_precision": 0.49999999995833333,
      "answer_correctness": 0.6259489320910719,
      "EM": 0.0,
      "F1": 0.40738500114686077,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 1.5554515520731609,
      "avg_total": 1.6198640895612313,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.914393636138602,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.999999999925,
      "answer_correctness": 0.8963038941665926,
      "EM": 0.25,
      "F1": 0.59747920997921,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 0.7322570085525513,
      "avg_total": 0.7966695460406217,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.6103497322962542,
      "faithfulness": 0.8333333333333334,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.9999999999166667,
      "answer_correctness": 0.6658640875080057,
      "EM": 0.0,
      "F1": 0.4175878162613609,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 1.631325085957845,
      "avg_total": 1.6957376234459154,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9491214410157743,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.999999999925,
      "answer_correctness": 0.7334251947488967,
      "EM": 0.0,
      "F1": 0.40254872563718147,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 0.5239666700363159,
      "avg_total": 0.5883792075243863,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.1818518140717818,
      "faithfulness": 0.6,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7527679926809323,
      "EM": 0.6,
      "F1": 0.7846743295019157,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 1.2113761186599732,
      "avg_total": 1.2757886561480436,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.5623378949531642,
      "faithfulness": 0.7210597572362277,
      "context_recall": 0.6013888888888889,
      "context_precision": 0.7916666665975,
      "answer_correctness": 0.5237857776648878,
      "EM": 0.016666666666666666,
      "F1": 0.33862336599429316,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 0.9571170051892598,
      "avg_total": 1.0215295426773303,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.6604796525730673,
      "faithfulness": 0.8270833333333332,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.6624999999475001,
      "answer_correctness": 0.5747952327907148,
      "EM": 0.025,
      "F1": 0.3516280803231882,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 0.9415541350841522,
      "avg_total": 1.0059666725722227,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.1818518140717818,
      "faithfulness": 0.6,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7527679926809323,
      "EM": 0.6,
      "F1": 0.7846743295019157,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 1.2113761186599732,
      "avg_total": 1.2757886561480436,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.1818518140717818,
      "faithfulness": 0.6,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7527679926809323,
      "EM": 0.6,
      "F1": 0.7846743295019157,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 1.2113761186599732,
      "avg_total": 1.2757886561480436,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.6196953351596027,
      "faithfulness": 0.7757903161264507,
      "context_recall": 0.6529304029304029,
      "context_precision": 0.7362637362000001,
      "answer_correctness": 0.5584886227161396,
      "EM": 0.02197802197802198,
      "F1": 0.35997180778724663,
      "avg_retrieve_context": 0.06441253748807038,
      "avg_llm_response": 0.9564691899896978,
      "avg_total": 1.0208817274777682,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.41857603339874366,
      "faithfulness": 0.6388888888888888,
      "context_recall": 0.37037037037037035,
      "context_precision": 0.7777777777277778,
      "answer_correctness": 0.39961014492812774,
      "EM": 0.0,
      "F1": 0.1805656293272971,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 0.8944988250732422,
      "avg_total": 0.9589113625613126,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.5937566988146549,
      "faithfulness": 0.7640398381574853,
      "context_recall": 0.6305555555555555,
      "context_precision": 0.7333333332722223,
      "answer_correctness": 0.5460632971812742,
      "EM": 0.022222222222222223,
      "F1": 0.3486136839929762,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 0.9715139892366197,
      "avg_total": 1.0359265267246902,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.4269937523755708,
      "faithfulness": 0.6791666666666666,
      "context_recall": 0.7,
      "context_precision": 0.3999999999625,
      "answer_correctness": 0.640046957600825,
      "EM": 0.3,
      "F1": 0.542701845411821,
      "avg_retrieve_context": 0.0644125374880704,
      "avg_llm_response": 0.9883343935012817,
      "avg_total": 1.0527469309893522,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 8,
  "negative_rejection_percentage": 80.0
}