{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.7396582732346139,
      "faithfulness": 0.8048383838383838,
      "context_recall": 0.8844696969696969,
      "context_precision": 0.7312247474329493,
      "answer_correctness": 0.6936910506094095,
      "EM": 0.07272727272727272,
      "F1": 0.49360641239998027,
      "avg_retrieve_context": 0.047367926077409216,
      "avg_llm_response": 1.183629729531028,
      "avg_total": 1.2309976556084379,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.7168801870251122,
      "faithfulness": 0.8518518518518519,
      "context_recall": 0.8690476190476191,
      "context_precision": 0.9065476189920652,
      "answer_correctness": 0.593304136720507,
      "EM": 0.0,
      "F1": 0.29055814189437124,
      "avg_retrieve_context": 0.04736792607740923,
      "avg_llm_response": 1.1961325463794528,
      "avg_total": 1.2435004724568621,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.7897582566625688,
      "faithfulness": 0.8366666666666667,
      "context_recall": 0.9230769230769231,
      "context_precision": 0.7654914529588986,
      "answer_correctness": 0.6346599991968438,
      "EM": 0.07692307692307693,
      "F1": 0.5239690654080463,
      "avg_retrieve_context": 0.047367926077409236,
      "avg_llm_response": 1.4205627258007343,
      "avg_total": 1.4679306518781439,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.8086744796945687,
      "faithfulness": 0.8888888888888888,
      "context_recall": 1.0,
      "context_precision": 0.7805555555073959,
      "answer_correctness": 0.6674294720815145,
      "EM": 0.0,
      "F1": 0.3939630851451257,
      "avg_retrieve_context": 0.04736792607740923,
      "avg_llm_response": 0.8528482913970947,
      "avg_total": 0.9002162174745042,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.5299503706218625,
      "faithfulness": 0.6547619047619048,
      "context_recall": 0.7886904761904762,
      "context_precision": 0.7325396824974667,
      "answer_correctness": 0.544620353927452,
      "EM": 0.0,
      "F1": 0.400394365505557,
      "avg_retrieve_context": 0.047367926077409236,
      "avg_llm_response": 1.5771092346736364,
      "avg_total": 1.6244771607510455,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.9660421508117754,
      "faithfulness": 0.75,
      "context_recall": 1.0,
      "context_precision": 0.8064814814471912,
      "answer_correctness": 0.9497347461016488,
      "EM": 0.0,
      "F1": 0.5392121495062672,
      "avg_retrieve_context": 0.04736792607740922,
      "avg_llm_response": 0.6511298815409342,
      "avg_total": 0.6984978076183435,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.9287871423695944,
      "faithfulness": 0.74,
      "context_recall": 1.0,
      "context_precision": 0.8666666665883334,
      "answer_correctness": 0.790045844229289,
      "EM": 0.0,
      "F1": 0.5564466292445831,
      "avg_retrieve_context": 0.04736792607740922,
      "avg_llm_response": 1.2104959964752198,
      "avg_total": 1.257863922552629,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.9566655145724119,
      "faithfulness": 0.925,
      "context_recall": 1.0,
      "context_precision": 0.9041666666125173,
      "answer_correctness": 0.7553437465604622,
      "EM": 0.0,
      "F1": 0.553113325356325,
      "avg_retrieve_context": 0.04736792607740922,
      "avg_llm_response": 1.0744667947292328,
      "avg_total": 1.1218347208066421,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.980447998129217,
      "faithfulness": 0.75,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.7083333332875,
      "answer_correctness": 0.6860884979080607,
      "EM": 0.0,
      "F1": 0.6307062976043797,
      "avg_retrieve_context": 0.04736792607740922,
      "avg_llm_response": 0.5397325356801351,
      "avg_total": 0.5871004617575443,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9498817241893991,
      "faithfulness": 0.9444444444444445,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.6835648147913522,
      "answer_correctness": 0.6115279304810811,
      "EM": 0.0,
      "F1": 0.48497071423058724,
      "avg_retrieve_context": 0.04736792607740922,
      "avg_llm_response": 1.636514663696289,
      "avg_total": 1.6838825897736986,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.9492010995850617,
      "faithfulness": 0.7916666666666666,
      "context_recall": 1.0,
      "context_precision": 0.7999999999578125,
      "answer_correctness": 0.8237164939240713,
      "EM": 0.0,
      "F1": 0.5964428525404135,
      "avg_retrieve_context": 0.04736792607740922,
      "avg_llm_response": 0.7244863510131836,
      "avg_total": 0.7718542770905928,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.8862972996869654,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.8722222221670369,
      "answer_correctness": 0.9576012634688004,
      "EM": 0.0,
      "F1": 0.6568067455460357,
      "avg_retrieve_context": 0.04736792607740922,
      "avg_llm_response": 1.8661200205485027,
      "avg_total": 1.9134879466259116,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.9425532759845905,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.6249999999708333,
      "answer_correctness": 0.884671571942537,
      "EM": 0.0,
      "F1": 0.3514705882352941,
      "avg_retrieve_context": 0.04736792607740922,
      "avg_llm_response": 3.2197329998016357,
      "avg_total": 3.2671009258790447,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.09013759300459384,
      "faithfulness": 0.6,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.8548110935820276,
      "EM": 0.7,
      "F1": 0.8854700854700855,
      "avg_retrieve_context": 0.04736792607740923,
      "avg_llm_response": 0.7751214265823364,
      "avg_total": 0.8224893526597457,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.7074123368196942,
      "faithfulness": 0.8099814814814814,
      "context_recall": 0.8881944444444445,
      "context_precision": 0.8101851851392057,
      "answer_correctness": 0.6057300913442021,
      "EM": 0.016666666666666666,
      "F1": 0.3874399494817618,
      "avg_retrieve_context": 0.04736792607740923,
      "avg_llm_response": 1.2649967948595682,
      "avg_total": 1.3123647209369778,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.9504073479144985,
      "faithfulness": 0.8483333333333333,
      "context_recall": 0.9,
      "context_precision": 0.7955902777318024,
      "answer_correctness": 0.7853524787640661,
      "EM": 0.0,
      "F1": 0.5548901885097818,
      "avg_retrieve_context": 0.04736792607740922,
      "avg_llm_response": 1.1637062072753905,
      "avg_total": 1.2110741333527997,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.09013759300459384,
      "faithfulness": 0.6,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.8548110935820276,
      "EM": 0.7,
      "F1": 0.8854700854700855,
      "avg_retrieve_context": 0.04736792607740923,
      "avg_llm_response": 0.7751214265823364,
      "avg_total": 0.8224893526597457,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.09013759300459384,
      "faithfulness": 0.6,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.8548110935820276,
      "EM": 0.7,
      "F1": 0.8854700854700855,
      "avg_retrieve_context": 0.04736792607740923,
      "avg_llm_response": 0.7751214265823364,
      "avg_total": 0.8224893526597457,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.8339297533993867,
      "faithfulness": 0.8312454212454213,
      "context_recall": 0.9107142857142857,
      "context_precision": 0.7886141635668066,
      "answer_correctness": 0.6999997937961757,
      "EM": 0.01098901098901099,
      "F1": 0.48188911992191247,
      "avg_retrieve_context": 0.04736792607740922,
      "avg_llm_response": 1.2287075309963016,
      "avg_total": 1.2760754570737112,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.5081585073797101,
      "faithfulness": 0.7654320987654322,
      "context_recall": 0.7129629629629629,
      "context_precision": 0.9634259258938928,
      "answer_correctness": 0.4508803773069747,
      "EM": 0.0,
      "F1": 0.17667717737810362,
      "avg_retrieve_context": 0.04736792607740922,
      "avg_llm_response": 1.1817411846584744,
      "avg_total": 1.2291091107358838,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.8303346854488594,
      "faithfulness": 0.8281358024691359,
      "context_recall": 0.8921296296296297,
      "context_precision": 0.8055709876079212,
      "answer_correctness": 0.6966021738904735,
      "EM": 0.011111111111111112,
      "F1": 0.4710761887589827,
      "avg_retrieve_context": 0.04736792607740922,
      "avg_llm_response": 1.2882545974519517,
      "avg_total": 1.3356225235293613,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.33161441827050936,
      "faithfulness": 0.7,
      "context_recall": 0.85,
      "context_precision": 0.39666666664557637,
      "answer_correctness": 0.680590995844621,
      "EM": 0.35,
      "F1": 0.594992418784469,
      "avg_retrieve_context": 0.04736792607740923,
      "avg_llm_response": 0.7128178238868713,
      "avg_total": 0.7601857499642808,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 9,
  "negative_rejection_percentage": 90.0
}