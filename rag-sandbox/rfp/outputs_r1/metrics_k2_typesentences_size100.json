{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6364091550926754,
      "faithfulness": 0.8188528138528139,
      "context_recall": 0.8772727272727273,
      "context_precision": 0.7727272726740908,
      "answer_correctness": 0.6631893433747234,
      "EM": 0.09090909090909091,
      "F1": 0.449896133592899,
      "avg_retrieve_context": 0.0681144107471813,
      "avg_llm_response": 1.42392024343664,
      "avg_total": 1.4920346541838208,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.6713442138377869,
      "faithfulness": 0.8253968253968255,
      "context_recall": 0.8095238095238095,
      "context_precision": 0.8571428570833332,
      "answer_correctness": 0.5940592828489654,
      "EM": 0.0,
      "F1": 0.29279810204850604,
      "avg_retrieve_context": 0.06811441074718132,
      "avg_llm_response": 2.092572041920253,
      "avg_total": 2.160686452667434,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.6522775183193747,
      "faithfulness": 0.8461538461538461,
      "context_recall": 1.0,
      "context_precision": 0.9999999999346153,
      "answer_correctness": 0.6234199421701772,
      "EM": 0.07692307692307693,
      "F1": 0.46920372754279244,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 1.7551003052638128,
      "avg_total": 1.8232147160109942,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.8678307124018986,
      "faithfulness": 0.9166666666666666,
      "context_recall": 0.9166666666666666,
      "context_precision": 0.9583333332749998,
      "answer_correctness": 0.7836276114447059,
      "EM": 0.0,
      "F1": 0.4661818968450833,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 0.8040758172671,
      "avg_total": 0.8721902280142815,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.6577770861863245,
      "faithfulness": 0.755952380952381,
      "context_recall": 0.8214285714285714,
      "context_precision": 0.7857142856535713,
      "answer_correctness": 0.627855558575553,
      "EM": 0.14285714285714285,
      "F1": 0.503824365959395,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 1.5112099647521973,
      "avg_total": 1.5793243754993787,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.9480326595828474,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.9166666666,
      "answer_correctness": 0.8087063622693392,
      "EM": 0.16666666666666666,
      "F1": 0.5196000144665014,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 1.0543187061945598,
      "avg_total": 1.1224331169417412,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.5599923335923279,
      "faithfulness": 0.6599999999999999,
      "context_recall": 0.8,
      "context_precision": 0.69999999994,
      "answer_correctness": 0.49042896761981486,
      "EM": 0.0,
      "F1": 0.31592291766204805,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 1.2607152938842774,
      "avg_total": 1.3288297046314586,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.5791887363489923,
      "faithfulness": 0.7946428571428572,
      "context_recall": 0.875,
      "context_precision": 0.81249999994375,
      "answer_correctness": 0.6318673600554807,
      "EM": 0.0,
      "F1": 0.3996885363958535,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 1.1016579270362854,
      "avg_total": 1.1697723377834668,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.4765121702329341,
      "faithfulness": 0.75,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.49999999995833333,
      "answer_correctness": 0.5153520997157659,
      "EM": 0.0,
      "F1": 0.3282971014492753,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 0.7621838649113973,
      "avg_total": 0.8302982756585786,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.7728958914150447,
      "faithfulness": 0.9166666666666666,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.8333333332833334,
      "answer_correctness": 0.5519991513997837,
      "EM": 0.0,
      "F1": 0.367552909348575,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 1.930187424023946,
      "avg_total": 1.9983018347711274,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.6816786727229982,
      "faithfulness": 0.875,
      "context_recall": 1.0,
      "context_precision": 0.9999999999375,
      "answer_correctness": 0.726946961016536,
      "EM": 0.0,
      "F1": 0.33730158730158727,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 0.8714074492454529,
      "avg_total": 0.9395218599926342,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.8943602155096707,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.8333333332833334,
      "answer_correctness": 0.9945388167876114,
      "EM": 0.0,
      "F1": 0.6771544183810914,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 2.2819769382476807,
      "avg_total": 2.3500913489948623,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.42690222274666967,
      "faithfulness": 0.75,
      "context_recall": 1.0,
      "context_precision": 0.74999999995,
      "answer_correctness": 0.48892441264254805,
      "EM": 0.0,
      "F1": 0.23764145324597977,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 1.2717616558074951,
      "avg_total": 1.3398760665546765,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.09226074069646865,
      "faithfulness": 0.65,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8544931907218464,
      "EM": 0.6,
      "F1": 0.8666666666666666,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 0.8592996835708618,
      "avg_total": 0.9274140943180431,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.703344733069612,
      "faithfulness": 0.8319444444444444,
      "context_recall": 0.875,
      "context_precision": 0.8916666666058332,
      "answer_correctness": 0.6462202224239131,
      "EM": 0.05,
      "F1": 0.4149355414441243,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 1.6261027693748473,
      "avg_total": 1.6942171801220292,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.672042891726322,
      "faithfulness": 0.8414285714285714,
      "context_recall": 0.875,
      "context_precision": 0.787499999945,
      "answer_correctness": 0.6408170629641583,
      "EM": 0.025,
      "F1": 0.398144388547619,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 1.2618015944957732,
      "avg_total": 1.3299160052429546,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.09226074069646865,
      "faithfulness": 0.65,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8544931907218464,
      "EM": 0.6,
      "F1": 0.8666666666666666,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 0.8592996835708618,
      "avg_total": 0.9274140943180431,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.09226074069646865,
      "faithfulness": 0.65,
      "context_recall": 0.9,
      "context_precision": 0.0,
      "answer_correctness": 0.8544931907218464,
      "EM": 0.6,
      "F1": 0.8666666666666666,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 0.8592996835708618,
      "avg_total": 0.9274140943180431,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.7191014289533912,
      "faithfulness": 0.8487964416535845,
      "context_recall": 0.8882783882783883,
      "context_precision": 0.8406593406000001,
      "answer_correctness": 0.6624332658962893,
      "EM": 0.04395604395604396,
      "F1": 0.4285367437827169,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 1.4384051600655356,
      "avg_total": 1.5065195708127166,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.40490773538566566,
      "faithfulness": 0.7037037037037037,
      "context_recall": 0.7407407407407407,
      "context_precision": 0.9444444443944443,
      "answer_correctness": 0.45827429638208744,
      "EM": 0.0,
      "F1": 0.20278492714721957,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 1.904817819595337,
      "avg_total": 1.9729322303425185,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.694281980206927,
      "faithfulness": 0.8397089947089946,
      "context_recall": 0.8722222222222222,
      "context_precision": 0.8499999999405556,
      "answer_correctness": 0.6560900097381563,
      "EM": 0.044444444444444446,
      "F1": 0.4161991076356611,
      "avg_retrieve_context": 0.06811441074718129,
      "avg_llm_response": 1.510656115743849,
      "avg_total": 1.5787705264910301,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.37598144207854245,
      "faithfulness": 0.725,
      "context_recall": 0.9,
      "context_precision": 0.424999999975,
      "answer_correctness": 0.6951363447392755,
      "EM": 0.3,
      "F1": 0.6015327504004692,
      "avg_retrieve_context": 0.0681144107471813,
      "avg_llm_response": 1.0336088180541991,
      "avg_total": 1.1017232288013805,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 9,
  "negative_rejection_percentage": 90.0
}