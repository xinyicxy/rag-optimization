{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.6322991723296321,
      "faithfulness": 0.7886583366128821,
      "context_recall": 0.7367424242424243,
      "context_precision": 0.7318181817627272,
      "answer_correctness": 0.600768510357879,
      "EM": 0.045454545454545456,
      "F1": 0.4273953494778803,
      "avg_retrieve_context": 0.06348946528001263,
      "avg_llm_response": 1.0644382195039228,
      "avg_total": 1.1279276847839355,
      "sample_size": 110
    }
  },
  "RFP_id": {
    "infra_1": {
      "answer_relevancy": 0.7193216912540855,
      "faithfulness": 0.8578231292517006,
      "context_recall": 0.6587301587301587,
      "context_precision": 0.9047619046952379,
      "answer_correctness": 0.5253578488988604,
      "EM": 0.0,
      "F1": 0.28012447043791316,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 1.1851903370448522,
      "avg_total": 1.2486798023248649,
      "sample_size": 21
    },
    "infra_2": {
      "answer_relevancy": 0.5723227699100627,
      "faithfulness": 0.782051282051282,
      "context_recall": 0.6538461538461539,
      "context_precision": 0.769230769173077,
      "answer_correctness": 0.56799167117312,
      "EM": 0.0,
      "F1": 0.387957930206214,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 1.41700685941256,
      "avg_total": 1.4804963246925726,
      "sample_size": 13
    },
    "infra_3": {
      "answer_relevancy": 0.5543610493073289,
      "faithfulness": 0.7333333333333334,
      "context_recall": 0.75,
      "context_precision": 0.7499999999416666,
      "answer_correctness": 0.5233327610182315,
      "EM": 0.0,
      "F1": 0.38152802398193003,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 0.6014308532079061,
      "avg_total": 0.6649203184879187,
      "sample_size": 12
    },
    "infra_4": {
      "answer_relevancy": 0.3924583965443961,
      "faithfulness": 0.6106601731601733,
      "context_recall": 0.6220238095238094,
      "context_precision": 0.78571428565,
      "answer_correctness": 0.4043402265070193,
      "EM": 0.0,
      "F1": 0.3364725624223208,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 0.9758702516555786,
      "avg_total": 1.039359716935591,
      "sample_size": 14
    },
    "natsec_1": {
      "answer_relevancy": 0.7860536917289541,
      "faithfulness": 0.7083333333333334,
      "context_recall": 0.8333333333333334,
      "context_precision": 0.833333333275,
      "answer_correctness": 0.7909101290731497,
      "EM": 0.0,
      "F1": 0.4603095484726538,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 0.6087982257207235,
      "avg_total": 0.672287691000736,
      "sample_size": 6
    },
    "natsec_2": {
      "answer_relevancy": 0.7481143977561977,
      "faithfulness": 0.9,
      "context_recall": 1.0,
      "context_precision": 0.89999999991,
      "answer_correctness": 0.6273931118238928,
      "EM": 0.0,
      "F1": 0.4583960813311254,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 1.155409574508667,
      "avg_total": 1.2188990397886796,
      "sample_size": 5
    },
    "natsec_3": {
      "answer_relevancy": 0.8349148629956196,
      "faithfulness": 0.9375,
      "context_recall": 1.0,
      "context_precision": 0.9374999999375,
      "answer_correctness": 0.763302518466217,
      "EM": 0.0,
      "F1": 0.48458624706173936,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 0.8560836911201477,
      "avg_total": 0.9195731564001602,
      "sample_size": 8
    },
    "natsec_4": {
      "answer_relevancy": 0.9647434365728947,
      "faithfulness": 0.763888888888889,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.6666666666166666,
      "answer_correctness": 0.6507803779954645,
      "EM": 0.0,
      "F1": 0.6013956424608783,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 0.526711622873942,
      "avg_total": 0.5902010881539547,
      "sample_size": 6
    },
    "natsec_5": {
      "answer_relevancy": 0.9526397453575619,
      "faithfulness": 0.9166666666666666,
      "context_recall": 0.6666666666666666,
      "context_precision": 0.5833333332916667,
      "answer_correctness": 0.6019630162360784,
      "EM": 0.0,
      "F1": 0.4925108862845165,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 1.641402045885722,
      "avg_total": 1.7048915111657343,
      "sample_size": 6
    },
    "natsec_6": {
      "answer_relevancy": 0.7146772030157968,
      "faithfulness": 0.875,
      "context_recall": 0.75,
      "context_precision": 0.74999999995,
      "answer_correctness": 0.7164317573309733,
      "EM": 0.0,
      "F1": 0.35308692489543547,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 0.6447058916091919,
      "avg_total": 0.7081953568892045,
      "sample_size": 4
    },
    "natsec_7": {
      "answer_relevancy": 0.877098235128141,
      "faithfulness": 0.9629629629629629,
      "context_recall": 1.0,
      "context_precision": 0.9999999999166667,
      "answer_correctness": 0.9553986037644898,
      "EM": 0.0,
      "F1": 0.554589651952735,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 2.263059695561727,
      "avg_total": 2.3265491608417395,
      "sample_size": 3
    },
    "natsec_8": {
      "answer_relevancy": 0.4553829110147049,
      "faithfulness": 0.75,
      "context_recall": 0.5,
      "context_precision": 0.499999999975,
      "answer_correctness": 0.5194161881072987,
      "EM": 0.0,
      "F1": 0.2463768115942029,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 0.8436449766159058,
      "avg_total": 0.9071344418959184,
      "sample_size": 2
    },
    "negative_rejection": {
      "answer_relevancy": 0.18189258136039857,
      "faithfulness": 0.7,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7451311220413706,
      "EM": 0.5,
      "F1": 0.7735632183908046,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 1.255628275871277,
      "avg_total": 1.3191177411512893,
      "sample_size": 10
    }
  },
  "RFP_type": {
    "infra": {
      "answer_relevancy": 0.5782116944746016,
      "faithfulness": 0.7588365800865802,
      "context_recall": 0.6673611111111111,
      "context_precision": 0.8166666666041666,
      "answer_correctness": 0.5059527142573945,
      "EM": 0.0,
      "F1": 0.33691698555954347,
      "avg_retrieve_context": 0.06348946528001263,
      "avg_llm_response": 1.0698240001996357,
      "avg_total": 1.1333134654796484,
      "sample_size": 60
    },
    "natsec": {
      "answer_relevancy": 0.8260320368544857,
      "faithfulness": 0.8555555555555555,
      "context_recall": 0.825,
      "context_precision": 0.78749999994125,
      "answer_correctness": 0.7069015515877328,
      "EM": 0.0,
      "F1": 0.4765709281271547,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 1.008562034368515,
      "avg_total": 1.0720514996485275,
      "sample_size": 40
    },
    "negative_rejection": {
      "answer_relevancy": 0.18189258136039857,
      "faithfulness": 0.7,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7451311220413706,
      "EM": 0.5,
      "F1": 0.7735632183908046,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 1.255628275871277,
      "avg_total": 1.3191177411512893,
      "sample_size": 10
    }
  },
  "chunks_length": {
    "0": {
      "answer_relevancy": 0.18189258136039857,
      "faithfulness": 0.7,
      "context_recall": 0.8,
      "context_precision": 0.0,
      "answer_correctness": 0.7451311220413706,
      "EM": 0.5,
      "F1": 0.7735632183908046,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 1.255628275871277,
      "avg_total": 1.3191177411512893,
      "sample_size": 10
    },
    "1": {
      "answer_relevancy": 0.6937229479148145,
      "faithfulness": 0.8026168276168276,
      "context_recall": 0.7586996336996338,
      "context_precision": 0.7857142856527474,
      "answer_correctness": 0.6072104292934275,
      "EM": 0.0,
      "F1": 0.4131955700885677,
      "avg_retrieve_context": 0.06348946528001263,
      "avg_llm_response": 1.0432673967801607,
      "avg_total": 1.1067568620601733,
      "sample_size": 91
    },
    "2": {
      "answer_relevancy": 0.5116883202674906,
      "faithfulness": 0.746031746031746,
      "context_recall": 0.4444444444444444,
      "context_precision": 0.9999999999444444,
      "answer_correctness": 0.3752306503612316,
      "EM": 0.0,
      "F1": 0.18633993117768102,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 1.0660653644137912,
      "avg_total": 1.1295548296938036,
      "sample_size": 9
    }
  },
  "manually_edited": {
    "false": {
      "answer_relevancy": 0.7108056495851055,
      "faithfulness": 0.8028046336379671,
      "context_recall": 0.7412037037037038,
      "context_precision": 0.811111111048889,
      "answer_correctness": 0.6087969418784974,
      "EM": 0.0,
      "F1": 0.4092716492170824,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 1.0802421119478014,
      "avg_total": 1.143731577227814,
      "sample_size": 90
    },
    "true": {
      "answer_relevancy": 0.27902002468000114,
      "faithfulness": 0.725,
      "context_recall": 0.7166666666666666,
      "context_precision": 0.374999999975,
      "answer_correctness": 0.5646405685150963,
      "EM": 0.25,
      "F1": 0.508952000651471,
      "avg_retrieve_context": 0.06348946528001265,
      "avg_llm_response": 0.9933207035064697,
      "avg_total": 1.0568101687864826,
      "sample_size": 20
    }
  },
  "total_negative_questions": 10,
  "total_negative_rejections": 8,
  "negative_rejection_percentage": 80.0
}