{
  "full_dataset": {
    "full_dataset": {
      "answer_relevancy": 0.7024152488976001,
      "faithfulness": 0.6236111111111111,
      "context_recall": 0.475,
      "context_precision": 0.36694775129097024,
      "answer_correctness": 0.7431208111403513,
      "EM": 0.6166666666666667,
      "F1": 0.6614252543122511,
      "avg_retrieve_context": 0.057182039817174284,
      "avg_llm_response": 0.989611957470576,
      "avg_total": 1.0467939972877502,
      "sample_size": 120
    }
  },
  "answer_type": {
    "date": {
      "answer_relevancy": 0.6807138807857316,
      "faithfulness": 0.703125,
      "context_recall": 0.40625,
      "context_precision": 0.3890997023425502,
      "answer_correctness": 0.7941878160838691,
      "EM": 0.625,
      "F1": 0.625,
      "avg_retrieve_context": 0.05718203981717428,
      "avg_llm_response": 0.9030218943953514,
      "avg_total": 0.9602039342125257,
      "sample_size": 32
    },
    "organization": {
      "answer_relevancy": 0.0,
      "faithfulness": 1.0,
      "context_recall": 0.0,
      "context_precision": 0.0,
      "answer_correctness": 0.1934697312196276,
      "EM": 0.0,
      "F1": 0.10939112487100104,
      "avg_retrieve_context": 0.05718203981717427,
      "avg_llm_response": 1.0204227765401204,
      "avg_total": 1.0776048163572947,
      "sample_size": 3
    },
    "person": {
      "answer_relevancy": 0.7164976873236651,
      "faithfulness": 0.5698924731182795,
      "context_recall": 0.5483870967741935,
      "context_precision": 0.37265745004755085,
      "answer_correctness": 0.7721481851094586,
      "EM": 0.6612903225806451,
      "F1": 0.7426267281105992,
      "avg_retrieve_context": 0.05718203981717426,
      "avg_llm_response": 0.9772732296297627,
      "avg_total": 1.0344552694469367,
      "sample_size": 62
    },
    "place": {
      "answer_relevancy": 0.7589884424812192,
      "faithfulness": 1.0,
      "context_recall": 1.0,
      "context_precision": 0.72499999993875,
      "answer_correctness": 0.8673731044664574,
      "EM": 0.5,
      "F1": 0.5,
      "avg_retrieve_context": 0.05718203981717428,
      "avg_llm_response": 2.044204592704773,
      "avg_total": 2.101386632521947,
      "sample_size": 2
    },
    "year": {
      "answer_relevancy": 0.7888643896923294,
      "faithfulness": 0.5714285714285714,
      "context_recall": 0.38095238095238093,
      "context_precision": 0.33465608462519836,
      "answer_correctness": 0.6462925877514346,
      "EM": 0.5714285714285714,
      "F1": 0.5714285714285714,
      "avg_retrieve_context": 0.05718203981717428,
      "avg_llm_response": 1.0531484058925085,
      "avg_total": 1.1103304457096825,
      "sample_size": 21
    }
  }
}