"""
This script processes QnA pairs generated by a language model from chunks of PDF text

It:

Loads the LLM output and corresponding text chunks,

Extracts structured QnA pairs including associated text snippets,

Creates context out of text snippets

Saves the enriched QnA data with contextual segmentation into a JSON file.
"""

import json
import re
import os


def load_files(base_name, infra_or_natsec="infra"):
    """
    Loads the generated LLM output and corresponding chunked text data from files

    Args:
    base_name (str): Base name of the files to load (i.e. "infra-1")
    infra_or_natsec (str): Folder name under 'data/', either "infra" or "natsec"

    Returns:
    tuple: A tuple containing:
        - output_data (list of str): Lines of raw LLM output text
        - chunks_data (list of dict): JSON list of chunked document segments

    """
    output_file = f"data/{infra_or_natsec}/{base_name}-output.txt"
    chunks_file = f"data/{infra_or_natsec}/{base_name}-chunks.json"

    with open(output_file, 'r', encoding='utf-8') as f:
        output_data = f.readlines()

    with open(chunks_file, 'r', encoding='utf-8') as f:
        chunks_data = json.load(f)

    return output_data, chunks_data


def extract_qna(output_data):
    """
    Parses LLM output lines to extract structured question-answer pairs with text snippets

    Args:
    output_data (list of str): Lines from the output file generated by the language model

    Returns:
    list of dict: A list of QnA dictionaries, each containing:
        - chunk (int): The chunk number.
        - question (str): The extracted question text.
        - answer (str): The corresponding answer text.
        - snippet (str): A quoted text snippet from the original document.
    """
    qna_list = []
    chunk_number = None

    for line in output_data:
        chunk_match = re.match(r'=== Chunk (\d+) ===', line)
        if chunk_match:
            chunk_number = int(chunk_match.group(1))

        q_match = re.search(r'Q\d+:\s*(.+)', line)  # match on question
        a_match = re.search(r'A\d+:\s*(.+)', line)  # match on answer
        snippet_match = re.search(r'\*\*Text Snippet:\*\*\s*"(.+?)"', line)

        if q_match:
            question = q_match.group(1).strip('*').strip()
        elif a_match:
            answer = a_match.group(1).strip('*').strip()
        elif snippet_match:
            snippet = snippet_match.group(1).strip('*').strip()
            qna_list.append({
                "chunk": chunk_number,
                "question": question,
                "answer": answer,
                "snippet": snippet
            })
            # reset question and answer after storing
            question = None
            answer = None

    return qna_list


def segment_snippet(snippet):
    """
    Segments the snippet into a list of parts by splitting on '...' or '[...]',
    removing the ellipses from the output.
    Args:
    snippet (str): A text snippet extracted from the original document

    Returns:
    list of str: A list of non-empty, trimmed text segments
    """
    # Split the snippet on '...' or '[...]' and remove empty segments
    segments = re.split(r'\.\.\.|\[\.\.\.\]', snippet)
    segments = [segment.strip() for segment in segments if segment.strip()]

    return segments


def process_qna(base_name):
    """
    Orchestrates the QnA post-processing pipeline:
    - Loads files,
    - Extracts QnA pairs,
    - Segments snippets for context,
    - Attaches context segments to QnAs,
    - Saves the enriched QnA data into a JSON file.

    Args:

    base_name (str): The base name for identifying related input/output files
    """
    output_data, chunks_data = load_files(base_name)
    qna_list = extract_qna(output_data)

    chunk_map = {chunk['id']: chunk['text'] for chunk in chunks_data}

    for qna in qna_list:
        chunk_text = chunk_map.get(qna['chunk'], '')
        qna['context'] = segment_snippet(qna['snippet'])

    output_dir = "expanded_outputs"
    os.makedirs(output_dir, exist_ok=True)
    output_filename = os.path.join(output_dir, f"{base_name}-expanded.json")

    with open(output_filename, 'w', encoding='utf-8') as f:
        json.dump(qna_list, f, indent=4)

    print(f"Expanded QnA saved to {output_filename}")


if __name__ == "__main__":
    # example use
    # for i in range(8):
        # process_qna("natsec-" + str(i+1))
    process_qna("infra-1")
